{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image \n",
    "#import package.utilities as ut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.utils import resample\n",
    "from six import StringIO\n",
    "from pydot import graph_from_dot_data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime as datetime\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance\n",
    "import pandas_ta as ta\n",
    "#from package import indicator as idr\n",
    "#from package import euklid as eu\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Neural network libraries\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Visualization\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "#config = tf.compat.v1.ConfigProto(device_count = {'GPU': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary work on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_df = pd.read_csv(\"../data/GOLD.csv\")\n",
    "#yahoo_df = yahoo_df.set_index(\"Date\")\n",
    "yahoo_df = yahoo_df.set_index(\"Date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = yahoo_df[['ROC_1', 'ROC_4', 'ROC_7', 'Momentum', '1 Day ROI', '3 Day ROI',\n",
    "       '5 Day ROI', '20 Day ROI', '6_day_RSI', 'MACD_12_26', 'SRSI_30',\n",
    "       'Williams_1', 'Williams_3', 'Williams_14', 'ATR_14', 'CCI']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = yahoo_df[['Open', 'ROC_3', 'ROC_4', 'Momentum', '6 Day ROI', '20 Day ROI',\n",
    "       'EMA_26', 'SRSI_10']]\n",
    "y = yahoo_df[\"Up down\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42134937041909415"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in 80/20 the dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    #df = data\n",
    "    for column in df:\n",
    "        df[column]=((df[column]-df[column].mean())/df[column].std())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set early stopping monitor so the model stops training when it won't improve anymore\n",
    "esm = EarlyStopping(monitor = 'val_binary_accuracy',patience=50)\n",
    "\n",
    "# Set the optimizer\n",
    "opt = keras.optimizers.SGD(learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[keras.metrics.Accuracy(),\n",
    "    keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.49),\n",
    "    keras.metrics.MeanSquaredError(name='my_mse'),\n",
    "    keras.metrics.BinaryCrossentropy(),\n",
    "    keras.metrics.Hinge()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 1.5758 - accuracy: 0.0559 - binary_accuracy: 0.5966 - my_mse: 0.3620 - binary_crossentropy: 1.5758 - hinge: 1.0081 - val_loss: 1.1904 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3956 - val_binary_crossentropy: 1.1904 - val_hinge: 1.0059\n",
      "Epoch 2/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 1.0299 - accuracy: 0.0021 - binary_accuracy: 0.5966 - my_mse: 0.3331 - binary_crossentropy: 1.0299 - hinge: 1.0186 - val_loss: 1.0723 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3738 - val_binary_crossentropy: 1.0723 - val_hinge: 1.0077\n",
      "Epoch 3/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.9246 - accuracy: 0.0010 - binary_accuracy: 0.5966 - my_mse: 0.3172 - binary_crossentropy: 0.9246 - hinge: 1.0237 - val_loss: 1.0063 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3590 - val_binary_crossentropy: 1.0063 - val_hinge: 1.0089\n",
      "Epoch 4/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.8749 - accuracy: 2.6110e-04 - binary_accuracy: 0.5966 - my_mse: 0.3065 - binary_crossentropy: 0.8749 - hinge: 1.0282 - val_loss: 0.9622 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3478 - val_binary_crossentropy: 0.9622 - val_hinge: 1.0100\n",
      "Epoch 5/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.8411 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2979 - binary_crossentropy: 0.8411 - hinge: 1.0314 - val_loss: 0.9294 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3388 - val_binary_crossentropy: 0.9294 - val_hinge: 1.0109\n",
      "Epoch 6/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.8147 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2915 - binary_crossentropy: 0.8147 - hinge: 1.0346 - val_loss: 0.9036 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3312 - val_binary_crossentropy: 0.9036 - val_hinge: 1.0116\n",
      "Epoch 7/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7970 - accuracy: 2.6110e-04 - binary_accuracy: 0.5966 - my_mse: 0.2862 - binary_crossentropy: 0.7970 - hinge: 1.0374 - val_loss: 0.8825 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3247 - val_binary_crossentropy: 0.8825 - val_hinge: 1.0123\n",
      "Epoch 8/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7836 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2810 - binary_crossentropy: 0.7836 - hinge: 1.0392 - val_loss: 0.8651 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3191 - val_binary_crossentropy: 0.8651 - val_hinge: 1.0130\n",
      "Epoch 9/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7712 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2771 - binary_crossentropy: 0.7712 - hinge: 1.0413 - val_loss: 0.8503 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3142 - val_binary_crossentropy: 0.8503 - val_hinge: 1.0135\n",
      "Epoch 10/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7564 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2732 - binary_crossentropy: 0.7564 - hinge: 1.0429 - val_loss: 0.8375 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3098 - val_binary_crossentropy: 0.8375 - val_hinge: 1.0141\n",
      "Epoch 11/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7479 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2702 - binary_crossentropy: 0.7479 - hinge: 1.0446 - val_loss: 0.8264 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3058 - val_binary_crossentropy: 0.8264 - val_hinge: 1.0146\n",
      "Epoch 12/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2678 - binary_crossentropy: 0.7413 - hinge: 1.0467 - val_loss: 0.8166 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.3023 - val_binary_crossentropy: 0.8166 - val_hinge: 1.0150\n",
      "Epoch 13/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 2.6110e-04 - binary_accuracy: 0.5966 - my_mse: 0.2654 - binary_crossentropy: 0.7345 - hinge: 1.0481 - val_loss: 0.8079 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2991 - val_binary_crossentropy: 0.8079 - val_hinge: 1.0154\n",
      "Epoch 14/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7273 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2627 - binary_crossentropy: 0.7273 - hinge: 1.0491 - val_loss: 0.8002 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2962 - val_binary_crossentropy: 0.8002 - val_hinge: 1.0158\n",
      "Epoch 15/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7229 - accuracy: 2.6110e-04 - binary_accuracy: 0.5966 - my_mse: 0.2610 - binary_crossentropy: 0.7229 - hinge: 1.0506 - val_loss: 0.7933 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2935 - val_binary_crossentropy: 0.7933 - val_hinge: 1.0162\n",
      "Epoch 16/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7182 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2592 - binary_crossentropy: 0.7182 - hinge: 1.0517 - val_loss: 0.7870 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2911 - val_binary_crossentropy: 0.7870 - val_hinge: 1.0166\n",
      "Epoch 17/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7139 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2575 - binary_crossentropy: 0.7139 - hinge: 1.0530 - val_loss: 0.7814 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2889 - val_binary_crossentropy: 0.7814 - val_hinge: 1.0169\n",
      "Epoch 18/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2566 - binary_crossentropy: 0.7121 - hinge: 1.0543 - val_loss: 0.7761 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2868 - val_binary_crossentropy: 0.7761 - val_hinge: 1.0172\n",
      "Epoch 19/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7086 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2553 - binary_crossentropy: 0.7086 - hinge: 1.0555 - val_loss: 0.7714 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2849 - val_binary_crossentropy: 0.7714 - val_hinge: 1.0175\n",
      "Epoch 20/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2538 - binary_crossentropy: 0.7047 - hinge: 1.0563 - val_loss: 0.7671 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2831 - val_binary_crossentropy: 0.7671 - val_hinge: 1.0178\n",
      "Epoch 21/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2532 - binary_crossentropy: 0.7032 - hinge: 1.0576 - val_loss: 0.7632 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2815 - val_binary_crossentropy: 0.7632 - val_hinge: 1.0181\n",
      "Epoch 22/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2518 - binary_crossentropy: 0.6999 - hinge: 1.0579 - val_loss: 0.7595 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2800 - val_binary_crossentropy: 0.7595 - val_hinge: 1.0183\n",
      "Epoch 23/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2506 - binary_crossentropy: 0.6968 - hinge: 1.0585 - val_loss: 0.7562 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2786 - val_binary_crossentropy: 0.7562 - val_hinge: 1.0186\n",
      "Epoch 24/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2500 - binary_crossentropy: 0.6954 - hinge: 1.0595 - val_loss: 0.7531 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2773 - val_binary_crossentropy: 0.7531 - val_hinge: 1.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2494 - binary_crossentropy: 0.6942 - hinge: 1.0605 - val_loss: 0.7503 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2761 - val_binary_crossentropy: 0.7503 - val_hinge: 1.0190\n",
      "Epoch 26/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2490 - binary_crossentropy: 0.6932 - hinge: 1.0614 - val_loss: 0.7476 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2750 - val_binary_crossentropy: 0.7476 - val_hinge: 1.0192\n",
      "Epoch 27/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2480 - binary_crossentropy: 0.6906 - hinge: 1.0618 - val_loss: 0.7452 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2739 - val_binary_crossentropy: 0.7452 - val_hinge: 1.0194\n",
      "Epoch 28/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.0000e+00 - binary_accuracy: 0.5969 - my_mse: 0.2479 - binary_crossentropy: 0.6940 - hinge: 1.0628 - val_loss: 0.7429 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2729 - val_binary_crossentropy: 0.7429 - val_hinge: 1.0196\n",
      "Epoch 29/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2469 - binary_crossentropy: 0.6882 - hinge: 1.0629 - val_loss: 0.7408 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2720 - val_binary_crossentropy: 0.7408 - val_hinge: 1.0198\n",
      "Epoch 30/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2462 - binary_crossentropy: 0.6866 - hinge: 1.0635 - val_loss: 0.7389 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2712 - val_binary_crossentropy: 0.7389 - val_hinge: 1.0200\n",
      "Epoch 31/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2465 - binary_crossentropy: 0.6874 - hinge: 1.0648 - val_loss: 0.7370 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2704 - val_binary_crossentropy: 0.7370 - val_hinge: 1.0201\n",
      "Epoch 32/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2455 - binary_crossentropy: 0.6850 - hinge: 1.0647 - val_loss: 0.7353 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2696 - val_binary_crossentropy: 0.7353 - val_hinge: 1.0203\n",
      "Epoch 33/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.0000e+00 - binary_accuracy: 0.5969 - my_mse: 0.2454 - binary_crossentropy: 0.6848 - hinge: 1.0656 - val_loss: 0.7337 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2689 - val_binary_crossentropy: 0.7337 - val_hinge: 1.0204\n",
      "Epoch 34/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2453 - binary_crossentropy: 0.6844 - hinge: 1.0662 - val_loss: 0.7322 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2682 - val_binary_crossentropy: 0.7322 - val_hinge: 1.0206\n",
      "Epoch 35/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6837 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2449 - binary_crossentropy: 0.6837 - hinge: 1.0667 - val_loss: 0.7308 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2676 - val_binary_crossentropy: 0.7308 - val_hinge: 1.0207\n",
      "Epoch 36/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.0000e+00 - binary_accuracy: 0.5963 - my_mse: 0.2443 - binary_crossentropy: 0.6823 - hinge: 1.0667 - val_loss: 0.7295 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2670 - val_binary_crossentropy: 0.7295 - val_hinge: 1.0208\n",
      "Epoch 37/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2444 - binary_crossentropy: 0.6825 - hinge: 1.0674 - val_loss: 0.7282 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2665 - val_binary_crossentropy: 0.7282 - val_hinge: 1.0210\n",
      "Epoch 38/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2438 - binary_crossentropy: 0.6812 - hinge: 1.0677 - val_loss: 0.7271 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2660 - val_binary_crossentropy: 0.7271 - val_hinge: 1.0211\n",
      "Epoch 39/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2439 - binary_crossentropy: 0.6814 - hinge: 1.0682 - val_loss: 0.7260 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2655 - val_binary_crossentropy: 0.7260 - val_hinge: 1.0212\n",
      "Epoch 40/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2438 - binary_crossentropy: 0.6812 - hinge: 1.0688 - val_loss: 0.7249 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2650 - val_binary_crossentropy: 0.7249 - val_hinge: 1.0213\n",
      "Epoch 41/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2428 - binary_crossentropy: 0.6790 - hinge: 1.0685 - val_loss: 0.7240 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2645 - val_binary_crossentropy: 0.7240 - val_hinge: 1.0214\n",
      "Epoch 42/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2430 - binary_crossentropy: 0.6795 - hinge: 1.0693 - val_loss: 0.7231 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2641 - val_binary_crossentropy: 0.7231 - val_hinge: 1.0215\n",
      "Epoch 43/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2431 - binary_crossentropy: 0.6804 - hinge: 1.0697 - val_loss: 0.7221 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2637 - val_binary_crossentropy: 0.7221 - val_hinge: 1.0216\n",
      "Epoch 44/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.0000e+00 - binary_accuracy: 0.5963 - my_mse: 0.2430 - binary_crossentropy: 0.6795 - hinge: 1.0702 - val_loss: 0.7213 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2633 - val_binary_crossentropy: 0.7213 - val_hinge: 1.0217\n",
      "Epoch 45/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2434 - binary_crossentropy: 0.6805 - hinge: 1.0709 - val_loss: 0.7205 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2630 - val_binary_crossentropy: 0.7205 - val_hinge: 1.0218\n",
      "Epoch 46/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.0000e+00 - binary_accuracy: 0.5963 - my_mse: 0.2429 - binary_crossentropy: 0.6792 - hinge: 1.0710 - val_loss: 0.7198 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2626 - val_binary_crossentropy: 0.7198 - val_hinge: 1.0219\n",
      "Epoch 47/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.0000e+00 - binary_accuracy: 0.5969 - my_mse: 0.2425 - binary_crossentropy: 0.6782 - hinge: 1.0709 - val_loss: 0.7191 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2623 - val_binary_crossentropy: 0.7191 - val_hinge: 1.0220\n",
      "Epoch 48/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2422 - binary_crossentropy: 0.6776 - hinge: 1.0711 - val_loss: 0.7184 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2620 - val_binary_crossentropy: 0.7184 - val_hinge: 1.0220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2424 - binary_crossentropy: 0.6782 - hinge: 1.0716 - val_loss: 0.7178 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2617 - val_binary_crossentropy: 0.7178 - val_hinge: 1.0221\n",
      "Epoch 50/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6768 - accuracy: 0.0000e+00 - binary_accuracy: 0.5966 - my_mse: 0.2418 - binary_crossentropy: 0.6768 - hinge: 1.0715 - val_loss: 0.7172 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2615 - val_binary_crossentropy: 0.7172 - val_hinge: 1.0222\n",
      "Epoch 51/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.0000e+00 - binary_accuracy: 0.5971 - my_mse: 0.2419 - binary_crossentropy: 0.6770 - hinge: 1.0717 - val_loss: 0.7167 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5282 - val_my_mse: 0.2612 - val_binary_crossentropy: 0.7167 - val_hinge: 1.0223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e14caf0b50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(256,  activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(Dense(128,  activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(Dense(64,  activation = 'relu'))\n",
    "classifier.add(Dense(32,  activation = 'relu'))\n",
    "classifier.add(Dense(16,  activation = 'relu'))\n",
    "classifier.add(Dense(8,  activation = 'relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(1,  activation = 'relu'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = metrics)\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 50, epochs = 1000, validation_split = 0.10, callbacks = [esm],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training and validation loss\n",
    "plt.plot(classifier.history.history[\"loss\"], label='train')\n",
    "plt.plot(classifier.history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "#x1,y1 =plt.axis()\n",
    "#plt.axis([0,0])\n",
    "#plt.ylim([0.5, 0.7])\n",
    "plt.title('Training/Validation Loss');\n",
    "# Evaluate the model >> model.metrics_names\n",
    "#print(f'{model.metrics_names}: {model.evaluate(Bitcoin_train, y_train , verbose=1)}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = classifier.predict(X_test)\n",
    "y_pred = list(map(lambda x: 0 if x<0.5 else 1, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5342723004694836\n"
     ]
    }
   ],
   "source": [
    "# Computing Accuracy, Precision and Recall\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogReg_pred</th>\n",
       "      <th>LogReg_accuracy</th>\n",
       "      <th>LogReg_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.413014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.513517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.390613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.442266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.318965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.384292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.453980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.340107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.457871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.475958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1065 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LogReg_pred  LogReg_accuracy  LogReg_prob\n",
       "0               0         0.581221     0.413014\n",
       "1               1         0.581221     0.513517\n",
       "2               0         0.581221     0.390613\n",
       "3               0         0.581221     0.442266\n",
       "4               0         0.581221     0.318965\n",
       "...           ...              ...          ...\n",
       "1060            0         0.581221     0.384292\n",
       "1061            0         0.581221     0.453980\n",
       "1062            0         0.581221     0.340107\n",
       "1063            0         0.581221     0.457871\n",
       "1064            0         0.581221     0.475958\n",
       "\n",
       "[1065 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction = pd.read_csv(\"../data/model_accuracy_gold.csv\", index_col = False)\n",
    "df_prediction =  df_prediction.drop(columns=[\"Unnamed: 0\"])\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction[\"ANN_pred\"] = y_pred\n",
    "df_prediction[\"ANN_accuracy\"] = [accuracy for x in range(len(y_pred))]\n",
    "df_prediction[\"ANN_prob\"] = y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogReg_pred</th>\n",
       "      <th>LogReg_accuracy</th>\n",
       "      <th>LogReg_prob</th>\n",
       "      <th>ANN_pred</th>\n",
       "      <th>ANN_accuracy</th>\n",
       "      <th>ANN_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.413014</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.513517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.368543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.390613</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.369001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.442266</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.370133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.318965</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.374883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.384292</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.355275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.453980</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.363723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.340107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.365227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.457871</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.381241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0</td>\n",
       "      <td>0.581221</td>\n",
       "      <td>0.475958</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.374609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1065 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LogReg_pred  LogReg_accuracy  LogReg_prob  ANN_pred  ANN_accuracy  \\\n",
       "0               0         0.581221     0.413014         0      0.534272   \n",
       "1               1         0.581221     0.513517         0      0.534272   \n",
       "2               0         0.581221     0.390613         0      0.534272   \n",
       "3               0         0.581221     0.442266         0      0.534272   \n",
       "4               0         0.581221     0.318965         0      0.534272   \n",
       "...           ...              ...          ...       ...           ...   \n",
       "1060            0         0.581221     0.384292         0      0.534272   \n",
       "1061            0         0.581221     0.453980         0      0.534272   \n",
       "1062            0         0.581221     0.340107         0      0.534272   \n",
       "1063            0         0.581221     0.457871         0      0.534272   \n",
       "1064            0         0.581221     0.475958         0      0.534272   \n",
       "\n",
       "      ANN_prob  \n",
       "0     0.375100  \n",
       "1     0.368543  \n",
       "2     0.369001  \n",
       "3     0.370133  \n",
       "4     0.374883  \n",
       "...        ...  \n",
       "1060  0.355275  \n",
       "1061  0.363723  \n",
       "1062  0.365227  \n",
       "1063  0.381241  \n",
       "1064  0.374609  \n",
       "\n",
       "[1065 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv(\"../data/model_accuracy_gold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
