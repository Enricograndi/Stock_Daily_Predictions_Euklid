{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from package import euklid_regressor as eu\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_df = pd.read_csv('../data/OIL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>SO</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>1 Day ROI</th>\n",
       "      <th>2 Day ROI</th>\n",
       "      <th>3 Day ROI</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>Previous_differenced</th>\n",
       "      <th>Differenced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.709999</td>\n",
       "      <td>88.942238</td>\n",
       "      <td>88.167118</td>\n",
       "      <td>74.710855</td>\n",
       "      <td>67.792084</td>\n",
       "      <td>55.686023</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.217881</td>\n",
       "      <td>0.047954</td>\n",
       "      <td>0.169927</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.005604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.980000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.912837</td>\n",
       "      <td>82.971376</td>\n",
       "      <td>74.729346</td>\n",
       "      <td>57.515026</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.015061</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.261059</td>\n",
       "      <td>0.072905</td>\n",
       "      <td>0.188153</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.009404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.860001</td>\n",
       "      <td>92.452898</td>\n",
       "      <td>62.992404</td>\n",
       "      <td>68.134442</td>\n",
       "      <td>66.270738</td>\n",
       "      <td>56.406417</td>\n",
       "      <td>-0.004141</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.282339</td>\n",
       "      <td>0.075349</td>\n",
       "      <td>0.206991</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>-0.004141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.910000</td>\n",
       "      <td>95.597504</td>\n",
       "      <td>71.093668</td>\n",
       "      <td>71.337782</td>\n",
       "      <td>68.266248</td>\n",
       "      <td>56.778336</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>0.299783</td>\n",
       "      <td>0.074234</td>\n",
       "      <td>0.225549</td>\n",
       "      <td>-0.004141</td>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.910000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.037211</td>\n",
       "      <td>92.862721</td>\n",
       "      <td>87.689086</td>\n",
       "      <td>63.458814</td>\n",
       "      <td>0.034590</td>\n",
       "      <td>0.036383</td>\n",
       "      <td>0.032091</td>\n",
       "      <td>0.389806</td>\n",
       "      <td>0.131406</td>\n",
       "      <td>0.258401</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.034590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>112.120003</td>\n",
       "      <td>59.595269</td>\n",
       "      <td>92.289437</td>\n",
       "      <td>79.351172</td>\n",
       "      <td>70.956700</td>\n",
       "      <td>59.812992</td>\n",
       "      <td>0.070869</td>\n",
       "      <td>0.088755</td>\n",
       "      <td>0.179714</td>\n",
       "      <td>3.398582</td>\n",
       "      <td>-0.818534</td>\n",
       "      <td>4.217115</td>\n",
       "      <td>0.016702</td>\n",
       "      <td>0.070869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>111.760002</td>\n",
       "      <td>58.339161</td>\n",
       "      <td>86.713748</td>\n",
       "      <td>76.767088</td>\n",
       "      <td>69.383213</td>\n",
       "      <td>59.444077</td>\n",
       "      <td>-0.003211</td>\n",
       "      <td>0.067431</td>\n",
       "      <td>0.085259</td>\n",
       "      <td>3.690022</td>\n",
       "      <td>-0.421675</td>\n",
       "      <td>4.111697</td>\n",
       "      <td>0.070869</td>\n",
       "      <td>-0.003211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>114.930000</td>\n",
       "      <td>69.399868</td>\n",
       "      <td>93.562791</td>\n",
       "      <td>83.754692</td>\n",
       "      <td>75.707786</td>\n",
       "      <td>61.674259</td>\n",
       "      <td>0.028364</td>\n",
       "      <td>0.025062</td>\n",
       "      <td>0.097708</td>\n",
       "      <td>4.129184</td>\n",
       "      <td>0.013990</td>\n",
       "      <td>4.115194</td>\n",
       "      <td>-0.003211</td>\n",
       "      <td>0.028364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>112.339996</td>\n",
       "      <td>60.362867</td>\n",
       "      <td>50.784147</td>\n",
       "      <td>61.197273</td>\n",
       "      <td>61.800465</td>\n",
       "      <td>58.841720</td>\n",
       "      <td>-0.022535</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>4.219591</td>\n",
       "      <td>0.083517</td>\n",
       "      <td>4.136074</td>\n",
       "      <td>0.028364</td>\n",
       "      <td>-0.022535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>113.900002</td>\n",
       "      <td>65.806013</td>\n",
       "      <td>68.263841</td>\n",
       "      <td>68.791310</td>\n",
       "      <td>66.711387</td>\n",
       "      <td>60.026487</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>-0.008962</td>\n",
       "      <td>0.019148</td>\n",
       "      <td>4.366781</td>\n",
       "      <td>0.184566</td>\n",
       "      <td>4.182215</td>\n",
       "      <td>-0.022535</td>\n",
       "      <td>0.013886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5241 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Close          SO      RSI_1      RSI_2      RSI_3     RSI_14  \\\n",
       "0      28.709999   88.942238  88.167118  74.710855  67.792084  55.686023   \n",
       "1      28.980000  100.000000  94.912837  82.971376  74.729346  57.515026   \n",
       "2      28.860001   92.452898  62.992404  68.134442  66.270738  56.406417   \n",
       "3      28.910000   95.597504  71.093668  71.337782  68.266248  56.778336   \n",
       "4      29.910000  100.000000  97.037211  92.862721  87.689086  63.458814   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "5236  112.120003   59.595269  92.289437  79.351172  70.956700  59.812992   \n",
       "5237  111.760002   58.339161  86.713748  76.767088  69.383213  59.444077   \n",
       "5238  114.930000   69.399868  93.562791  83.754692  75.707786  61.674259   \n",
       "5239  112.339996   60.362867  50.784147  61.197273  61.800465  58.841720   \n",
       "5240  113.900002   65.806013  68.263841  68.791310  66.711387  60.026487   \n",
       "\n",
       "      1 Day ROI  2 Day ROI  3 Day ROI  MACD_12_26_9  MACDh_12_26_9  \\\n",
       "0      0.005604   0.006662   0.017003      0.217881       0.047954   \n",
       "1      0.009404   0.015061   0.016129      0.261059       0.072905   \n",
       "2     -0.004141   0.005225   0.010858      0.282339       0.075349   \n",
       "3      0.001732  -0.002415   0.006966      0.299783       0.074234   \n",
       "4      0.034590   0.036383   0.032091      0.389806       0.131406   \n",
       "...         ...        ...        ...           ...            ...   \n",
       "5236   0.070869   0.088755   0.179714      3.398582      -0.818534   \n",
       "5237  -0.003211   0.067431   0.085259      3.690022      -0.421675   \n",
       "5238   0.028364   0.025062   0.097708      4.129184       0.013990   \n",
       "5239  -0.022535   0.005190   0.001962      4.219591       0.083517   \n",
       "5240   0.013886  -0.008962   0.019148      4.366781       0.184566   \n",
       "\n",
       "      MACDs_12_26_9  Previous_differenced  Differenced  \n",
       "0          0.169927              0.001052     0.005604  \n",
       "1          0.188153              0.005604     0.009404  \n",
       "2          0.206991              0.009404    -0.004141  \n",
       "3          0.225549             -0.004141     0.001732  \n",
       "4          0.258401              0.001732     0.034590  \n",
       "...             ...                   ...          ...  \n",
       "5236       4.217115              0.016702     0.070869  \n",
       "5237       4.111697              0.070869    -0.003211  \n",
       "5238       4.115194             -0.003211     0.028364  \n",
       "5239       4.136074              0.028364    -0.022535  \n",
       "5240       4.182215             -0.022535     0.013886  \n",
       "\n",
       "[5241 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yahoo_df =yahoo_df[[\"Close\",'SO',\n",
    "                       'RSI_1', \n",
    "                    'RSI_2',\n",
    "                    'RSI_3',\n",
    "                    'RSI_14', \n",
    "                    '1 Day ROI', \n",
    "                    '2 Day ROI',\n",
    "                       '3 Day ROI', \n",
    "                    'MACD_12_26_9',\n",
    "                    'MACDh_12_26_9', \n",
    "                    'MACDs_12_26_9',\n",
    "                     \"Previous_differenced\",\n",
    "                    \"Differenced\"]]\n",
    "price = yahoo_df['Differenced'] \n",
    "close = yahoo_df['Close']\n",
    "yahoo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.8709999e+01,  8.8942238e+01,  8.8167114e+01, ...,\n",
       "         1.6992721e-01,  1.0518506e-03,  5.6041977e-03],\n",
       "       [ 2.8980000e+01,  1.0000000e+02,  9.4912834e+01, ...,\n",
       "         1.8815349e-01,  5.6041977e-03,  9.4044050e-03],\n",
       "       [ 2.8860001e+01,  9.2452896e+01,  6.2992405e+01, ...,\n",
       "         2.0699069e-01,  9.4044050e-03, -4.1407500e-03],\n",
       "       ...,\n",
       "       [ 1.1493000e+02,  6.9399864e+01,  9.3562790e+01, ...,\n",
       "         4.1151943e+00, -3.2108510e-03,  2.8364336e-02],\n",
       "       [ 1.1234000e+02,  6.0362869e+01,  5.0784145e+01, ...,\n",
       "         4.1360736e+00,  2.8364336e-02, -2.2535492e-02],\n",
       "       [ 1.1390000e+02,  6.5806015e+01,  6.8263840e+01, ...,\n",
       "         4.1822147e+00, -2.2535492e-02,  1.3886463e-02]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# convert series to supervised learning\n",
    "values = yahoo_df.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  yahoo_df[[  'SO',\n",
    "                       'RSI_1', 'RSI_2', 'RSI_3', 'RSI_14', '1 Day ROI', '2 Day ROI',\n",
    "                       '3 Day ROI', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9',\n",
    "                     \"Previous_differenced\",\n",
    "                    ]]\n",
    "\n",
    "y = yahoo_df[\"Differenced\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in 80/20 the dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.20,shuffle=False)\n",
    "close_train, close_test = train_test_split(close,test_size = 0.20, shuffle=False)\n",
    "\n",
    "close_train, close_test = list(close_train), list(close_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4192, 1, 12)\n",
      "(4192,)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(75, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(40))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "10/10 [==============================] - 3s 115ms/step - loss: 0.2953 - val_loss: 0.2644\n",
      "Epoch 2/2000\n",
      "10/10 [==============================] - 1s 65ms/step - loss: 0.2804 - val_loss: 0.1766\n",
      "Epoch 3/2000\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 0.2560 - val_loss: 0.1596\n",
      "Epoch 4/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2430 - val_loss: 0.1685\n",
      "Epoch 5/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2439 - val_loss: 0.1543\n",
      "Epoch 6/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2398 - val_loss: 0.1111\n",
      "Epoch 7/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2248 - val_loss: 0.1447\n",
      "Epoch 8/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2248 - val_loss: 0.1255\n",
      "Epoch 9/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2254 - val_loss: 0.1328\n",
      "Epoch 10/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2236 - val_loss: 0.1097\n",
      "Epoch 11/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2197 - val_loss: 0.1042\n",
      "Epoch 12/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2138 - val_loss: 0.0991\n",
      "Epoch 13/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2102 - val_loss: 0.1127\n",
      "Epoch 14/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2137 - val_loss: 0.0943\n",
      "Epoch 15/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2064 - val_loss: 0.0878\n",
      "Epoch 16/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2062 - val_loss: 0.0724\n",
      "Epoch 17/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2003 - val_loss: 0.0854\n",
      "Epoch 18/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2004 - val_loss: 0.0993\n",
      "Epoch 19/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1970 - val_loss: 0.0785\n",
      "Epoch 20/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1948 - val_loss: 0.0716\n",
      "Epoch 21/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1919 - val_loss: 0.0578\n",
      "Epoch 22/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1913 - val_loss: 0.0929\n",
      "Epoch 23/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1923 - val_loss: 0.0673\n",
      "Epoch 24/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1874 - val_loss: 0.0827\n",
      "Epoch 25/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1865 - val_loss: 0.0481\n",
      "Epoch 26/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1855 - val_loss: 0.0533\n",
      "Epoch 27/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1764 - val_loss: 0.0822\n",
      "Epoch 28/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1810 - val_loss: 0.0624\n",
      "Epoch 29/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1807 - val_loss: 0.0771\n",
      "Epoch 30/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1772 - val_loss: 0.0812\n",
      "Epoch 31/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1793 - val_loss: 0.0659\n",
      "Epoch 32/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1699 - val_loss: 0.0573\n",
      "Epoch 33/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1725 - val_loss: 0.0649\n",
      "Epoch 34/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1763 - val_loss: 0.0596\n",
      "Epoch 35/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1722 - val_loss: 0.0621\n",
      "Epoch 36/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1686 - val_loss: 0.0578\n",
      "Epoch 37/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1673 - val_loss: 0.1076\n",
      "Epoch 38/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1699 - val_loss: 0.1210\n",
      "Epoch 39/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1704 - val_loss: 0.0817\n",
      "Epoch 40/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1670 - val_loss: 0.0665\n",
      "Epoch 41/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1678 - val_loss: 0.0650\n",
      "Epoch 42/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1651 - val_loss: 0.0510\n",
      "Epoch 43/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1590 - val_loss: 0.0676\n",
      "Epoch 44/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1549 - val_loss: 0.0779\n",
      "Epoch 45/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1582 - val_loss: 0.2165\n",
      "Epoch 46/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2009 - val_loss: 0.0606\n",
      "Epoch 47/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1610 - val_loss: 0.0897\n",
      "Epoch 48/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1580 - val_loss: 0.0554\n",
      "Epoch 49/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1515 - val_loss: 0.0633\n",
      "Epoch 50/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1523 - val_loss: 0.0615\n",
      "Epoch 51/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1545 - val_loss: 0.0464\n",
      "Epoch 52/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1501 - val_loss: 0.0514\n",
      "Epoch 53/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1499 - val_loss: 0.0401\n",
      "Epoch 54/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1453 - val_loss: 0.0701\n",
      "Epoch 55/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1466 - val_loss: 0.0763\n",
      "Epoch 56/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1434 - val_loss: 0.0566\n",
      "Epoch 57/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1471 - val_loss: 0.0659\n",
      "Epoch 58/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1409 - val_loss: 0.0564\n",
      "Epoch 59/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1405 - val_loss: 0.0593\n",
      "Epoch 60/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1369 - val_loss: 0.0773\n",
      "Epoch 61/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1392 - val_loss: 0.0569\n",
      "Epoch 62/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1396 - val_loss: 0.0593\n",
      "Epoch 63/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1413 - val_loss: 0.0599\n",
      "Epoch 64/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1352 - val_loss: 0.0492\n",
      "Epoch 65/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1382 - val_loss: 0.0393\n",
      "Epoch 66/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1332 - val_loss: 0.0650\n",
      "Epoch 67/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1317 - val_loss: 0.0416\n",
      "Epoch 68/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1302 - val_loss: 0.0533\n",
      "Epoch 69/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1306 - val_loss: 0.0598\n",
      "Epoch 70/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1317 - val_loss: 0.0391\n",
      "Epoch 71/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1264 - val_loss: 0.0392\n",
      "Epoch 72/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1250 - val_loss: 0.0476\n",
      "Epoch 73/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1260 - val_loss: 0.0515\n",
      "Epoch 74/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1227 - val_loss: 0.0533\n",
      "Epoch 75/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1218 - val_loss: 0.0561\n",
      "Epoch 76/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1234 - val_loss: 0.0400\n",
      "Epoch 77/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1185 - val_loss: 0.0307\n",
      "Epoch 78/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1168 - val_loss: 0.0359\n",
      "Epoch 79/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1161 - val_loss: 0.0331\n",
      "Epoch 80/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1140 - val_loss: 0.0398\n",
      "Epoch 81/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1106 - val_loss: 0.0417\n",
      "Epoch 82/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1118 - val_loss: 0.0335\n",
      "Epoch 83/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1099 - val_loss: 0.0325\n",
      "Epoch 84/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1092 - val_loss: 0.0390\n",
      "Epoch 85/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1078 - val_loss: 0.0360\n",
      "Epoch 86/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1069 - val_loss: 0.0289\n",
      "Epoch 87/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1045 - val_loss: 0.0361\n",
      "Epoch 88/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1057 - val_loss: 0.0416\n",
      "Epoch 89/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1061 - val_loss: 0.0315\n",
      "Epoch 90/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1010 - val_loss: 0.0406\n",
      "Epoch 91/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1026 - val_loss: 0.0400\n",
      "Epoch 92/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1005 - val_loss: 0.0375\n",
      "Epoch 93/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0991 - val_loss: 0.0282\n",
      "Epoch 94/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0310\n",
      "Epoch 95/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0944 - val_loss: 0.0321\n",
      "Epoch 96/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0971 - val_loss: 0.0287\n",
      "Epoch 97/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0940 - val_loss: 0.0352\n",
      "Epoch 98/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0943 - val_loss: 0.0349\n",
      "Epoch 99/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0931 - val_loss: 0.0324\n",
      "Epoch 100/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0916 - val_loss: 0.0398\n",
      "Epoch 101/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0902 - val_loss: 0.0416\n",
      "Epoch 102/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0895 - val_loss: 0.0289\n",
      "Epoch 103/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0876 - val_loss: 0.0319\n",
      "Epoch 104/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0874 - val_loss: 0.0281\n",
      "Epoch 105/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0867 - val_loss: 0.0304\n",
      "Epoch 106/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0869 - val_loss: 0.0360\n",
      "Epoch 107/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0841 - val_loss: 0.0334\n",
      "Epoch 108/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0858 - val_loss: 0.0259\n",
      "Epoch 109/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0817 - val_loss: 0.0309\n",
      "Epoch 110/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0820 - val_loss: 0.0273\n",
      "Epoch 111/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0786 - val_loss: 0.0289\n",
      "Epoch 112/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0821 - val_loss: 0.0262\n",
      "Epoch 113/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0785 - val_loss: 0.0312\n",
      "Epoch 114/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0785 - val_loss: 0.0251\n",
      "Epoch 115/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0770 - val_loss: 0.0275\n",
      "Epoch 116/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0763 - val_loss: 0.0303\n",
      "Epoch 117/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0746 - val_loss: 0.0333\n",
      "Epoch 118/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0751 - val_loss: 0.0217\n",
      "Epoch 119/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0756 - val_loss: 0.0244\n",
      "Epoch 120/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0718 - val_loss: 0.0243\n",
      "Epoch 121/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0709 - val_loss: 0.0273\n",
      "Epoch 122/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0702 - val_loss: 0.0279\n",
      "Epoch 123/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0702 - val_loss: 0.0277\n",
      "Epoch 124/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0691 - val_loss: 0.0268\n",
      "Epoch 125/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0709 - val_loss: 0.0208\n",
      "Epoch 126/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0675 - val_loss: 0.0212\n",
      "Epoch 127/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0673 - val_loss: 0.0223\n",
      "Epoch 128/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0649 - val_loss: 0.0255\n",
      "Epoch 129/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0657 - val_loss: 0.0199\n",
      "Epoch 130/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0630 - val_loss: 0.0256\n",
      "Epoch 131/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0622 - val_loss: 0.0248\n",
      "Epoch 132/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0630 - val_loss: 0.0270\n",
      "Epoch 133/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0618 - val_loss: 0.0192\n",
      "Epoch 134/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0606 - val_loss: 0.0215\n",
      "Epoch 135/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0612 - val_loss: 0.0223\n",
      "Epoch 136/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0611 - val_loss: 0.0246\n",
      "Epoch 137/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0613 - val_loss: 0.0205\n",
      "Epoch 138/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0580 - val_loss: 0.0267\n",
      "Epoch 139/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0575 - val_loss: 0.0285\n",
      "Epoch 140/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0577 - val_loss: 0.0196\n",
      "Epoch 141/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0554 - val_loss: 0.0264\n",
      "Epoch 142/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0557 - val_loss: 0.0219\n",
      "Epoch 143/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0555 - val_loss: 0.0223\n",
      "Epoch 144/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0548 - val_loss: 0.0191\n",
      "Epoch 145/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0540 - val_loss: 0.0287\n",
      "Epoch 146/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0525 - val_loss: 0.0277\n",
      "Epoch 147/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0537 - val_loss: 0.0262\n",
      "Epoch 148/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0520 - val_loss: 0.0216\n",
      "Epoch 149/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0520 - val_loss: 0.0220\n",
      "Epoch 150/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0495 - val_loss: 0.0204\n",
      "Epoch 151/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0511 - val_loss: 0.0257\n",
      "Epoch 152/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0504 - val_loss: 0.0260\n",
      "Epoch 153/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0498 - val_loss: 0.0179\n",
      "Epoch 154/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0489 - val_loss: 0.0267\n",
      "Epoch 155/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0494 - val_loss: 0.0175\n",
      "Epoch 156/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0467 - val_loss: 0.0236\n",
      "Epoch 157/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0475 - val_loss: 0.0183\n",
      "Epoch 158/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0459 - val_loss: 0.0237\n",
      "Epoch 159/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0468 - val_loss: 0.0213\n",
      "Epoch 160/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0452 - val_loss: 0.0209\n",
      "Epoch 161/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0440 - val_loss: 0.0235\n",
      "Epoch 162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0440 - val_loss: 0.0247\n",
      "Epoch 163/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0432 - val_loss: 0.0183\n",
      "Epoch 164/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0434 - val_loss: 0.0199\n",
      "Epoch 165/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0416 - val_loss: 0.0176\n",
      "Epoch 166/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0427 - val_loss: 0.0171\n",
      "Epoch 167/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0407 - val_loss: 0.0190\n",
      "Epoch 168/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0417 - val_loss: 0.0171\n",
      "Epoch 169/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0399 - val_loss: 0.0224\n",
      "Epoch 170/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0405 - val_loss: 0.0213\n",
      "Epoch 171/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0400 - val_loss: 0.0227\n",
      "Epoch 172/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0398 - val_loss: 0.0185\n",
      "Epoch 173/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0394 - val_loss: 0.0175\n",
      "Epoch 174/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0383 - val_loss: 0.0167\n",
      "Epoch 175/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0376 - val_loss: 0.0181\n",
      "Epoch 176/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0371 - val_loss: 0.0160\n",
      "Epoch 177/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0362 - val_loss: 0.0162\n",
      "Epoch 178/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0363 - val_loss: 0.0169\n",
      "Epoch 179/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0352 - val_loss: 0.0156\n",
      "Epoch 180/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0353 - val_loss: 0.0159\n",
      "Epoch 181/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0355 - val_loss: 0.0160\n",
      "Epoch 182/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0344 - val_loss: 0.0155\n",
      "Epoch 183/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0347 - val_loss: 0.0155\n",
      "Epoch 184/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0333 - val_loss: 0.0162\n",
      "Epoch 185/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0325 - val_loss: 0.0155\n",
      "Epoch 186/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0336 - val_loss: 0.0157\n",
      "Epoch 187/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0318 - val_loss: 0.0155\n",
      "Epoch 188/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0319 - val_loss: 0.0151\n",
      "Epoch 189/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0319 - val_loss: 0.0152\n",
      "Epoch 190/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0149\n",
      "Epoch 191/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0309 - val_loss: 0.0154\n",
      "Epoch 192/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0304 - val_loss: 0.0160\n",
      "Epoch 193/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0304 - val_loss: 0.0158\n",
      "Epoch 194/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0306 - val_loss: 0.0146\n",
      "Epoch 195/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0299 - val_loss: 0.0153\n",
      "Epoch 196/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0294 - val_loss: 0.0146\n",
      "Epoch 197/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0296 - val_loss: 0.0147\n",
      "Epoch 198/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0293 - val_loss: 0.0150\n",
      "Epoch 199/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0286 - val_loss: 0.0150\n",
      "Epoch 200/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0286 - val_loss: 0.0145\n",
      "Epoch 201/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0289 - val_loss: 0.0150\n",
      "Epoch 202/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0289 - val_loss: 0.0152\n",
      "Epoch 203/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0287 - val_loss: 0.0147\n",
      "Epoch 204/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0283 - val_loss: 0.0149\n",
      "Epoch 205/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0278 - val_loss: 0.0154\n",
      "Epoch 206/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0275 - val_loss: 0.0140\n",
      "Epoch 207/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.0147\n",
      "Epoch 208/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.0144\n",
      "Epoch 209/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0266 - val_loss: 0.0149\n",
      "Epoch 210/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.0149\n",
      "Epoch 211/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0264 - val_loss: 0.0140\n",
      "Epoch 212/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0266 - val_loss: 0.0142\n",
      "Epoch 213/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0262 - val_loss: 0.0142\n",
      "Epoch 214/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0266 - val_loss: 0.0140\n",
      "Epoch 215/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0259 - val_loss: 0.0143\n",
      "Epoch 216/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0260 - val_loss: 0.0141\n",
      "Epoch 217/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0258 - val_loss: 0.0141\n",
      "Epoch 218/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0256 - val_loss: 0.0136\n",
      "Epoch 219/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0254 - val_loss: 0.0139\n",
      "Epoch 220/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0139\n",
      "Epoch 221/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0254 - val_loss: 0.0142\n",
      "Epoch 222/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0248 - val_loss: 0.0138\n",
      "Epoch 223/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.0137\n",
      "Epoch 224/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0135\n",
      "Epoch 225/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0245 - val_loss: 0.0141\n",
      "Epoch 226/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0144\n",
      "Epoch 227/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0257 - val_loss: 0.0133\n",
      "Epoch 228/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0248 - val_loss: 0.0137\n",
      "Epoch 229/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0251 - val_loss: 0.0133\n",
      "Epoch 230/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0136\n",
      "Epoch 231/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0246 - val_loss: 0.0133\n",
      "Epoch 232/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0138\n",
      "Epoch 233/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0238 - val_loss: 0.0133\n",
      "Epoch 234/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.0135\n",
      "Epoch 235/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.0135\n",
      "Epoch 236/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0238 - val_loss: 0.0133\n",
      "Epoch 237/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0239 - val_loss: 0.0142\n",
      "Epoch 238/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0241 - val_loss: 0.0142\n",
      "Epoch 239/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 0.0144\n",
      "Epoch 240/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0242 - val_loss: 0.0141\n",
      "Epoch 241/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0141\n",
      "Epoch 242/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0235 - val_loss: 0.0144\n",
      "Epoch 243/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0230 - val_loss: 0.0131\n",
      "Epoch 244/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0232 - val_loss: 0.0131\n",
      "Epoch 245/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0128\n",
      "Epoch 246/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0226 - val_loss: 0.0132\n",
      "Epoch 247/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0233 - val_loss: 0.0129\n",
      "Epoch 248/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0135\n",
      "Epoch 249/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.0139\n",
      "Epoch 250/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0234 - val_loss: 0.0131\n",
      "Epoch 251/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0224 - val_loss: 0.0134\n",
      "Epoch 252/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0225 - val_loss: 0.0131\n",
      "Epoch 253/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0233 - val_loss: 0.0133\n",
      "Epoch 254/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0228 - val_loss: 0.0139\n",
      "Epoch 255/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0232 - val_loss: 0.0127\n",
      "Epoch 256/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0224 - val_loss: 0.0132\n",
      "Epoch 257/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.0138\n",
      "Epoch 258/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0225 - val_loss: 0.0126\n",
      "Epoch 259/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0222 - val_loss: 0.0126\n",
      "Epoch 260/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0219 - val_loss: 0.0131\n",
      "Epoch 261/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0219 - val_loss: 0.0138\n",
      "Epoch 262/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0222 - val_loss: 0.0128\n",
      "Epoch 263/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0217 - val_loss: 0.0131\n",
      "Epoch 264/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.0128\n",
      "Epoch 265/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0216 - val_loss: 0.0129\n",
      "Epoch 266/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0218 - val_loss: 0.0128\n",
      "Epoch 267/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.0124\n",
      "Epoch 268/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0212 - val_loss: 0.0135\n",
      "Epoch 269/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0124\n",
      "Epoch 270/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0130\n",
      "Epoch 271/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.0128\n",
      "Epoch 272/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0217 - val_loss: 0.0125\n",
      "Epoch 273/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0211 - val_loss: 0.0126\n",
      "Epoch 274/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0215 - val_loss: 0.0129\n",
      "Epoch 275/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0217 - val_loss: 0.0124\n",
      "Epoch 276/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0215 - val_loss: 0.0126\n",
      "Epoch 277/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0211 - val_loss: 0.0127\n",
      "Epoch 278/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0213 - val_loss: 0.0125\n",
      "Epoch 279/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0216 - val_loss: 0.0123\n",
      "Epoch 280/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0124\n",
      "Epoch 281/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.0125\n",
      "Epoch 282/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0209 - val_loss: 0.0123\n",
      "Epoch 283/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0208 - val_loss: 0.0126\n",
      "Epoch 284/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.0129\n",
      "Epoch 285/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0209 - val_loss: 0.0123\n",
      "Epoch 286/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0211 - val_loss: 0.0125\n",
      "Epoch 287/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0208 - val_loss: 0.0123\n",
      "Epoch 288/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.0130\n",
      "Epoch 289/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.0123\n",
      "Epoch 290/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0209 - val_loss: 0.0127\n",
      "Epoch 291/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0209 - val_loss: 0.0125\n",
      "Epoch 292/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0207 - val_loss: 0.0127\n",
      "Epoch 293/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0130\n",
      "Epoch 294/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0132\n",
      "Epoch 295/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0207 - val_loss: 0.0122\n",
      "Epoch 296/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0125\n",
      "Epoch 297/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0207 - val_loss: 0.0127\n",
      "Epoch 298/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.0124\n",
      "Epoch 299/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0206 - val_loss: 0.0123\n",
      "Epoch 300/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.0123\n",
      "Epoch 301/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0206 - val_loss: 0.0121\n",
      "Epoch 302/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0121\n",
      "Epoch 303/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0126\n",
      "Epoch 304/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.0126\n",
      "Epoch 305/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0121\n",
      "Epoch 306/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0200 - val_loss: 0.0124\n",
      "Epoch 307/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0208 - val_loss: 0.0120\n",
      "Epoch 308/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0122\n",
      "Epoch 309/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0120\n",
      "Epoch 310/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0196 - val_loss: 0.0123\n",
      "Epoch 311/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0121\n",
      "Epoch 312/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0118\n",
      "Epoch 313/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0202 - val_loss: 0.0119\n",
      "Epoch 314/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0121\n",
      "Epoch 315/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0126\n",
      "Epoch 316/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0129\n",
      "Epoch 317/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0198 - val_loss: 0.0127\n",
      "Epoch 318/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0199 - val_loss: 0.0120\n",
      "Epoch 319/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0197 - val_loss: 0.0124\n",
      "Epoch 320/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0121\n",
      "Epoch 321/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0196 - val_loss: 0.0117\n",
      "Epoch 322/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0191 - val_loss: 0.0120\n",
      "Epoch 323/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0119\n",
      "Epoch 324/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0121\n",
      "Epoch 325/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0123\n",
      "Epoch 326/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0120\n",
      "Epoch 327/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0117\n",
      "Epoch 328/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0117\n",
      "Epoch 329/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0117\n",
      "Epoch 330/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0193 - val_loss: 0.0122\n",
      "Epoch 331/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0120\n",
      "Epoch 332/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.0123\n",
      "Epoch 333/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0121\n",
      "Epoch 334/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0122\n",
      "Epoch 335/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0119\n",
      "Epoch 336/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0122\n",
      "Epoch 337/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0122\n",
      "Epoch 338/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0117\n",
      "Epoch 339/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0119\n",
      "Epoch 340/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0121\n",
      "Epoch 341/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0117\n",
      "Epoch 342/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0119\n",
      "Epoch 343/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0119\n",
      "Epoch 344/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0121\n",
      "Epoch 345/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0186 - val_loss: 0.0121\n",
      "Epoch 346/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0115\n",
      "Epoch 347/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0189 - val_loss: 0.0121\n",
      "Epoch 348/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0118\n",
      "Epoch 349/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0118\n",
      "Epoch 350/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0126\n",
      "Epoch 351/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0117\n",
      "Epoch 352/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0117\n",
      "Epoch 353/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0119\n",
      "Epoch 354/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0187 - val_loss: 0.0126\n",
      "Epoch 355/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0118\n",
      "Epoch 356/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0182 - val_loss: 0.0119\n",
      "Epoch 357/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0116\n",
      "Epoch 358/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0118\n",
      "Epoch 359/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0118\n",
      "Epoch 360/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0117\n",
      "Epoch 361/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0117\n",
      "Epoch 362/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0116\n",
      "Epoch 363/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0118\n",
      "Epoch 364/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0116\n",
      "Epoch 365/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0115\n",
      "Epoch 366/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0113\n",
      "Epoch 367/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0120\n",
      "Epoch 368/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0120\n",
      "Epoch 369/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0115\n",
      "Epoch 370/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0119\n",
      "Epoch 371/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0120\n",
      "Epoch 372/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0117\n",
      "Epoch 373/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0115\n",
      "Epoch 374/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0120\n",
      "Epoch 375/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0122\n",
      "Epoch 376/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0115\n",
      "Epoch 377/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0119\n",
      "Epoch 378/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0115\n",
      "Epoch 379/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0116\n",
      "Epoch 380/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0117\n",
      "Epoch 381/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0115\n",
      "Epoch 382/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0115\n",
      "Epoch 383/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0120\n",
      "Epoch 384/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0115\n",
      "Epoch 385/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0116\n",
      "Epoch 386/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0120\n",
      "Epoch 387/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0118\n",
      "Epoch 388/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0113\n",
      "Epoch 389/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0179 - val_loss: 0.0118\n",
      "Epoch 390/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0179 - val_loss: 0.0115\n",
      "Epoch 391/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0113\n",
      "Epoch 392/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0114\n",
      "Epoch 393/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0119\n",
      "Epoch 394/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0114\n",
      "Epoch 395/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0118\n",
      "Epoch 396/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0113\n",
      "Epoch 397/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0114\n",
      "Epoch 398/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0113\n",
      "Epoch 399/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0112\n",
      "Epoch 400/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0115\n",
      "Epoch 401/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0118\n",
      "Epoch 402/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0112\n",
      "Epoch 403/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 404/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0117\n",
      "Epoch 405/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0117\n",
      "Epoch 406/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0116\n",
      "Epoch 407/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 408/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0112\n",
      "Epoch 409/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0113\n",
      "Epoch 410/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.0115\n",
      "Epoch 411/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0115\n",
      "Epoch 412/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0111\n",
      "Epoch 413/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0113\n",
      "Epoch 414/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0113\n",
      "Epoch 415/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0118\n",
      "Epoch 416/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0112\n",
      "Epoch 417/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0117\n",
      "Epoch 418/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0114\n",
      "Epoch 419/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.0113\n",
      "Epoch 420/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0118\n",
      "Epoch 421/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0113\n",
      "Epoch 422/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0115\n",
      "Epoch 423/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 424/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0110\n",
      "Epoch 425/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0115\n",
      "Epoch 426/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0113\n",
      "Epoch 427/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0115\n",
      "Epoch 428/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0108\n",
      "Epoch 429/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 430/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 431/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0112\n",
      "Epoch 432/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0117\n",
      "Epoch 433/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0117\n",
      "Epoch 434/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0110\n",
      "Epoch 435/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0113\n",
      "Epoch 436/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0175 - val_loss: 0.0110\n",
      "Epoch 437/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0171 - val_loss: 0.0111\n",
      "Epoch 438/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0170 - val_loss: 0.0116\n",
      "Epoch 439/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0172 - val_loss: 0.0112\n",
      "Epoch 440/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 441/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0116\n",
      "Epoch 442/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.0111\n",
      "Epoch 443/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.0114\n",
      "Epoch 444/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0115\n",
      "Epoch 445/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0116\n",
      "Epoch 446/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0112\n",
      "Epoch 447/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.0110\n",
      "Epoch 448/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 449/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 450/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.0111\n",
      "Epoch 451/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 452/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 453/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0113\n",
      "Epoch 454/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0109\n",
      "Epoch 455/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0114\n",
      "Epoch 456/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.0113\n",
      "Epoch 457/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0172 - val_loss: 0.0112\n",
      "Epoch 458/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 459/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0109\n",
      "Epoch 460/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 461/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0111\n",
      "Epoch 462/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0114\n",
      "Epoch 463/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0110\n",
      "Epoch 464/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 465/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0116\n",
      "Epoch 466/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0109\n",
      "Epoch 467/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0110\n",
      "Epoch 468/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0109\n",
      "Epoch 469/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0113\n",
      "Epoch 470/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0111\n",
      "Epoch 471/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0118\n",
      "Epoch 472/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0113\n",
      "Epoch 473/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0114\n",
      "Epoch 474/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 475/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0111\n",
      "Epoch 476/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 477/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 478/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0112\n",
      "Epoch 479/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0109\n",
      "Epoch 480/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0114\n",
      "Epoch 481/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0108\n",
      "Epoch 482/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0117\n",
      "Epoch 483/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0111\n",
      "Epoch 484/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0166 - val_loss: 0.0107\n",
      "Epoch 485/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0110\n",
      "Epoch 486/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0112\n",
      "Epoch 487/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0166 - val_loss: 0.0110\n",
      "Epoch 488/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0163 - val_loss: 0.0110\n",
      "Epoch 489/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 490/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0106\n",
      "Epoch 491/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0115\n",
      "Epoch 492/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0106\n",
      "Epoch 493/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0107\n",
      "Epoch 494/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0114\n",
      "Epoch 495/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0108\n",
      "Epoch 496/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0109\n",
      "Epoch 497/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0112\n",
      "Epoch 498/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 499/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0110\n",
      "Epoch 500/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0117\n",
      "Epoch 501/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0110\n",
      "Epoch 502/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0109\n",
      "Epoch 503/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0112\n",
      "Epoch 504/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 505/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0106\n",
      "Epoch 506/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 507/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 508/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0109\n",
      "Epoch 509/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0104\n",
      "Epoch 510/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0108\n",
      "Epoch 511/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0112\n",
      "Epoch 512/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0116\n",
      "Epoch 513/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0111\n",
      "Epoch 514/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 515/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0112\n",
      "Epoch 516/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 517/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 518/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0160 - val_loss: 0.0116\n",
      "Epoch 519/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0107\n",
      "Epoch 520/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.0110\n",
      "Epoch 521/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.0111\n",
      "Epoch 522/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0107\n",
      "Epoch 523/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0108\n",
      "Epoch 524/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0107\n",
      "Epoch 525/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0108\n",
      "Epoch 526/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0115\n",
      "Epoch 527/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0111\n",
      "Epoch 528/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0107\n",
      "Epoch 529/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 530/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0107\n",
      "Epoch 531/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0108\n",
      "Epoch 532/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 533/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0107\n",
      "Epoch 534/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 535/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 536/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 537/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0108\n",
      "Epoch 538/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0111\n",
      "Epoch 539/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0105\n",
      "Epoch 540/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0112\n",
      "Epoch 541/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0104\n",
      "Epoch 542/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0109\n",
      "Epoch 543/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0158 - val_loss: 0.0105\n",
      "Epoch 544/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0107\n",
      "Epoch 545/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 546/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0158 - val_loss: 0.0106\n",
      "Epoch 547/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0108\n",
      "Epoch 548/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0111\n",
      "Epoch 549/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0160 - val_loss: 0.0111\n",
      "Epoch 550/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0105\n",
      "Epoch 551/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 552/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0162 - val_loss: 0.0109\n",
      "Epoch 553/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0106\n",
      "Epoch 554/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0109\n",
      "Epoch 555/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 556/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0110\n",
      "Epoch 557/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0105\n",
      "Epoch 558/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 559/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.0111\n",
      "Epoch 560/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 561/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0157 - val_loss: 0.0109\n",
      "Epoch 562/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 563/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0106\n",
      "Epoch 564/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.0106\n",
      "Epoch 565/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0158 - val_loss: 0.0110\n",
      "Epoch 566/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 567/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.0107\n",
      "Epoch 568/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 569/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0160 - val_loss: 0.0110\n",
      "Epoch 570/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0162 - val_loss: 0.0110\n",
      "Epoch 571/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0158 - val_loss: 0.0108\n",
      "Epoch 572/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0154 - val_loss: 0.0107\n",
      "Epoch 573/2000\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 574/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0159 - val_loss: 0.0106\n",
      "Epoch 575/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0160 - val_loss: 0.0108\n",
      "Epoch 576/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0160 - val_loss: 0.0103\n",
      "Epoch 577/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0155 - val_loss: 0.0106\n",
      "Epoch 578/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 579/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 580/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 581/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0158 - val_loss: 0.0110\n",
      "Epoch 582/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0108\n",
      "Epoch 583/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0155 - val_loss: 0.0106\n",
      "Epoch 584/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0154 - val_loss: 0.0107\n",
      "Epoch 585/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0159 - val_loss: 0.0109\n",
      "Epoch 586/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0156 - val_loss: 0.0111\n",
      "Epoch 587/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0156 - val_loss: 0.0106\n",
      "Epoch 588/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0157 - val_loss: 0.0107\n",
      "Epoch 589/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0157 - val_loss: 0.0103\n",
      "Epoch 590/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0156 - val_loss: 0.0107\n",
      "Epoch 591/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0157 - val_loss: 0.0106\n",
      "Epoch 592/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0107\n",
      "Epoch 593/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0160 - val_loss: 0.0109\n",
      "Epoch 594/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0158 - val_loss: 0.0105\n",
      "Epoch 595/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0158 - val_loss: 0.0105\n",
      "Epoch 596/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0108\n",
      "Epoch 597/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0157 - val_loss: 0.0112\n",
      "Epoch 598/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0157 - val_loss: 0.0115\n",
      "Epoch 599/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0107\n",
      "Epoch 600/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 601/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0159 - val_loss: 0.0103\n",
      "Epoch 602/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0157 - val_loss: 0.0108\n",
      "Epoch 603/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0154 - val_loss: 0.0107\n",
      "Epoch 604/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 605/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0154 - val_loss: 0.0107\n",
      "Epoch 606/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 607/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0158 - val_loss: 0.0107\n",
      "Epoch 608/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0154 - val_loss: 0.0105\n",
      "Epoch 609/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0104\n",
      "Epoch 610/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 611/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0155 - val_loss: 0.0111\n",
      "Epoch 612/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0107\n",
      "Epoch 613/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 614/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0156 - val_loss: 0.0115\n",
      "Epoch 615/2000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0159 - val_loss: 0.0102\n",
      "Epoch 616/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0107\n",
      "Epoch 617/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0154 - val_loss: 0.0109\n",
      "Epoch 618/2000\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0154 - val_loss: 0.0105\n",
      "Epoch 619/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0156 - val_loss: 0.0111\n",
      "Epoch 620/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0158 - val_loss: 0.0107\n",
      "Epoch 621/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 622/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 623/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 624/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 625/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0156 - val_loss: 0.0104\n",
      "Epoch 626/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 627/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0152 - val_loss: 0.0107\n",
      "Epoch 628/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 629/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0106\n",
      "Epoch 630/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0154 - val_loss: 0.0104\n",
      "Epoch 631/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 632/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0153 - val_loss: 0.0111\n",
      "Epoch 633/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0155 - val_loss: 0.0110\n",
      "Epoch 634/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0153 - val_loss: 0.0105\n",
      "Epoch 635/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 636/2000\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0155 - val_loss: 0.0103\n",
      "Epoch 637/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0154 - val_loss: 0.0105\n",
      "Epoch 638/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0151 - val_loss: 0.0102\n",
      "Epoch 639/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 640/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0154 - val_loss: 0.0107\n",
      "Epoch 641/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 642/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0111\n",
      "Epoch 643/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0152 - val_loss: 0.0104\n",
      "Epoch 644/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 645/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0154 - val_loss: 0.0108\n",
      "Epoch 646/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 647/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0153 - val_loss: 0.0107\n",
      "Epoch 648/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0102\n",
      "Epoch 649/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0108\n",
      "Epoch 650/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 651/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0151 - val_loss: 0.0112\n",
      "Epoch 652/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 653/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 654/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0152 - val_loss: 0.0104\n",
      "Epoch 655/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 656/2000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0155 - val_loss: 0.0101\n",
      "Epoch 657/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 658/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0112\n",
      "Epoch 659/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 660/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 661/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 662/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 663/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 664/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0108\n",
      "Epoch 665/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 666/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 667/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0108\n",
      "Epoch 668/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0107\n",
      "Epoch 669/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 670/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 671/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 672/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0155 - val_loss: 0.0103\n",
      "Epoch 673/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0151 - val_loss: 0.0107\n",
      "Epoch 674/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 675/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0104\n",
      "Epoch 676/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0150 - val_loss: 0.0104\n",
      "Epoch 677/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 678/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 679/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0153 - val_loss: 0.0110\n",
      "Epoch 680/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0151 - val_loss: 0.0110\n",
      "Epoch 681/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 682/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 683/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 684/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0153 - val_loss: 0.0104\n",
      "Epoch 685/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 686/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0153 - val_loss: 0.0106\n",
      "Epoch 687/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 688/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0151 - val_loss: 0.0106\n",
      "Epoch 689/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 690/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0152 - val_loss: 0.0108\n",
      "Epoch 691/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 692/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0104\n",
      "Epoch 693/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0154 - val_loss: 0.0111\n",
      "Epoch 694/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0153 - val_loss: 0.0102\n",
      "Epoch 695/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 696/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0150 - val_loss: 0.0103\n",
      "Epoch 697/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0150 - val_loss: 0.0108\n",
      "Epoch 698/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 699/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0150 - val_loss: 0.0106\n",
      "Epoch 700/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0106\n",
      "Epoch 701/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0151 - val_loss: 0.0107\n",
      "Epoch 702/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 703/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 704/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0107\n",
      "Epoch 705/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0149 - val_loss: 0.0102\n",
      "Epoch 706/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0106\n",
      "Epoch 707/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 708/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0103\n",
      "Epoch 709/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0151 - val_loss: 0.0100\n",
      "Epoch 710/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0107\n",
      "Epoch 711/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 712/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 713/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 714/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0104\n",
      "Epoch 715/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 716/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0100\n",
      "Epoch 717/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 718/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 719/2000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0150 - val_loss: 0.0104\n",
      "Epoch 720/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 721/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0150 - val_loss: 0.0105\n",
      "Epoch 722/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0150 - val_loss: 0.0104\n",
      "Epoch 723/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0100\n",
      "Epoch 724/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0148 - val_loss: 0.0104\n",
      "Epoch 725/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0107\n",
      "Epoch 726/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 727/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 728/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0150 - val_loss: 0.0106\n",
      "Epoch 729/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0107\n",
      "Epoch 730/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0100\n",
      "Epoch 731/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0150 - val_loss: 0.0105\n",
      "Epoch 732/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0147 - val_loss: 0.0101\n",
      "Epoch 733/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0104\n",
      "Epoch 734/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0104\n",
      "Epoch 735/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0150 - val_loss: 0.0103\n",
      "Epoch 736/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0108\n",
      "Epoch 737/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0153 - val_loss: 0.0103\n",
      "Epoch 738/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0147 - val_loss: 0.0104\n",
      "Epoch 739/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 740/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0150 - val_loss: 0.0105\n",
      "Epoch 741/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0145 - val_loss: 0.0105\n",
      "Epoch 742/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0102\n",
      "Epoch 743/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 744/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0147 - val_loss: 0.0104\n",
      "Epoch 745/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0151 - val_loss: 0.0105\n",
      "Epoch 746/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0147 - val_loss: 0.0104\n",
      "Epoch 747/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0147 - val_loss: 0.0103\n",
      "Epoch 748/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0148 - val_loss: 0.0106\n",
      "Epoch 749/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0103\n",
      "Epoch 750/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0106\n",
      "Epoch 751/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 752/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0106\n",
      "Epoch 753/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0150 - val_loss: 0.0111\n",
      "Epoch 754/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0152 - val_loss: 0.0112\n",
      "Epoch 755/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 756/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 757/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0103\n",
      "Epoch 758/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 759/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 760/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 761/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0104\n",
      "Epoch 762/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 763/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0105\n",
      "Epoch 764/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0149 - val_loss: 0.0102\n",
      "Epoch 765/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0145 - val_loss: 0.0106\n",
      "Epoch 766/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0104\n",
      "Epoch 767/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 768/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0145 - val_loss: 0.0101\n",
      "Epoch 769/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 770/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 771/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0147 - val_loss: 0.0103\n",
      "Epoch 772/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0148 - val_loss: 0.0100\n",
      "Epoch 773/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 774/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0149 - val_loss: 0.0108\n",
      "Epoch 775/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 776/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0145 - val_loss: 0.0105\n",
      "Epoch 777/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 778/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 779/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0149 - val_loss: 0.0109\n",
      "Epoch 780/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0103\n",
      "Epoch 781/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 782/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0150 - val_loss: 0.0100\n",
      "Epoch 783/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0104\n",
      "Epoch 784/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 785/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0104\n",
      "Epoch 786/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0106\n",
      "Epoch 787/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 788/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0145 - val_loss: 0.0106\n",
      "Epoch 789/2000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0148 - val_loss: 0.0106\n",
      "Epoch 790/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0149 - val_loss: 0.0103\n",
      "Epoch 791/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0107\n",
      "Epoch 792/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 793/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 794/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 795/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0106\n",
      "Epoch 796/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.0111\n",
      "Epoch 797/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 798/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0145 - val_loss: 0.0106\n",
      "Epoch 799/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 800/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0100\n",
      "Epoch 801/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 802/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0145 - val_loss: 0.0105\n",
      "Epoch 803/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 804/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 805/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0145 - val_loss: 0.0108\n",
      "Epoch 806/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0147 - val_loss: 0.0103\n",
      "Epoch 807/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.0105\n",
      "Epoch 808/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0145 - val_loss: 0.0102\n",
      "Epoch 809/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 810/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0149 - val_loss: 0.0106\n",
      "Epoch 811/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0148 - val_loss: 0.0106\n",
      "Epoch 812/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0147 - val_loss: 0.0108\n",
      "Epoch 813/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0146 - val_loss: 0.0104\n",
      "Epoch 814/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0148 - val_loss: 0.0101\n",
      "Epoch 815/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 816/2000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 817/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 818/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0106\n",
      "Epoch 819/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 820/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 821/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0144 - val_loss: 0.0105\n",
      "Epoch 822/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0105\n",
      "Epoch 823/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 824/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0144 - val_loss: 0.0103\n",
      "Epoch 825/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0144 - val_loss: 0.0102\n",
      "Epoch 826/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 827/2000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0149 - val_loss: 0.0100\n",
      "Epoch 828/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 829/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0148 - val_loss: 0.0104\n",
      "Epoch 830/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 831/2000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0147 - val_loss: 0.0101\n",
      "Epoch 832/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0105\n",
      "Epoch 833/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0147 - val_loss: 0.0105\n",
      "Epoch 834/2000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0145 - val_loss: 0.0108\n",
      "Epoch 835/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 836/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 837/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 838/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 839/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0101\n",
      "Epoch 840/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0100\n",
      "Epoch 841/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0101\n",
      "Epoch 842/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0108\n",
      "Epoch 843/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0101\n",
      "Epoch 844/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 845/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0105\n",
      "Epoch 846/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 847/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 848/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0105\n",
      "Epoch 849/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 850/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0100\n",
      "Epoch 851/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 852/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0102\n",
      "Epoch 853/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0106\n",
      "Epoch 854/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 855/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 856/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0108\n",
      "Epoch 857/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 858/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0105\n",
      "Epoch 859/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 860/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0099\n",
      "Epoch 861/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0101\n",
      "Epoch 862/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 863/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 864/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 865/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0100\n",
      "Epoch 866/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 867/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0104\n",
      "Epoch 868/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0101\n",
      "Epoch 869/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0103\n",
      "Epoch 870/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0101\n",
      "Epoch 871/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 872/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0104\n",
      "Epoch 873/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 874/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0107\n",
      "Epoch 875/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0111\n",
      "Epoch 876/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0098\n",
      "Epoch 877/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0101\n",
      "Epoch 878/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 879/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0101\n",
      "Epoch 880/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0107\n",
      "Epoch 881/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0105\n",
      "Epoch 882/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0100\n",
      "Epoch 883/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0105\n",
      "Epoch 884/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 885/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0105\n",
      "Epoch 886/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0101\n",
      "Epoch 887/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0100\n",
      "Epoch 888/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 889/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 890/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0100\n",
      "Epoch 891/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0107\n",
      "Epoch 892/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 893/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0104\n",
      "Epoch 894/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 895/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0102\n",
      "Epoch 896/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0104\n",
      "Epoch 897/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0102\n",
      "Epoch 898/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 899/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0105\n",
      "Epoch 900/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 901/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 902/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0105\n",
      "Epoch 903/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 904/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 905/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 906/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0107\n",
      "Epoch 907/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0147 - val_loss: 0.0109\n",
      "Epoch 908/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0100\n",
      "Epoch 909/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 910/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0101\n",
      "Epoch 911/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0102\n",
      "Epoch 912/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0104\n",
      "Epoch 913/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 914/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 915/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0109\n",
      "Epoch 916/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0100\n",
      "Epoch 917/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0106\n",
      "Epoch 918/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 919/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0101\n",
      "Epoch 920/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0106\n",
      "Epoch 921/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0102\n",
      "Epoch 922/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0104\n",
      "Epoch 923/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 924/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0102\n",
      "Epoch 925/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 926/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0097\n",
      "Epoch 927/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0103\n",
      "Epoch 928/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0105\n",
      "Epoch 929/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0107\n",
      "Epoch 930/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0101\n",
      "Epoch 931/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 932/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0100\n",
      "Epoch 933/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 934/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0097\n",
      "Epoch 935/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 936/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0104\n",
      "Epoch 937/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0099\n",
      "Epoch 938/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 939/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0104\n",
      "Epoch 940/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0103\n",
      "Epoch 941/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0102\n",
      "Epoch 942/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 943/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 944/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 945/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0104\n",
      "Epoch 946/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0099\n",
      "Epoch 947/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0099\n",
      "Epoch 948/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 949/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0104\n",
      "Epoch 950/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 951/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0098\n",
      "Epoch 952/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 953/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0098\n",
      "Epoch 954/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 955/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0108\n",
      "Epoch 956/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0102\n",
      "Epoch 957/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 958/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0102\n",
      "Epoch 959/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 960/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 961/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 962/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0104\n",
      "Epoch 963/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0103\n",
      "Epoch 964/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0104\n",
      "Epoch 965/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0110\n",
      "Epoch 966/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0100\n",
      "Epoch 967/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 968/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 969/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 970/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0105\n",
      "Epoch 971/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0106\n",
      "Epoch 972/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0100\n",
      "Epoch 973/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 974/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0104\n",
      "Epoch 975/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 976/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 977/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0104\n",
      "Epoch 978/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 979/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 980/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 981/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 982/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 983/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0097\n",
      "Epoch 984/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 985/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0103\n",
      "Epoch 986/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 987/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0105\n",
      "Epoch 988/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 989/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 990/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 991/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 992/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0106\n",
      "Epoch 993/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 994/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 995/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 996/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 997/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 998/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 999/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0101\n",
      "Epoch 1000/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 1001/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0101\n",
      "Epoch 1002/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 1003/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 1004/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 1005/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 1006/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0104\n",
      "Epoch 1007/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0106\n",
      "Epoch 1008/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0108\n",
      "Epoch 1009/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 1010/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 1011/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 1012/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 1013/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0104\n",
      "Epoch 1014/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0103\n",
      "Epoch 1015/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 1016/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 1017/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0104\n",
      "Epoch 1018/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0099\n",
      "Epoch 1019/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 1020/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 1021/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0099\n",
      "Epoch 1022/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 1023/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0100\n",
      "Epoch 1024/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 1025/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0099\n",
      "Epoch 1026/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 1027/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 1028/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 1029/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 1030/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 1031/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 1032/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1033/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 1034/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 1035/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0102\n",
      "Epoch 1036/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0101\n",
      "Epoch 1037/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0102\n",
      "Epoch 1038/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 1039/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0098\n",
      "Epoch 1040/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 1041/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0099\n",
      "Epoch 1042/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 1043/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0103\n",
      "Epoch 1044/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0101\n",
      "Epoch 1045/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 1046/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 1047/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 1048/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 1049/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0103\n",
      "Epoch 1050/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 1051/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 1052/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0108\n",
      "Epoch 1053/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 1054/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0101\n",
      "Epoch 1055/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 1056/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0098\n",
      "Epoch 1057/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 1058/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 1059/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 1060/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0106\n",
      "Epoch 1061/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0100\n",
      "Epoch 1062/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0104\n",
      "Epoch 1063/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 1064/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0105\n",
      "Epoch 1065/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 1066/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 1067/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 1068/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 1069/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 1070/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0099\n",
      "Epoch 1071/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1072/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 1073/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0097\n",
      "Epoch 1074/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 1075/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 1076/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 1077/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0103\n",
      "Epoch 1078/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 1079/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1080/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 1081/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 1082/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 1083/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 1084/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 1085/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0104\n",
      "Epoch 1086/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 1087/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0099\n",
      "Epoch 1088/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 1089/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 1090/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 1091/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 1092/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 1093/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1094/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 1095/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 1096/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 1097/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0106\n",
      "Epoch 1098/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 1099/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 1100/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 1101/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1102/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 1103/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0100\n",
      "Epoch 1104/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 1105/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1106/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 1107/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 1108/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0105\n",
      "Epoch 1109/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1110/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0104\n",
      "Epoch 1111/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0099\n",
      "Epoch 1112/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 1113/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 1114/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 1115/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 1116/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 1117/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 1118/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0097\n",
      "Epoch 1119/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1120/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1121/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1122/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 1123/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0106\n",
      "Epoch 1124/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 1125/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 1126/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0096\n",
      "Epoch 1127/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1128/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 1129/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0099\n",
      "Epoch 1130/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 1131/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 1132/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 1133/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1134/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 1135/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0099\n",
      "Epoch 1136/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 1137/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 1138/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 1139/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0098\n",
      "Epoch 1140/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1141/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1142/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0101\n",
      "Epoch 1143/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0107\n",
      "Epoch 1144/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0103\n",
      "Epoch 1145/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0098\n",
      "Epoch 1146/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 1147/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 1148/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 1149/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 1150/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0099\n",
      "Epoch 1151/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 1152/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 1153/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0104\n",
      "Epoch 1154/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1155/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0099\n",
      "Epoch 1156/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1157/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 1158/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0107\n",
      "Epoch 1159/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 1160/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 1161/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 1162/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0101\n",
      "Epoch 1163/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 1164/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 1165/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 1166/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 1167/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 1168/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1169/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1170/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 1171/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 1172/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0107\n",
      "Epoch 1173/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 1174/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1175/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0097\n",
      "Epoch 1176/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 1177/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 1178/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1179/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 1180/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1181/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0107\n",
      "Epoch 1182/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 1183/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 1184/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1185/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1186/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 1187/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 1188/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 1189/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 1190/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0099\n",
      "Epoch 1191/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 1192/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0106\n",
      "Epoch 1193/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0098\n",
      "Epoch 1194/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 1195/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 1196/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 1197/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 1198/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 1199/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1200/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1201/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 1202/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 1203/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1204/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 1205/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1206/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 1207/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1208/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1209/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 1210/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0097\n",
      "Epoch 1211/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1212/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1213/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 1214/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0101\n",
      "Epoch 1215/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 1216/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0103\n",
      "Epoch 1217/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 1218/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 1219/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0101\n",
      "Epoch 1220/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 1221/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 1222/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 1223/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1224/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 1225/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1226/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1227/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1228/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1229/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1230/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 1231/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0097\n",
      "Epoch 1232/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1233/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1234/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 1235/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 1236/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1237/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0105\n",
      "Epoch 1238/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 1239/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 1240/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1241/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1242/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0107\n",
      "Epoch 1243/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1244/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1245/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1246/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 1247/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0098\n",
      "Epoch 1248/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0105\n",
      "Epoch 1249/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1250/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1251/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 1252/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 1253/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1254/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 1255/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0097\n",
      "Epoch 1256/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1257/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1258/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 1259/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 1260/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 1261/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 1262/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0100\n",
      "Epoch 1263/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1264/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 1265/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1266/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 1267/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 1268/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 1269/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 1270/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0096\n",
      "Epoch 1271/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 1272/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0098\n",
      "Epoch 1273/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0096\n",
      "Epoch 1274/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1275/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0100\n",
      "Epoch 1276/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 1277/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 1278/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0099\n",
      "Epoch 1279/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 1280/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1281/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 1282/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1283/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1284/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1285/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1286/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1287/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1288/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 1289/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 1290/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1291/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1292/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1293/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 1294/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1295/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1296/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1297/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 1298/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0099\n",
      "Epoch 1299/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1300/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1301/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 1302/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0104\n",
      "Epoch 1303/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1304/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1305/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 1306/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1307/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1308/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1309/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0098\n",
      "Epoch 1310/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1311/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 1312/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1313/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1314/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0102\n",
      "Epoch 1315/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 1316/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1317/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 1318/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0097\n",
      "Epoch 1319/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1320/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0103\n",
      "Epoch 1321/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1322/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1323/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 1324/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 1325/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 1326/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1327/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1328/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1329/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 1330/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1331/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1332/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 1333/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1334/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1335/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1336/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 1337/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 1338/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1339/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 1340/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1341/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 1342/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1343/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 1344/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0104\n",
      "Epoch 1345/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0096\n",
      "Epoch 1346/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1347/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0097\n",
      "Epoch 1348/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 1349/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 1350/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1351/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1352/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1353/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0106\n",
      "Epoch 1354/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1355/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0097\n",
      "Epoch 1356/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 1357/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 1358/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1359/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1360/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1361/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0108\n",
      "Epoch 1362/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 1363/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1364/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 1365/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 1366/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1367/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 1368/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 1369/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 1370/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1371/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1372/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 1373/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 1374/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 1375/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 1376/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0098\n",
      "Epoch 1377/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1378/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0097\n",
      "Epoch 1379/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1380/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 1381/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1382/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1383/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1384/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1385/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1386/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1387/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 1388/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0097\n",
      "Epoch 1389/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 1390/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1391/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1392/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 1393/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1394/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0101\n",
      "Epoch 1395/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1396/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1397/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1398/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1399/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1400/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1401/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1402/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 1403/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1404/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1405/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1406/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0101\n",
      "Epoch 1407/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1408/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1409/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1410/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0106\n",
      "Epoch 1411/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1412/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1413/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1414/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1415/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1416/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1417/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1418/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1419/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1420/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1421/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1422/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0102\n",
      "Epoch 1423/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0097\n",
      "Epoch 1424/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1425/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1426/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1427/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1428/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 1429/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1430/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0099\n",
      "Epoch 1431/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0096\n",
      "Epoch 1432/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1433/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1434/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1435/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1436/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0097\n",
      "Epoch 1437/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1438/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1439/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1440/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 1441/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0097\n",
      "Epoch 1442/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1443/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1444/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1445/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1446/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1447/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 1448/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1449/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1450/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 1451/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1452/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1453/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1454/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1455/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1456/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 1457/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 1458/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0100\n",
      "Epoch 1459/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1460/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 1461/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1462/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1463/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1464/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0105\n",
      "Epoch 1465/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1466/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 1467/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1468/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0096\n",
      "Epoch 1469/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1470/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1471/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1472/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1473/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1474/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1475/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1476/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 1477/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1478/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1479/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 1480/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 1481/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0096\n",
      "Epoch 1482/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1483/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 1484/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1485/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 1486/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1487/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1488/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 1489/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 1490/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 1491/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1492/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1493/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1494/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 1495/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1496/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1497/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1498/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1499/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1500/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1501/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1502/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 1503/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0107\n",
      "Epoch 1504/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1505/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1506/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0097\n",
      "Epoch 1507/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 1508/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1509/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1510/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 1511/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 1512/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1513/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1514/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 1515/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1516/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1517/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1518/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1519/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 1520/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1521/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 1522/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0097\n",
      "Epoch 1523/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1524/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1525/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1526/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1527/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 1528/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1529/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1530/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 1531/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1532/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 1533/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0097\n",
      "Epoch 1534/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1535/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1536/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 1537/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1538/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0095\n",
      "Epoch 1539/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1540/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1541/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 1542/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0099\n",
      "Epoch 1543/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1544/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1545/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0105\n",
      "Epoch 1546/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1547/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1548/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 1549/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 1550/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1551/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1552/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 1553/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1554/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 1555/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 1556/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 1557/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1558/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1559/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1560/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 1561/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 1562/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 1563/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1564/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1565/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1566/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 1567/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 1568/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 1569/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 1570/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1571/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1572/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1573/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 1574/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 1575/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1576/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1577/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1578/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 1579/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 1580/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0100\n",
      "Epoch 1581/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0103\n",
      "Epoch 1582/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1583/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1584/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1585/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1586/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1587/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1588/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0103\n",
      "Epoch 1589/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1590/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 1591/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 1592/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1593/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1594/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1595/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1596/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 1597/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1598/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1599/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1600/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1601/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1602/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 1603/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1604/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 1605/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1606/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1607/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 1608/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0096\n",
      "Epoch 1609/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1610/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 1611/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 1612/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1613/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1614/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0094\n",
      "Epoch 1615/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 1616/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1617/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1618/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1619/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1620/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1621/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 1622/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1623/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 1624/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1625/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1626/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 1627/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 1628/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 1629/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0102\n",
      "Epoch 1630/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1631/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1632/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1633/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1634/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1635/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1636/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 1637/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 1638/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0095\n",
      "Epoch 1639/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1640/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1641/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1642/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1643/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0096\n",
      "Epoch 1644/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1645/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1646/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0105\n",
      "Epoch 1647/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 1648/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1649/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1650/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1651/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1652/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1653/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1654/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 1655/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1656/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1657/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1658/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1659/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 1660/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1661/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0095\n",
      "Epoch 1662/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1663/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1664/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1665/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1666/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1667/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1668/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 1669/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 1670/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1671/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1672/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1673/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1674/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1675/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0101\n",
      "Epoch 1676/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1677/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1678/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0096\n",
      "Epoch 1679/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1680/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 1681/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0096\n",
      "Epoch 1682/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1683/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 1684/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1685/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1686/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 1687/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 1688/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0098\n",
      "Epoch 1689/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1690/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1691/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1692/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1693/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1694/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0096\n",
      "Epoch 1695/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1696/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 1697/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0105\n",
      "Epoch 1698/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0104\n",
      "Epoch 1699/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0098\n",
      "Epoch 1700/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0103\n",
      "Epoch 1701/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 1702/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 1703/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1704/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1705/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1706/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1707/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1708/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1709/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 1710/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0103\n",
      "Epoch 1711/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0104\n",
      "Epoch 1712/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1713/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1714/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1715/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1716/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 1717/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1718/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1719/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1720/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 1721/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1722/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1723/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1724/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1725/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1726/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0096\n",
      "Epoch 1727/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1728/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1729/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1730/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1731/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 1732/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1733/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 1734/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 1735/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1736/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 1737/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1738/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1739/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1740/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 1741/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1742/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1743/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 1744/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1745/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 1746/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1747/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 1748/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 1749/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0102\n",
      "Epoch 1750/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1751/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1752/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 1753/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0095\n",
      "Epoch 1754/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1755/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 1756/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1757/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1758/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1759/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1760/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1761/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 1762/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 1763/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1764/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1765/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1766/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 1767/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1768/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0097\n",
      "Epoch 1769/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 1770/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0102\n",
      "Epoch 1771/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1772/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 1773/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1774/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0103\n",
      "Epoch 1775/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1776/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1777/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0101\n",
      "Epoch 1778/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1779/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1780/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1781/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1782/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1783/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0095\n",
      "Epoch 1784/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0098\n",
      "Epoch 1785/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1786/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 1787/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1788/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1789/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1790/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1791/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 1792/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1793/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0096\n",
      "Epoch 1794/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0097\n",
      "Epoch 1795/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1796/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1797/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1798/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 1799/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0099\n",
      "Epoch 1800/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0101\n",
      "Epoch 1801/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1802/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1803/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1804/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 1805/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 1806/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1807/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1808/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1809/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 1810/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1811/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1812/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1813/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1814/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1815/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1816/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1817/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 1818/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 1819/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1820/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 1821/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 1822/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1823/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0105\n",
      "Epoch 1824/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1825/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 1826/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1827/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 1828/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 1829/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 1830/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1831/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 1832/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1833/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1834/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 1835/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1836/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0102\n",
      "Epoch 1837/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1838/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 1839/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1840/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1841/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1842/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1843/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1844/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1845/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1846/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 1847/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1848/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1849/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1850/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 1851/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1852/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1853/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 1854/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 1855/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1856/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1857/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0098\n",
      "Epoch 1858/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1859/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 1860/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 1861/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 1862/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 1863/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 1864/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1865/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 1866/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 1867/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0102\n",
      "Epoch 1868/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1869/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0102\n",
      "Epoch 1870/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1871/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 1872/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1873/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1874/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0100\n",
      "Epoch 1875/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0100\n",
      "Epoch 1876/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1877/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 1878/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1879/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1880/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0105\n",
      "Epoch 1881/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1882/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1883/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1884/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 1885/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 1886/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1887/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0104\n",
      "Epoch 1888/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1889/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1890/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 1891/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1892/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 1893/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 1894/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 1895/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 1896/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1897/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1898/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 1899/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 1900/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0102\n",
      "Epoch 1901/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0101\n",
      "Epoch 1902/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1903/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 1904/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 1905/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 1906/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 1907/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0098\n",
      "Epoch 1908/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 1909/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1910/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0103\n",
      "Epoch 1911/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1912/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0098\n",
      "Epoch 1913/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1914/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1915/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1916/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0101\n",
      "Epoch 1917/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 1918/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 1919/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0097\n",
      "Epoch 1920/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 1921/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1922/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1923/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1924/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1925/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1926/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1927/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1928/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1929/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1930/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 1931/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1932/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 1933/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0103\n",
      "Epoch 1934/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1935/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0101\n",
      "Epoch 1936/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 1937/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1938/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0094\n",
      "Epoch 1939/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 1940/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 1941/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 1942/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 1943/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1944/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1945/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1946/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1947/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 1948/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 1949/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1950/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 1951/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 1952/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1953/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1954/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1955/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 1956/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 1957/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 1958/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 1959/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1960/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0098\n",
      "Epoch 1961/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1962/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1963/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1964/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0098\n",
      "Epoch 1965/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1966/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0102\n",
      "Epoch 1967/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1968/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0098\n",
      "Epoch 1969/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 1970/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0100\n",
      "Epoch 1971/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0097\n",
      "Epoch 1972/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0097\n",
      "Epoch 1973/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 1974/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 1975/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 1976/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1977/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 1978/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1979/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0098\n",
      "Epoch 1980/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1981/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 1982/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 0.0096\n",
      "Epoch 1983/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 1984/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0131 - val_loss: 0.0103\n",
      "Epoch 1985/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1986/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0132 - val_loss: 0.0100\n",
      "Epoch 1987/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 1988/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 1989/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 1990/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 1991/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 1992/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 1993/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 1994/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 1995/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0131 - val_loss: 0.0097\n",
      "Epoch 1996/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0095\n",
      "Epoch 1997/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0130 - val_loss: 0.0101\n",
      "Epoch 1998/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0133 - val_loss: 0.0098\n",
      "Epoch 1999/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 2000/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0101\n"
     ]
    }
   ],
   "source": [
    "# Set early stopping monitor so the model stops training when it won't improve anymore\n",
    "esm = EarlyStopping(monitor = 'loss', patience = 70)\n",
    "# Set the optimizer\n",
    "opt = tf.optimizers.SGD(learning_rate = 0.001)\n",
    "#design network\n",
    "batch_size = int(round(X_train.shape[0]*0.1))\n",
    "# fit network\n",
    "model.compile(loss='mae', optimizer=opt)\n",
    "history = model.fit(X_train, y_train, epochs=2000, batch_size= batch_size, verbose=1,\n",
    "    shuffle=False, validation_split=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)\n",
    "predict = [float(predict[i]) for i in range(len(predict))]\n",
    "pred = eu.scale_back_pct(predict, close_test)\n",
    "updown_pred = eu.ud_pred(pred, close_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.8465204957102002\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(updown_pred)\n",
    "df[\"Close\"] = list(close_test)\n",
    "df[\"updown_pred\"] = df.iloc[:,0]\n",
    "df[\"updown_actual\"] = eu.ud(close_test)\n",
    "df[\"Scaled_pred\"] = pred\n",
    "df[\"Pred\"] = predict\n",
    "df = df.iloc[:,1:] \n",
    "acc = (df[\"updown_pred\"] == df[\"updown_actual\"]).sum()/df.shape[0]\n",
    "print('Model Accuracy: ', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>updown_pred</th>\n",
       "      <th>updown_actual</th>\n",
       "      <th>Scaled_pred</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.559998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65.559998</td>\n",
       "      <td>-0.002615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.797211</td>\n",
       "      <td>-0.011635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.730003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64.293070</td>\n",
       "      <td>-0.003208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.800003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65.728251</td>\n",
       "      <td>0.015422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.449997</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66.104212</td>\n",
       "      <td>0.004623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>112.120003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106.614113</td>\n",
       "      <td>0.018282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>111.760002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114.061760</td>\n",
       "      <td>0.017319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>114.930000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113.756826</td>\n",
       "      <td>0.017867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>112.339996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114.221836</td>\n",
       "      <td>-0.006162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>113.900002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>113.464271</td>\n",
       "      <td>0.010008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1049 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Close  updown_pred  updown_actual  Scaled_pred      Pred\n",
       "0      65.559998            1              1    65.559998 -0.002615\n",
       "1      64.500000            0              0    64.797211 -0.011635\n",
       "2      64.730003            0              1    64.293070 -0.003208\n",
       "3      65.800003            1              1    65.728251  0.015422\n",
       "4      65.449997            1              0    66.104212  0.004623\n",
       "...          ...          ...            ...          ...       ...\n",
       "1044  112.120003            1              1   106.614113  0.018282\n",
       "1045  111.760002            1              0   114.061760  0.017319\n",
       "1046  114.930000            1              1   113.756826  0.017867\n",
       "1047  112.339996            0              0   114.221836 -0.006162\n",
       "1048  113.900002            1              1   113.464271  0.010008\n",
       "\n",
       "[1049 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['Scaled_pred'], label='pred')\n",
    "plt.plot(df[\"Close\"], label='Close')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "commission = 0.00\n",
    "def long_equity(prediction, close):\n",
    "    long = [close[0]]\n",
    "    for i in range(1,len(prediction)-1):\n",
    "        if prediction[i] == 1:\n",
    "            long.append(long[i-1] + close[i] - close[i-1] - close[i-1]*commission)\n",
    "        else:\n",
    "            long.append(long[i-1] + 0)\n",
    "    return long\n",
    "\n",
    "def short_equity(prediction, close):\n",
    "    short = [close[0]]\n",
    "    for i in range(1,len(prediction)-1):\n",
    "        if prediction[i] == 0:\n",
    "            short.append(short[i-1] + close[i-1] - close[i] - close[i-1]*commission)\n",
    "        else:\n",
    "            short.append(short[i-1] + 0)\n",
    "    return short  \n",
    "\n",
    "def total_equity(prediction, close):\n",
    "    total = [close[0]]\n",
    "    for i in range(1,len(prediction)-1):\n",
    "        if prediction[i] == 1:\n",
    "            total.append(total[i-1] + close[i] - close[i-1] - close[i-1]*commission)\n",
    "        else:\n",
    "            total.append(total[i-1] + close[i-1] - close[i] - close[i-1]*commission)\n",
    "    return total\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f7d7634940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_equity = pd.DataFrame()\n",
    "df_equity[\"long_equity\"] = eu.long_equity(df[\"updown_pred\"], df[\"Close\"])\n",
    "df_equity[\"short_equity\"] = eu.short_equity(df[\"updown_pred\"], df[\"Close\"])\n",
    "df_equity[\"total_equity\"] = eu.total_equity(df[\"updown_pred\"], df[\"Close\"])\n",
    "plt.plot(np.array(df_equity.index), df_equity[\"short_equity\"])\n",
    "# df_equity[\"short_equity\"].plot()\n",
    "df_equity[\"long_equity\"].plot()\n",
    "df_equity[\"total_equity\"].plot()\n",
    "df[\"Close\"].plot()\n",
    "# df[\"Pred\"].shift(-1).plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dates = pd.to_datetime(yahoo_df['Date'].iloc[n_val_days+1:].reset_index()['Date'])\n",
    "df_equity['percentage_total_return'] = eu.percentage_returns(df_equity['total_equity'])\n",
    "df_equity['percentage_long_return'] = eu.percentage_returns(df_equity['long_equity'])\n",
    "df_equity['percentage_short_return'] = eu.percentage_returns(df_equity['short_equity'])\n",
    "df_equity['percentage_total_return_for_dd'] = eu.percentage_returns_for_dd(df_equity['total_equity'])\n",
    "df_equity['percentage_long_return_for_dd'] = eu.percentage_returns_for_dd(df_equity['long_equity'])\n",
    "df_equity['percentage_short_return_for_dd'] = eu.percentage_returns_for_dd(df_equity['short_equity'])\n",
    "df_equity['updown_actual'] = df['updown_actual']\n",
    "df_equity[\"updown_pred\"] = df[\"updown_pred\"]\n",
    "plt.plot( df_equity['percentage_total_return'], label = 'Total Percentage Returns')\n",
    "plt.plot( df_equity['percentage_long_return'], label = 'Long Percentage Returns')\n",
    "plt.plot( df_equity['percentage_short_return'], label = 'Short Percentage Returns')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max drawdown:  16.075316368369897 %\n",
      "Average drwadown:  0.299829944179895 %\n",
      "Number of days a long position was held:  674\n",
      "Number of days a short position was held:  374\n"
     ]
    }
   ],
   "source": [
    "print('Max drawdown: ', eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[0], '%')  \n",
    "print('Average drwadown: ', eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[1], '%')\n",
    "print('Number of days a long position was held: ', eu.long_short_market_time(df_equity['updown_pred'])[0])       \n",
    "print('Number of days a short position was held: ', eu.long_short_market_time(df_equity['updown_pred'])[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trades:  375\n",
      "Average profit per trade:  4.070124084340735\n",
      "#####################\n",
      "### SHORT RESULTS ###\n",
      "#####################\n",
      "\n",
      "\n",
      "Number of short trades:  188\n",
      "Number of winning short trades:  76\n",
      "Win ratio:  0.40425531914893614\n",
      "Short trades average loss:  -0.22363662719726562\n",
      "Short trades average profit:  2.6422369982066907\n",
      "Short trades profit/loss ratio:  11.814866962181574\n",
      "Short trades best profit:  14.770002365112305\n",
      "Short trades worst loss:  -0.7900009155273438\n",
      "Short trades average % loss:  -0.11218075412430192 %\n",
      "Short trades average % profit:  1.24503925741307 %\n",
      "Short trades best % profit:  7.453608501403565 %\n",
      "Short trades worst % loss:  -0.345246733400397 %\n",
      "\n",
      "\n",
      "####################\n",
      "### LONG RESULTS ###\n",
      "#####################\n",
      "\n",
      "\n",
      "Number of long trades:  187\n",
      "Number of winning long trades:  122\n",
      "Win ratio:  0.6524064171122995\n",
      "Long trades average loss:  -0.6693336486816406\n",
      "Long trades average profit:  2.4257375529555025\n",
      "Long trades profit/loss ratio:  3.6241081824190067\n",
      "Long trades best profit:  27.979995727539062\n",
      "Long trades worst loss:  -3.5600013732910156\n",
      "Long trades average % loss:  -0.3504791944034046 %\n",
      "Long trades average % profit:  1.006603620245609 %\n",
      "Long trades best % profit:  6.779921249290079 %\n",
      "Long trades worst % loss:  -1.5201339195187273 %\n"
     ]
    }
   ],
   "source": [
    "total_short = eu.number_of_trades(df_equity['short_equity'],df_equity['updown_pred'])\n",
    "winning_short = eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[0]\n",
    "total_long = eu.number_of_trades(df_equity['long_equity'],df_equity['updown_pred'])\n",
    "winning_long = eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[0]\n",
    "\n",
    "print('Total number of trades: ', eu.number_of_trades(df_equity['total_equity'],df_equity['updown_pred']))\n",
    "print('Average profit per trade: ', df_equity['percentage_total_return'][len(df_equity)-1]/(total_short + total_long))\n",
    "\n",
    "print('#####################')\n",
    "print('### SHORT RESULTS ###')\n",
    "print('#####################')\n",
    "print('\\n')\n",
    "print('Number of short trades: ', eu.number_of_trades(df_equity['short_equity'],df_equity['updown_pred']))\n",
    "print('Number of winning short trades: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[0])\n",
    "print('Win ratio: ', winning_short/total_short)\n",
    "print('Short trades average loss: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[2])\n",
    "print('Short trades average profit: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[1])\n",
    "print('Short trades profit/loss ratio: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[3])\n",
    "print('Short trades best profit: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[4])\n",
    "print('Short trades worst loss: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[5])\n",
    "print('Short trades average % loss: ', eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[2], '%')\n",
    "print('Short trades average % profit: ', eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[1], '%')\n",
    "print('Short trades best % profit: ', eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[4], '%')\n",
    "print('Short trades worst % loss: ', eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[5], '%')\n",
    "\n",
    "print('\\n')\n",
    "print('####################')\n",
    "print('### LONG RESULTS ###')\n",
    "print('#####################')\n",
    "print('\\n')\n",
    "print('Number of long trades: ', eu.number_of_trades(df_equity['long_equity'],df_equity['updown_pred']))\n",
    "print('Number of winning long trades: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[0])\n",
    "print('Win ratio: ', winning_long/total_long)\n",
    "print('Long trades average loss: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[2])\n",
    "print('Long trades average profit: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[1])\n",
    "print('Long trades profit/loss ratio: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[3])\n",
    "print('Long trades best profit: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[4])\n",
    "print('Long trades worst loss: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[5])\n",
    "print('Long trades average % loss: ', eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[2], '%')\n",
    "print('Long trades average % profit: ',eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[1], '%')\n",
    "print('Long trades best % profit: ', eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[4], '%')\n",
    "print('Long trades worst % loss: ', eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[5], '%')\n",
    "# print('Totale trades average profit: ', number_of_trades(df_equity['total_equity'],df_equity['updown_pred'])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average compounded daily returns:  0.2664699031558637  %\n",
      "Average compounded annual returns:  96.06424868224106  %\n",
      "Max drawdown:  16.075316368369897 %\n",
      "Average drwadown:  0.299829944179895 %\n",
      "Total period return:  1526.2965316277757 %\n"
     ]
    }
   ],
   "source": [
    "daily_yield = ((1+df_equity['percentage_total_return'][len(df_equity)-1]/100)**(1/len(df_equity))-1)*100\n",
    "daily_yield\n",
    "annualized_yield = (((1+daily_yield/100)**253)-1)*100\n",
    "annualized_yield\n",
    "print('Average compounded daily returns: ', daily_yield, ' %')\n",
    "print('Average compounded annual returns: ', annualized_yield, ' %')\n",
    "print('Max drawdown: ', eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[0], '%')  \n",
    "print('Average drwadown: ', eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[1], '%')\n",
    "print('Total period return: ', df_equity['percentage_total_return'][len(df_equity)-1], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = pd.DataFrame({'Total (375 days) %': [df_equity['percentage_total_return'][len(df_equity)-1]],\n",
    "                       'Compounded Annual %' : [annualized_yield],\n",
    "                       'Compounded Daily %': [daily_yield]}, index = None)\n",
    "\n",
    "run_down = pd.DataFrame({'Maximum Drawdown %': [eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[0]],\n",
    "                       'Average Drawdown %' : [eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[1]]})\n",
    "\n",
    "efficiency_long = pd.DataFrame({'Average Win %': [eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[1]],\n",
    "                       'Average Loss %' : [eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[2]],\n",
    "                        'Time at market (days)' : [long_short_market_time(df_equity['updown_pred'])[0]]})\n",
    "\n",
    "efficiency_short = pd.DataFrame({'Average Win %': [eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[1]],\n",
    "                       'Average Loss %' : [eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[2]],\n",
    "                        'Time at market (days)' : [long_short_market_time(df_equity['updown_pred'])[1]]})\n",
    "\n",
    "# efficiency_total = pd.concat({\"Efficiency\": efficiency_long}, axis=1, names=[\"l1\", \"l2\"])\n",
    "\n",
    "trade_analysis_long = pd.DataFrame({'Total trades': [eu.number_of_trades(df_equity['long_equity'],df_equity['updown_pred'])],\n",
    "                                   'Positive': [eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[0]],\n",
    "                                   'Negative': [eu.number_of_trades(df_equity['long_equity'],df_equity['updown_pred'])-eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[0]],\n",
    "                                    'Positive trades %': [eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[0]/eu.number_of_trades(df_equity['long_equity'],df_equity['updown_pred'])*100],\n",
    "                                   'Best Profit %': [eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[4]],\n",
    "                                   'Worst Loss %': [eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[5]],\n",
    "                                   'Average Profit/Loss ratio': [eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[1]/eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[2]]})\n",
    "\n",
    "trade_analysis_short = pd.DataFrame({'Total trades': [eu.number_of_trades(df_equity['short_equity'],df_equity['updown_pred'])],\n",
    "                                   'Positive': [eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[0]],\n",
    "                                   'Negative': [eu.number_of_trades(df_equity['short_equity'],df_equity['updown_pred'])-eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[0]],\n",
    "                                    'Positive trades %': [eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[0]/eu.number_of_trades(df_equity['short_equity'],df_equity['updown_pred'])*100],\n",
    "                                   'Best Profit %': [eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[4]],\n",
    "                                   'Worst Loss %': [eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[5]],\n",
    "                                   'Average Profit/Loss ratio': [eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[1]/eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[2]]})\n",
    "\n",
    "efficiency_total = pd.concat({\"Long\" : efficiency_long, \"Short\" : efficiency_short})\n",
    "\n",
    "trade_analysis_total = pd.concat({\"Long\" : trade_analysis_long, \"Short\" : trade_analysis_short})\n",
    "                                \n",
    "final = pd.concat({\"Returns\" : returns,\"Run Down\": run_down,\"Efficiency long\": efficiency_long, \"Efficiency short\": efficiency_short, \"Trade Analysis Long\": trade_analysis_long, \"Trade Analysis Short\": trade_analysis_short}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('../data/Report_OIL.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_prediction = pd.read_csv(\"../data/model_accuracy_oil.csv\", index_col = False)\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_prediction[\"LSTM_price_accuracy\"] = [acc for x in range(len(df_prediction))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv(\"../data/model_accuracy_oil.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
