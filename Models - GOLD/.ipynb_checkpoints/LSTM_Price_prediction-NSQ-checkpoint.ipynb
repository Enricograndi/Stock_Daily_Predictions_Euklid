{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from package import euklid_regressor as eu\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_df = pd.read_csv('../data/NSQ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>SO</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>1 Day ROI</th>\n",
       "      <th>2 Day ROI</th>\n",
       "      <th>3 Day ROI</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>Previous_differenced</th>\n",
       "      <th>Differenced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1791.00</td>\n",
       "      <td>71.689895</td>\n",
       "      <td>21.862764</td>\n",
       "      <td>39.404226</td>\n",
       "      <td>47.783316</td>\n",
       "      <td>52.064839</td>\n",
       "      <td>-0.015393</td>\n",
       "      <td>-0.083184</td>\n",
       "      <td>-0.083184</td>\n",
       "      <td>14.845864</td>\n",
       "      <td>48.764418</td>\n",
       "      <td>-33.918554</td>\n",
       "      <td>-0.068851</td>\n",
       "      <td>-0.015393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1824.00</td>\n",
       "      <td>77.439024</td>\n",
       "      <td>49.007054</td>\n",
       "      <td>50.908448</td>\n",
       "      <td>54.563943</td>\n",
       "      <td>53.590307</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>-0.066291</td>\n",
       "      <td>19.312162</td>\n",
       "      <td>42.584572</td>\n",
       "      <td>-23.272411</td>\n",
       "      <td>-0.015393</td>\n",
       "      <td>0.018425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1774.00</td>\n",
       "      <td>63.103803</td>\n",
       "      <td>23.874383</td>\n",
       "      <td>35.563467</td>\n",
       "      <td>43.224632</td>\n",
       "      <td>50.957746</td>\n",
       "      <td>-0.027412</td>\n",
       "      <td>-0.009492</td>\n",
       "      <td>-0.024739</td>\n",
       "      <td>18.602712</td>\n",
       "      <td>33.500098</td>\n",
       "      <td>-14.897386</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>-0.027412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1823.00</td>\n",
       "      <td>73.175745</td>\n",
       "      <td>62.035182</td>\n",
       "      <td>55.348283</td>\n",
       "      <td>55.349391</td>\n",
       "      <td>53.363270</td>\n",
       "      <td>0.027621</td>\n",
       "      <td>-0.000548</td>\n",
       "      <td>0.017867</td>\n",
       "      <td>21.743711</td>\n",
       "      <td>29.312877</td>\n",
       "      <td>-7.569167</td>\n",
       "      <td>-0.027412</td>\n",
       "      <td>0.027621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1866.50</td>\n",
       "      <td>80.837004</td>\n",
       "      <td>79.913226</td>\n",
       "      <td>68.306695</td>\n",
       "      <td>64.358818</td>\n",
       "      <td>55.442106</td>\n",
       "      <td>0.023862</td>\n",
       "      <td>0.052142</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>27.426901</td>\n",
       "      <td>27.996854</td>\n",
       "      <td>-0.569953</td>\n",
       "      <td>0.027621</td>\n",
       "      <td>0.023862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>14654.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.741922</td>\n",
       "      <td>91.613859</td>\n",
       "      <td>85.112742</td>\n",
       "      <td>57.846042</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>0.039637</td>\n",
       "      <td>0.038425</td>\n",
       "      <td>-62.553224</td>\n",
       "      <td>155.357918</td>\n",
       "      <td>-217.911141</td>\n",
       "      <td>0.019524</td>\n",
       "      <td>0.019728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>14447.00</td>\n",
       "      <td>87.130867</td>\n",
       "      <td>53.329366</td>\n",
       "      <td>64.595899</td>\n",
       "      <td>66.791862</td>\n",
       "      <td>54.672003</td>\n",
       "      <td>-0.014126</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.024951</td>\n",
       "      <td>-21.673629</td>\n",
       "      <td>156.990010</td>\n",
       "      <td>-178.663639</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>-0.014126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>14763.75</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>80.477412</td>\n",
       "      <td>78.887258</td>\n",
       "      <td>76.925560</td>\n",
       "      <td>58.413145</td>\n",
       "      <td>0.021925</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.027365</td>\n",
       "      <td>35.869343</td>\n",
       "      <td>171.626385</td>\n",
       "      <td>-135.757043</td>\n",
       "      <td>-0.014126</td>\n",
       "      <td>0.021925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>14755.75</td>\n",
       "      <td>99.534410</td>\n",
       "      <td>78.180231</td>\n",
       "      <td>77.699029</td>\n",
       "      <td>76.143093</td>\n",
       "      <td>58.282974</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.021371</td>\n",
       "      <td>0.006943</td>\n",
       "      <td>79.905923</td>\n",
       "      <td>172.530373</td>\n",
       "      <td>-92.624449</td>\n",
       "      <td>0.021925</td>\n",
       "      <td>-0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>14985.25</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>91.727842</td>\n",
       "      <td>86.469111</td>\n",
       "      <td>82.825256</td>\n",
       "      <td>60.957224</td>\n",
       "      <td>0.015553</td>\n",
       "      <td>0.015003</td>\n",
       "      <td>0.037257</td>\n",
       "      <td>131.804602</td>\n",
       "      <td>179.543241</td>\n",
       "      <td>-47.738639</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.015553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5290 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Close          SO      RSI_1      RSI_2      RSI_3     RSI_14  \\\n",
       "0      1791.00   71.689895  21.862764  39.404226  47.783316  52.064839   \n",
       "1      1824.00   77.439024  49.007054  50.908448  54.563943  53.590307   \n",
       "2      1774.00   63.103803  23.874383  35.563467  43.224632  50.957746   \n",
       "3      1823.00   73.175745  62.035182  55.348283  55.349391  53.363270   \n",
       "4      1866.50   80.837004  79.913226  68.306695  64.358818  55.442106   \n",
       "...        ...         ...        ...        ...        ...        ...   \n",
       "5285  14654.00  100.000000  97.741922  91.613859  85.112742  57.846042   \n",
       "5286  14447.00   87.130867  53.329366  64.595899  66.791862  54.672003   \n",
       "5287  14763.75  100.000000  80.477412  78.887258  76.925560  58.413145   \n",
       "5288  14755.75   99.534410  78.180231  77.699029  76.143093  58.282974   \n",
       "5289  14985.25  100.000000  91.727842  86.469111  82.825256  60.957224   \n",
       "\n",
       "      1 Day ROI  2 Day ROI  3 Day ROI  MACD_12_26_9  MACDh_12_26_9  \\\n",
       "0     -0.015393  -0.083184  -0.083184     14.845864      48.764418   \n",
       "1      0.018425   0.002749  -0.066291     19.312162      42.584572   \n",
       "2     -0.027412  -0.009492  -0.024739     18.602712      33.500098   \n",
       "3      0.027621  -0.000548   0.017867     21.743711      29.312877   \n",
       "4      0.023862   0.052142   0.023300     27.426901      27.996854   \n",
       "...         ...        ...        ...           ...            ...   \n",
       "5285   0.019728   0.039637   0.038425    -62.553224     155.357918   \n",
       "5286  -0.014126   0.005323   0.024951    -21.673629     156.990010   \n",
       "5287   0.021925   0.007489   0.027365     35.869343     171.626385   \n",
       "5288  -0.000542   0.021371   0.006943     79.905923     172.530373   \n",
       "5289   0.015553   0.015003   0.037257    131.804602     179.543241   \n",
       "\n",
       "      MACDs_12_26_9  Previous_differenced  Differenced  \n",
       "0        -33.918554             -0.068851    -0.015393  \n",
       "1        -23.272411             -0.015393     0.018425  \n",
       "2        -14.897386              0.018425    -0.027412  \n",
       "3         -7.569167             -0.027412     0.027621  \n",
       "4         -0.569953              0.027621     0.023862  \n",
       "...             ...                   ...          ...  \n",
       "5285    -217.911141              0.019524     0.019728  \n",
       "5286    -178.663639              0.019728    -0.014126  \n",
       "5287    -135.757043             -0.014126     0.021925  \n",
       "5288     -92.624449              0.021925    -0.000542  \n",
       "5289     -47.738639             -0.000542     0.015553  \n",
       "\n",
       "[5290 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yahoo_df =yahoo_df[[\"Close\",'SO',\n",
    "                       'RSI_1', \n",
    "                    'RSI_2',\n",
    "                    'RSI_3',\n",
    "                    'RSI_14', \n",
    "                    '1 Day ROI', \n",
    "                    '2 Day ROI',\n",
    "                       '3 Day ROI', \n",
    "                    'MACD_12_26_9',\n",
    "                    'MACDh_12_26_9', \n",
    "                    'MACDs_12_26_9',\n",
    "                     \"Previous_differenced\",\n",
    "                    \"Differenced\"]]\n",
    "price = yahoo_df['Differenced'] \n",
    "close = yahoo_df['Close']\n",
    "yahoo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.7910000e+03,  7.1689896e+01,  2.1862764e+01, ...,\n",
       "        -3.3918552e+01, -6.8850778e-02, -1.5393073e-02],\n",
       "       [ 1.8240000e+03,  7.7439026e+01,  4.9007053e+01, ...,\n",
       "        -2.3272411e+01, -1.5393073e-02,  1.8425461e-02],\n",
       "       [ 1.7740000e+03,  6.3103802e+01,  2.3874382e+01, ...,\n",
       "        -1.4897387e+01,  1.8425461e-02, -2.7412280e-02],\n",
       "       ...,\n",
       "       [ 1.4763750e+04,  1.0000000e+02,  8.0477409e+01, ...,\n",
       "        -1.3575705e+02, -1.4125836e-02,  2.1924967e-02],\n",
       "       [ 1.4755750e+04,  9.9534409e+01,  7.8180229e+01, ...,\n",
       "        -9.2624451e+01,  2.1924967e-02, -5.4186775e-04],\n",
       "       [ 1.4985250e+04,  1.0000000e+02,  9.1727844e+01, ...,\n",
       "        -4.7738640e+01, -5.4186775e-04,  1.5553259e-02]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# convert series to supervised learning\n",
    "values = yahoo_df.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  yahoo_df[[  'SO',\n",
    "                       'RSI_1', 'RSI_2', 'RSI_3', 'RSI_14', '1 Day ROI', '2 Day ROI',\n",
    "                       '3 Day ROI', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9',\n",
    "                     \"Previous_differenced\",\n",
    "                    ]]\n",
    "\n",
    "y = yahoo_df[\"Differenced\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in 80/20 the dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.20,shuffle=False)\n",
    "close_train, close_test = train_test_split(close,test_size = 0.20, shuffle=False)\n",
    "\n",
    "close_train, close_test = list(close_train), list(close_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4232, 1, 12)\n",
      "(4232,)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(75, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(40))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "10/10 [==============================] - 5s 149ms/step - loss: 0.4228 - val_loss: 0.1957\n",
      "Epoch 2/2000\n",
      "10/10 [==============================] - 1s 86ms/step - loss: 0.3336 - val_loss: 0.1605\n",
      "Epoch 3/2000\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.2939 - val_loss: 0.1356\n",
      "Epoch 4/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.2786 - val_loss: 0.1299\n",
      "Epoch 5/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2640 - val_loss: 0.1175\n",
      "Epoch 6/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2671 - val_loss: 0.2592\n",
      "Epoch 7/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2942 - val_loss: 0.1198\n",
      "Epoch 8/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2604 - val_loss: 0.1108\n",
      "Epoch 9/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2565 - val_loss: 0.1051\n",
      "Epoch 10/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2512 - val_loss: 0.1048\n",
      "Epoch 11/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2536 - val_loss: 0.1053\n",
      "Epoch 12/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2490 - val_loss: 0.1014\n",
      "Epoch 13/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2360 - val_loss: 0.1032\n",
      "Epoch 14/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2509 - val_loss: 0.1035\n",
      "Epoch 15/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2463 - val_loss: 0.0978\n",
      "Epoch 16/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2382 - val_loss: 0.0977\n",
      "Epoch 17/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2345 - val_loss: 0.0975\n",
      "Epoch 18/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2342 - val_loss: 0.0971\n",
      "Epoch 19/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2302 - val_loss: 0.0948\n",
      "Epoch 20/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2317 - val_loss: 0.0943\n",
      "Epoch 21/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2270 - val_loss: 0.0938\n",
      "Epoch 22/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2311 - val_loss: 0.0968\n",
      "Epoch 23/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2274 - val_loss: 0.0902\n",
      "Epoch 24/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2206 - val_loss: 0.0898\n",
      "Epoch 25/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2238 - val_loss: 0.0896\n",
      "Epoch 26/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2237 - val_loss: 0.0906\n",
      "Epoch 27/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2141 - val_loss: 0.0856\n",
      "Epoch 28/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2121 - val_loss: 0.0876\n",
      "Epoch 29/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2176 - val_loss: 0.0869\n",
      "Epoch 30/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2109 - val_loss: 0.0829\n",
      "Epoch 31/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.2088 - val_loss: 0.0841\n",
      "Epoch 32/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2076 - val_loss: 0.0840\n",
      "Epoch 33/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2087 - val_loss: 0.0919\n",
      "Epoch 34/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2045 - val_loss: 0.0955\n",
      "Epoch 35/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2060 - val_loss: 0.0917\n",
      "Epoch 36/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.2069 - val_loss: 0.0817\n",
      "Epoch 37/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.2046 - val_loss: 0.0793\n",
      "Epoch 38/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2019 - val_loss: 0.0838\n",
      "Epoch 39/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1966 - val_loss: 0.0824\n",
      "Epoch 40/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1961 - val_loss: 0.0777\n",
      "Epoch 41/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.1939 - val_loss: 0.0743\n",
      "Epoch 42/2000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.1946 - val_loss: 0.0844\n",
      "Epoch 43/2000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1932 - val_loss: 0.0732\n",
      "Epoch 44/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1894 - val_loss: 0.0844\n",
      "Epoch 45/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.1908 - val_loss: 0.0854\n",
      "Epoch 46/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1912 - val_loss: 0.0837\n",
      "Epoch 47/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1903 - val_loss: 0.0842\n",
      "Epoch 48/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.1918 - val_loss: 0.0733\n",
      "Epoch 49/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1882 - val_loss: 0.0717\n",
      "Epoch 50/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1863 - val_loss: 0.0744\n",
      "Epoch 51/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1836 - val_loss: 0.0687\n",
      "Epoch 52/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1765 - val_loss: 0.0698\n",
      "Epoch 53/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1809 - val_loss: 0.0677\n",
      "Epoch 54/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1821 - val_loss: 0.0685\n",
      "Epoch 55/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1800 - val_loss: 0.0659\n",
      "Epoch 56/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1751 - val_loss: 0.0678\n",
      "Epoch 57/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1755 - val_loss: 0.0614\n",
      "Epoch 58/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1739 - val_loss: 0.0625\n",
      "Epoch 59/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1720 - val_loss: 0.0633\n",
      "Epoch 60/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1700 - val_loss: 0.0625\n",
      "Epoch 61/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1713 - val_loss: 0.0619\n",
      "Epoch 62/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1639 - val_loss: 0.0609\n",
      "Epoch 63/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1670 - val_loss: 0.0622\n",
      "Epoch 64/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1620 - val_loss: 0.0670\n",
      "Epoch 65/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1656 - val_loss: 0.0666\n",
      "Epoch 66/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1581 - val_loss: 0.0633\n",
      "Epoch 67/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1582 - val_loss: 0.0632\n",
      "Epoch 68/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1585 - val_loss: 0.0652\n",
      "Epoch 69/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1581 - val_loss: 0.0635\n",
      "Epoch 70/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1595 - val_loss: 0.0632\n",
      "Epoch 71/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1556 - val_loss: 0.0662\n",
      "Epoch 72/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1563 - val_loss: 0.0631\n",
      "Epoch 73/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1515 - val_loss: 0.0654\n",
      "Epoch 74/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1515 - val_loss: 0.0649\n",
      "Epoch 75/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1529 - val_loss: 0.0640\n",
      "Epoch 76/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1539 - val_loss: 0.0660\n",
      "Epoch 77/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1500 - val_loss: 0.0659\n",
      "Epoch 78/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1509 - val_loss: 0.0713\n",
      "Epoch 79/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1502 - val_loss: 0.0689\n",
      "Epoch 80/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1504 - val_loss: 0.0708\n",
      "Epoch 81/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1531 - val_loss: 0.0734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1517 - val_loss: 0.0657\n",
      "Epoch 83/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1494 - val_loss: 0.0652\n",
      "Epoch 84/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1465 - val_loss: 0.0579\n",
      "Epoch 85/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1448 - val_loss: 0.0560\n",
      "Epoch 86/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1440 - val_loss: 0.0566\n",
      "Epoch 87/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1434 - val_loss: 0.0584\n",
      "Epoch 88/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1423 - val_loss: 0.0583\n",
      "Epoch 89/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1420 - val_loss: 0.0633\n",
      "Epoch 90/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1383 - val_loss: 0.0602\n",
      "Epoch 91/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1389 - val_loss: 0.0557\n",
      "Epoch 92/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1388 - val_loss: 0.0568\n",
      "Epoch 93/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1351 - val_loss: 0.0574\n",
      "Epoch 94/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1349 - val_loss: 0.0592\n",
      "Epoch 95/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1360 - val_loss: 0.0630\n",
      "Epoch 96/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1359 - val_loss: 0.0590\n",
      "Epoch 97/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1343 - val_loss: 0.0598\n",
      "Epoch 98/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1352 - val_loss: 0.0579\n",
      "Epoch 99/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1302 - val_loss: 0.0536\n",
      "Epoch 100/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1340 - val_loss: 0.0558\n",
      "Epoch 101/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1299 - val_loss: 0.0587\n",
      "Epoch 102/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1288 - val_loss: 0.0556\n",
      "Epoch 103/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1315 - val_loss: 0.0570\n",
      "Epoch 104/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1261 - val_loss: 0.0562\n",
      "Epoch 105/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1243 - val_loss: 0.0558\n",
      "Epoch 106/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1267 - val_loss: 0.0574\n",
      "Epoch 107/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1268 - val_loss: 0.0542\n",
      "Epoch 108/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1216 - val_loss: 0.0536\n",
      "Epoch 109/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1217 - val_loss: 0.0551\n",
      "Epoch 110/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1217 - val_loss: 0.0535\n",
      "Epoch 111/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1173 - val_loss: 0.0524\n",
      "Epoch 112/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1196 - val_loss: 0.0534\n",
      "Epoch 113/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1167 - val_loss: 0.0507\n",
      "Epoch 114/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1176 - val_loss: 0.0498\n",
      "Epoch 115/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.1176 - val_loss: 0.0490\n",
      "Epoch 116/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1187 - val_loss: 0.0515\n",
      "Epoch 117/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1170 - val_loss: 0.0537\n",
      "Epoch 118/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1158 - val_loss: 0.0553\n",
      "Epoch 119/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1140 - val_loss: 0.0556\n",
      "Epoch 120/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1145 - val_loss: 0.0550\n",
      "Epoch 121/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1145 - val_loss: 0.0566\n",
      "Epoch 122/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1146 - val_loss: 0.0567\n",
      "Epoch 123/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1135 - val_loss: 0.0521\n",
      "Epoch 124/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1105 - val_loss: 0.0491\n",
      "Epoch 125/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1071 - val_loss: 0.0517\n",
      "Epoch 126/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1106 - val_loss: 0.0465\n",
      "Epoch 127/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1074 - val_loss: 0.0479\n",
      "Epoch 128/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1046 - val_loss: 0.0484\n",
      "Epoch 129/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1043 - val_loss: 0.0457\n",
      "Epoch 130/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1045 - val_loss: 0.0454\n",
      "Epoch 131/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.1034 - val_loss: 0.0460\n",
      "Epoch 132/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1038 - val_loss: 0.0475\n",
      "Epoch 133/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1030 - val_loss: 0.0492\n",
      "Epoch 134/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0996 - val_loss: 0.0468\n",
      "Epoch 135/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0989 - val_loss: 0.0483\n",
      "Epoch 136/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1003 - val_loss: 0.0476\n",
      "Epoch 137/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1007 - val_loss: 0.0490\n",
      "Epoch 138/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0975 - val_loss: 0.0525\n",
      "Epoch 139/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.1024 - val_loss: 0.0464\n",
      "Epoch 140/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0973 - val_loss: 0.0440\n",
      "Epoch 141/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0968 - val_loss: 0.0420\n",
      "Epoch 142/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0962 - val_loss: 0.0443\n",
      "Epoch 143/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0944 - val_loss: 0.0419\n",
      "Epoch 144/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0941 - val_loss: 0.0439\n",
      "Epoch 145/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0907 - val_loss: 0.0447\n",
      "Epoch 146/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0926 - val_loss: 0.0422\n",
      "Epoch 147/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0892 - val_loss: 0.0441\n",
      "Epoch 148/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0912 - val_loss: 0.0416\n",
      "Epoch 149/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0904 - val_loss: 0.0445\n",
      "Epoch 150/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0899 - val_loss: 0.0410\n",
      "Epoch 151/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0877 - val_loss: 0.0431\n",
      "Epoch 152/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0870 - val_loss: 0.0403\n",
      "Epoch 153/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0855 - val_loss: 0.0438\n",
      "Epoch 154/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0877 - val_loss: 0.0401\n",
      "Epoch 155/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0845 - val_loss: 0.0412\n",
      "Epoch 156/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0823 - val_loss: 0.0387\n",
      "Epoch 157/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0855 - val_loss: 0.0403\n",
      "Epoch 158/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0822 - val_loss: 0.0393\n",
      "Epoch 159/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0814 - val_loss: 0.0401\n",
      "Epoch 160/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0816 - val_loss: 0.0386\n",
      "Epoch 161/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0806 - val_loss: 0.0402\n",
      "Epoch 162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0797 - val_loss: 0.0429\n",
      "Epoch 163/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0798 - val_loss: 0.0380\n",
      "Epoch 164/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0784 - val_loss: 0.0371\n",
      "Epoch 165/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0780 - val_loss: 0.0382\n",
      "Epoch 166/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0783 - val_loss: 0.0393\n",
      "Epoch 167/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0773 - val_loss: 0.0417\n",
      "Epoch 168/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0742 - val_loss: 0.0373\n",
      "Epoch 169/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0766 - val_loss: 0.0378\n",
      "Epoch 170/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0746 - val_loss: 0.0394\n",
      "Epoch 171/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0747 - val_loss: 0.0398\n",
      "Epoch 172/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0757 - val_loss: 0.0469\n",
      "Epoch 173/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0736 - val_loss: 0.0382\n",
      "Epoch 174/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0729 - val_loss: 0.0361\n",
      "Epoch 175/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0729 - val_loss: 0.0357\n",
      "Epoch 176/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0702 - val_loss: 0.0345\n",
      "Epoch 177/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0706 - val_loss: 0.0393\n",
      "Epoch 178/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0716 - val_loss: 0.0359\n",
      "Epoch 179/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0695 - val_loss: 0.0388\n",
      "Epoch 180/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0675 - val_loss: 0.0411\n",
      "Epoch 181/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0709 - val_loss: 0.0392\n",
      "Epoch 182/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0673 - val_loss: 0.0388\n",
      "Epoch 183/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0672 - val_loss: 0.0384\n",
      "Epoch 184/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0679 - val_loss: 0.0354\n",
      "Epoch 185/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0662 - val_loss: 0.0336\n",
      "Epoch 186/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0646 - val_loss: 0.0340\n",
      "Epoch 187/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0649 - val_loss: 0.0335\n",
      "Epoch 188/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0630 - val_loss: 0.0322\n",
      "Epoch 189/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0624 - val_loss: 0.0336\n",
      "Epoch 190/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0633 - val_loss: 0.0321\n",
      "Epoch 191/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0609 - val_loss: 0.0363\n",
      "Epoch 192/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0604 - val_loss: 0.0310\n",
      "Epoch 193/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0604 - val_loss: 0.0317\n",
      "Epoch 194/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0607 - val_loss: 0.0315\n",
      "Epoch 195/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0590 - val_loss: 0.0317\n",
      "Epoch 196/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0618 - val_loss: 0.0336\n",
      "Epoch 197/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0562 - val_loss: 0.0303\n",
      "Epoch 198/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0568 - val_loss: 0.0316\n",
      "Epoch 199/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0562 - val_loss: 0.0307\n",
      "Epoch 200/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0551 - val_loss: 0.0311\n",
      "Epoch 201/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0562 - val_loss: 0.0297\n",
      "Epoch 202/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0532 - val_loss: 0.0313\n",
      "Epoch 203/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0537 - val_loss: 0.0289\n",
      "Epoch 204/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0551 - val_loss: 0.0296\n",
      "Epoch 205/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0546 - val_loss: 0.0300\n",
      "Epoch 206/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0529 - val_loss: 0.0294\n",
      "Epoch 207/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0514 - val_loss: 0.0306\n",
      "Epoch 208/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0505 - val_loss: 0.0288\n",
      "Epoch 209/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0491 - val_loss: 0.0290\n",
      "Epoch 210/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0500 - val_loss: 0.0298\n",
      "Epoch 211/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0499 - val_loss: 0.0278\n",
      "Epoch 212/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0510 - val_loss: 0.0279\n",
      "Epoch 213/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0476 - val_loss: 0.0273\n",
      "Epoch 214/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0472 - val_loss: 0.0277\n",
      "Epoch 215/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0461 - val_loss: 0.0273\n",
      "Epoch 216/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0475 - val_loss: 0.0283\n",
      "Epoch 217/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0469 - val_loss: 0.0266\n",
      "Epoch 218/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0443 - val_loss: 0.0267\n",
      "Epoch 219/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0471 - val_loss: 0.0282\n",
      "Epoch 220/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0475 - val_loss: 0.0298\n",
      "Epoch 221/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0452 - val_loss: 0.0261\n",
      "Epoch 222/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0446 - val_loss: 0.0263\n",
      "Epoch 223/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0431 - val_loss: 0.0262\n",
      "Epoch 224/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0431 - val_loss: 0.0260\n",
      "Epoch 225/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0406 - val_loss: 0.0258\n",
      "Epoch 226/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0433 - val_loss: 0.0278\n",
      "Epoch 227/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0422 - val_loss: 0.0253\n",
      "Epoch 228/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0427 - val_loss: 0.0246\n",
      "Epoch 229/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0424 - val_loss: 0.0250\n",
      "Epoch 230/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0416 - val_loss: 0.0244\n",
      "Epoch 231/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0390 - val_loss: 0.0260\n",
      "Epoch 232/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0395 - val_loss: 0.0244\n",
      "Epoch 233/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0400 - val_loss: 0.0253\n",
      "Epoch 234/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0395 - val_loss: 0.0242\n",
      "Epoch 235/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0380 - val_loss: 0.0246\n",
      "Epoch 236/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0387 - val_loss: 0.0239\n",
      "Epoch 237/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0375 - val_loss: 0.0235\n",
      "Epoch 238/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0359 - val_loss: 0.0242\n",
      "Epoch 239/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0376 - val_loss: 0.0235\n",
      "Epoch 240/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0352 - val_loss: 0.0227\n",
      "Epoch 241/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0369 - val_loss: 0.0237\n",
      "Epoch 242/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0352 - val_loss: 0.0223\n",
      "Epoch 243/2000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0336 - val_loss: 0.0221\n",
      "Epoch 244/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0342 - val_loss: 0.0238\n",
      "Epoch 245/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0336 - val_loss: 0.0220\n",
      "Epoch 246/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0331 - val_loss: 0.0222\n",
      "Epoch 247/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0328 - val_loss: 0.0214\n",
      "Epoch 248/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0333 - val_loss: 0.0223\n",
      "Epoch 249/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0311 - val_loss: 0.0212\n",
      "Epoch 250/2000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0318 - val_loss: 0.0209\n",
      "Epoch 251/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0300 - val_loss: 0.0213\n",
      "Epoch 252/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0302 - val_loss: 0.0209\n",
      "Epoch 253/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0312 - val_loss: 0.0206\n",
      "Epoch 254/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0302 - val_loss: 0.0206\n",
      "Epoch 255/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0305 - val_loss: 0.0201\n",
      "Epoch 256/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0306 - val_loss: 0.0201\n",
      "Epoch 257/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0299 - val_loss: 0.0216\n",
      "Epoch 258/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0285 - val_loss: 0.0199\n",
      "Epoch 259/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0285 - val_loss: 0.0195\n",
      "Epoch 260/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0289 - val_loss: 0.0215\n",
      "Epoch 261/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0266 - val_loss: 0.0208\n",
      "Epoch 262/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0278 - val_loss: 0.0202\n",
      "Epoch 263/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0187\n",
      "Epoch 264/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0263 - val_loss: 0.0189\n",
      "Epoch 265/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0276 - val_loss: 0.0191\n",
      "Epoch 266/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0271 - val_loss: 0.0181\n",
      "Epoch 267/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 0.0189\n",
      "Epoch 268/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0182\n",
      "Epoch 269/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0256 - val_loss: 0.0177\n",
      "Epoch 270/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0265 - val_loss: 0.0203\n",
      "Epoch 271/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0254 - val_loss: 0.0185\n",
      "Epoch 272/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0244 - val_loss: 0.0189\n",
      "Epoch 273/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0248 - val_loss: 0.0171\n",
      "Epoch 274/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0243 - val_loss: 0.0171\n",
      "Epoch 275/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0245 - val_loss: 0.0168\n",
      "Epoch 276/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0243 - val_loss: 0.0172\n",
      "Epoch 277/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0238 - val_loss: 0.0169\n",
      "Epoch 278/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0236 - val_loss: 0.0176\n",
      "Epoch 279/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0233 - val_loss: 0.0167\n",
      "Epoch 280/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0234 - val_loss: 0.0175\n",
      "Epoch 281/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0234 - val_loss: 0.0162\n",
      "Epoch 282/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0232 - val_loss: 0.0175\n",
      "Epoch 283/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0228 - val_loss: 0.0172\n",
      "Epoch 284/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.0167\n",
      "Epoch 285/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0227 - val_loss: 0.0161\n",
      "Epoch 286/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0219 - val_loss: 0.0158\n",
      "Epoch 287/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0168\n",
      "Epoch 288/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0219 - val_loss: 0.0155\n",
      "Epoch 289/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0215 - val_loss: 0.0170\n",
      "Epoch 290/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0209 - val_loss: 0.0152\n",
      "Epoch 291/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0165\n",
      "Epoch 292/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0211 - val_loss: 0.0152\n",
      "Epoch 293/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.0165\n",
      "Epoch 294/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0207 - val_loss: 0.0149\n",
      "Epoch 295/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0203 - val_loss: 0.0152\n",
      "Epoch 296/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 0.0163\n",
      "Epoch 297/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0204 - val_loss: 0.0158\n",
      "Epoch 298/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0205 - val_loss: 0.0151\n",
      "Epoch 299/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0204 - val_loss: 0.0146\n",
      "Epoch 300/2000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0197 - val_loss: 0.0155\n",
      "Epoch 301/2000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0198 - val_loss: 0.0145\n",
      "Epoch 302/2000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0197 - val_loss: 0.0154\n",
      "Epoch 303/2000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0204 - val_loss: 0.0147\n",
      "Epoch 304/2000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0195 - val_loss: 0.0140\n",
      "Epoch 305/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0197 - val_loss: 0.0151\n",
      "Epoch 306/2000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0194 - val_loss: 0.0142\n",
      "Epoch 307/2000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0195 - val_loss: 0.0140\n",
      "Epoch 308/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0147\n",
      "Epoch 309/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0191 - val_loss: 0.0142\n",
      "Epoch 310/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0191 - val_loss: 0.0136\n",
      "Epoch 311/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0197 - val_loss: 0.0145\n",
      "Epoch 312/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0138\n",
      "Epoch 313/2000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0192 - val_loss: 0.0138\n",
      "Epoch 314/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0190 - val_loss: 0.0146\n",
      "Epoch 315/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0181 - val_loss: 0.0142\n",
      "Epoch 316/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0185 - val_loss: 0.0135\n",
      "Epoch 317/2000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0184 - val_loss: 0.0142\n",
      "Epoch 318/2000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0186 - val_loss: 0.0129\n",
      "Epoch 319/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0185 - val_loss: 0.0138\n",
      "Epoch 320/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0181 - val_loss: 0.0133\n",
      "Epoch 321/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0182 - val_loss: 0.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0182 - val_loss: 0.0135\n",
      "Epoch 323/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0179 - val_loss: 0.0135\n",
      "Epoch 324/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0183 - val_loss: 0.0133\n",
      "Epoch 325/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0178 - val_loss: 0.0124\n",
      "Epoch 326/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0177 - val_loss: 0.0133\n",
      "Epoch 327/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0175 - val_loss: 0.0124\n",
      "Epoch 328/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0177 - val_loss: 0.0131\n",
      "Epoch 329/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0184 - val_loss: 0.0126\n",
      "Epoch 330/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0182 - val_loss: 0.0127\n",
      "Epoch 331/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0181 - val_loss: 0.0133\n",
      "Epoch 332/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0174 - val_loss: 0.0131\n",
      "Epoch 333/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0175 - val_loss: 0.0132\n",
      "Epoch 334/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0174 - val_loss: 0.0122\n",
      "Epoch 335/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0174 - val_loss: 0.0122\n",
      "Epoch 336/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0172 - val_loss: 0.0131\n",
      "Epoch 337/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0170 - val_loss: 0.0119\n",
      "Epoch 338/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0173 - val_loss: 0.0121\n",
      "Epoch 339/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0169 - val_loss: 0.0120\n",
      "Epoch 340/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0171 - val_loss: 0.0124\n",
      "Epoch 341/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0172 - val_loss: 0.0124\n",
      "Epoch 342/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0170 - val_loss: 0.0131\n",
      "Epoch 343/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0168 - val_loss: 0.0130\n",
      "Epoch 344/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0173 - val_loss: 0.0120\n",
      "Epoch 345/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0161 - val_loss: 0.0127\n",
      "Epoch 346/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0168 - val_loss: 0.0113\n",
      "Epoch 347/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0167 - val_loss: 0.0127\n",
      "Epoch 348/2000\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0167 - val_loss: 0.0119\n",
      "Epoch 349/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0165 - val_loss: 0.0111\n",
      "Epoch 350/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0166 - val_loss: 0.0121\n",
      "Epoch 351/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0163 - val_loss: 0.0109\n",
      "Epoch 352/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0161 - val_loss: 0.0125\n",
      "Epoch 353/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0168 - val_loss: 0.0114\n",
      "Epoch 354/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0161 - val_loss: 0.0130\n",
      "Epoch 355/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0164 - val_loss: 0.0111\n",
      "Epoch 356/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0165 - val_loss: 0.0124\n",
      "Epoch 357/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0168 - val_loss: 0.0111\n",
      "Epoch 358/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0161 - val_loss: 0.0114\n",
      "Epoch 359/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0157 - val_loss: 0.0115\n",
      "Epoch 360/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0163 - val_loss: 0.0110\n",
      "Epoch 361/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0164 - val_loss: 0.0111\n",
      "Epoch 362/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0164 - val_loss: 0.0118\n",
      "Epoch 363/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0164 - val_loss: 0.0110\n",
      "Epoch 364/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 365/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 366/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0162 - val_loss: 0.0107\n",
      "Epoch 367/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0159 - val_loss: 0.0107\n",
      "Epoch 368/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0157 - val_loss: 0.0104\n",
      "Epoch 369/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0156 - val_loss: 0.0114\n",
      "Epoch 370/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0159 - val_loss: 0.0114\n",
      "Epoch 371/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 372/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0158 - val_loss: 0.0111\n",
      "Epoch 373/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0160 - val_loss: 0.0102\n",
      "Epoch 374/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 375/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0154 - val_loss: 0.0112\n",
      "Epoch 376/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 377/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0152 - val_loss: 0.0111\n",
      "Epoch 378/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0156 - val_loss: 0.0109\n",
      "Epoch 379/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0150 - val_loss: 0.0106\n",
      "Epoch 380/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0150 - val_loss: 0.0109\n",
      "Epoch 381/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0152 - val_loss: 0.0107\n",
      "Epoch 382/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 383/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0154 - val_loss: 0.0101\n",
      "Epoch 384/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0150 - val_loss: 0.0102\n",
      "Epoch 385/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0147 - val_loss: 0.0112\n",
      "Epoch 386/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0150 - val_loss: 0.0099\n",
      "Epoch 387/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0151 - val_loss: 0.0103\n",
      "Epoch 388/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0150 - val_loss: 0.0106\n",
      "Epoch 389/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0151 - val_loss: 0.0097\n",
      "Epoch 390/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0149 - val_loss: 0.0107\n",
      "Epoch 391/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0153 - val_loss: 0.0113\n",
      "Epoch 392/2000\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0149 - val_loss: 0.0101\n",
      "Epoch 393/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0151 - val_loss: 0.0099\n",
      "Epoch 394/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0152 - val_loss: 0.0103\n",
      "Epoch 395/2000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0151 - val_loss: 0.0113\n",
      "Epoch 396/2000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0151 - val_loss: 0.0100\n",
      "Epoch 397/2000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 398/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0151 - val_loss: 0.0095\n",
      "Epoch 399/2000\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.0145 - val_loss: 0.0099\n",
      "Epoch 400/2000\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 401/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0148 - val_loss: 0.0106\n",
      "Epoch 402/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0151 - val_loss: 0.0095\n",
      "Epoch 403/2000\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0150 - val_loss: 0.0098\n",
      "Epoch 404/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0150 - val_loss: 0.0099\n",
      "Epoch 405/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0147 - val_loss: 0.0095\n",
      "Epoch 406/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0147 - val_loss: 0.0102\n",
      "Epoch 407/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0147 - val_loss: 0.0106\n",
      "Epoch 408/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0147 - val_loss: 0.0096\n",
      "Epoch 409/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0147 - val_loss: 0.0094\n",
      "Epoch 410/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0147 - val_loss: 0.0104\n",
      "Epoch 411/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0144 - val_loss: 0.0098\n",
      "Epoch 412/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0147 - val_loss: 0.0096\n",
      "Epoch 413/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0148 - val_loss: 0.0097\n",
      "Epoch 414/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0143 - val_loss: 0.0092\n",
      "Epoch 415/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0143 - val_loss: 0.0101\n",
      "Epoch 416/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0142 - val_loss: 0.0106\n",
      "Epoch 417/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 418/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0147 - val_loss: 0.0099\n",
      "Epoch 419/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 420/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0148 - val_loss: 0.0110\n",
      "Epoch 421/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 422/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0147 - val_loss: 0.0096\n",
      "Epoch 423/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 424/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0145 - val_loss: 0.0096\n",
      "Epoch 425/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0142 - val_loss: 0.0088\n",
      "Epoch 426/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0144 - val_loss: 0.0090\n",
      "Epoch 427/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0141 - val_loss: 0.0099\n",
      "Epoch 428/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0141 - val_loss: 0.0102\n",
      "Epoch 429/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0136 - val_loss: 0.0086\n",
      "Epoch 430/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0138 - val_loss: 0.0083\n",
      "Epoch 431/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0136 - val_loss: 0.0099\n",
      "Epoch 432/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0142 - val_loss: 0.0089\n",
      "Epoch 433/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0138 - val_loss: 0.0089\n",
      "Epoch 434/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0140 - val_loss: 0.0089\n",
      "Epoch 435/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0136 - val_loss: 0.0095\n",
      "Epoch 436/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0137 - val_loss: 0.0091\n",
      "Epoch 437/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0143 - val_loss: 0.0086\n",
      "Epoch 438/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0133 - val_loss: 0.0093\n",
      "Epoch 439/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0140 - val_loss: 0.0086\n",
      "Epoch 440/2000\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0135 - val_loss: 0.0092\n",
      "Epoch 441/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0136 - val_loss: 0.0088\n",
      "Epoch 442/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0136 - val_loss: 0.0092\n",
      "Epoch 443/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0143 - val_loss: 0.0090\n",
      "Epoch 444/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0138 - val_loss: 0.0092\n",
      "Epoch 445/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0140 - val_loss: 0.0091\n",
      "Epoch 446/2000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0135 - val_loss: 0.0094\n",
      "Epoch 447/2000\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0140 - val_loss: 0.0089\n",
      "Epoch 448/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0142 - val_loss: 0.0090\n",
      "Epoch 449/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0138 - val_loss: 0.0087\n",
      "Epoch 450/2000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0140 - val_loss: 0.0090\n",
      "Epoch 451/2000\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.0135 - val_loss: 0.0091\n",
      "Epoch 452/2000\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.0135 - val_loss: 0.0087\n",
      "Epoch 453/2000\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0135 - val_loss: 0.0093\n",
      "Epoch 454/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0143 - val_loss: 0.0087\n",
      "Epoch 455/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0135 - val_loss: 0.0089\n",
      "Epoch 456/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0137 - val_loss: 0.0080\n",
      "Epoch 457/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0136 - val_loss: 0.0092\n",
      "Epoch 458/2000\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.0138 - val_loss: 0.0088\n",
      "Epoch 459/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0135 - val_loss: 0.0087\n",
      "Epoch 460/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0131 - val_loss: 0.0093\n",
      "Epoch 461/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0134 - val_loss: 0.0089\n",
      "Epoch 462/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0136 - val_loss: 0.0089\n",
      "Epoch 463/2000\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.0135 - val_loss: 0.0079\n",
      "Epoch 464/2000\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.0133 - val_loss: 0.0080\n",
      "Epoch 465/2000\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0133 - val_loss: 0.0090\n",
      "Epoch 466/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0132 - val_loss: 0.0086\n",
      "Epoch 467/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0137 - val_loss: 0.0082\n",
      "Epoch 468/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0136 - val_loss: 0.0091\n",
      "Epoch 469/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0134 - val_loss: 0.0085\n",
      "Epoch 470/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0134 - val_loss: 0.0096\n",
      "Epoch 471/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0135 - val_loss: 0.0085\n",
      "Epoch 472/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0135 - val_loss: 0.0086\n",
      "Epoch 473/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0135 - val_loss: 0.0082\n",
      "Epoch 474/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0132 - val_loss: 0.0086\n",
      "Epoch 475/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0137 - val_loss: 0.0083\n",
      "Epoch 476/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0132 - val_loss: 0.0087\n",
      "Epoch 477/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0132 - val_loss: 0.0081\n",
      "Epoch 478/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0132 - val_loss: 0.0087\n",
      "Epoch 479/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0130 - val_loss: 0.0087\n",
      "Epoch 480/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0134 - val_loss: 0.0083\n",
      "Epoch 481/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0132 - val_loss: 0.0094\n",
      "Epoch 482/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0135 - val_loss: 0.0085\n",
      "Epoch 483/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0136 - val_loss: 0.0085\n",
      "Epoch 484/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0129 - val_loss: 0.0082\n",
      "Epoch 485/2000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0133 - val_loss: 0.0088\n",
      "Epoch 486/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0134 - val_loss: 0.0082\n",
      "Epoch 487/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0077\n",
      "Epoch 488/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0083\n",
      "Epoch 489/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0085\n",
      "Epoch 490/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0081\n",
      "Epoch 491/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0081\n",
      "Epoch 492/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 493/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0087\n",
      "Epoch 494/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0084\n",
      "Epoch 495/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0086\n",
      "Epoch 496/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0086\n",
      "Epoch 497/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0082\n",
      "Epoch 498/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0079\n",
      "Epoch 499/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 500/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0077\n",
      "Epoch 501/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0085\n",
      "Epoch 502/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0078\n",
      "Epoch 503/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0092\n",
      "Epoch 504/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0085\n",
      "Epoch 505/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 506/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 507/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 508/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0128 - val_loss: 0.0083\n",
      "Epoch 509/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0086\n",
      "Epoch 510/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0126 - val_loss: 0.0078\n",
      "Epoch 511/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0081\n",
      "Epoch 512/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 513/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0086\n",
      "Epoch 514/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0082\n",
      "Epoch 515/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0128 - val_loss: 0.0081\n",
      "Epoch 516/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 517/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0084\n",
      "Epoch 518/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0085\n",
      "Epoch 519/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0077\n",
      "Epoch 520/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0082\n",
      "Epoch 521/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0081\n",
      "Epoch 522/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0082\n",
      "Epoch 523/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0081\n",
      "Epoch 524/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0082\n",
      "Epoch 525/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0077\n",
      "Epoch 526/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0073\n",
      "Epoch 527/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0079\n",
      "Epoch 528/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 529/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0081\n",
      "Epoch 530/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0078\n",
      "Epoch 531/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0080\n",
      "Epoch 532/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0082\n",
      "Epoch 533/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0077\n",
      "Epoch 534/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0076\n",
      "Epoch 535/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0083\n",
      "Epoch 536/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0076\n",
      "Epoch 537/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0074\n",
      "Epoch 538/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0080\n",
      "Epoch 539/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0079\n",
      "Epoch 540/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0077\n",
      "Epoch 541/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0080\n",
      "Epoch 542/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0074\n",
      "Epoch 543/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0077\n",
      "Epoch 544/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0078\n",
      "Epoch 545/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0081\n",
      "Epoch 546/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0080\n",
      "Epoch 547/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0075\n",
      "Epoch 548/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0074\n",
      "Epoch 549/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 550/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0076\n",
      "Epoch 551/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0074\n",
      "Epoch 552/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0077\n",
      "Epoch 553/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0074\n",
      "Epoch 554/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0080\n",
      "Epoch 555/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0071\n",
      "Epoch 556/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0070\n",
      "Epoch 557/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0076\n",
      "Epoch 558/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0075\n",
      "Epoch 559/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0077\n",
      "Epoch 560/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0077\n",
      "Epoch 561/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0075\n",
      "Epoch 562/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0072\n",
      "Epoch 563/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 564/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0076\n",
      "Epoch 565/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0076\n",
      "Epoch 566/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 567/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0071\n",
      "Epoch 568/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0080\n",
      "Epoch 569/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0075\n",
      "Epoch 570/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 571/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0082\n",
      "Epoch 572/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 573/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0120 - val_loss: 0.0075\n",
      "Epoch 574/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0078\n",
      "Epoch 575/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0079\n",
      "Epoch 576/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0071\n",
      "Epoch 577/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 578/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0079\n",
      "Epoch 579/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0076\n",
      "Epoch 580/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0082\n",
      "Epoch 581/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 582/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0070\n",
      "Epoch 583/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0078\n",
      "Epoch 584/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0071\n",
      "Epoch 585/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0072\n",
      "Epoch 586/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0117 - val_loss: 0.0073\n",
      "Epoch 587/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0072\n",
      "Epoch 588/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0077\n",
      "Epoch 589/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0075\n",
      "Epoch 590/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0073\n",
      "Epoch 591/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0081\n",
      "Epoch 592/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0076\n",
      "Epoch 593/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 594/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 595/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0073\n",
      "Epoch 596/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0076\n",
      "Epoch 597/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0074\n",
      "Epoch 598/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0075\n",
      "Epoch 599/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 600/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0068\n",
      "Epoch 601/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0069\n",
      "Epoch 602/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0073\n",
      "Epoch 603/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0078\n",
      "Epoch 604/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0076\n",
      "Epoch 605/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0075\n",
      "Epoch 606/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0077\n",
      "Epoch 607/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0072\n",
      "Epoch 608/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0069\n",
      "Epoch 609/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0076\n",
      "Epoch 610/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0114 - val_loss: 0.0077\n",
      "Epoch 611/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0071\n",
      "Epoch 612/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0072\n",
      "Epoch 613/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0072\n",
      "Epoch 614/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0080\n",
      "Epoch 615/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 616/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0069\n",
      "Epoch 617/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 618/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 619/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0074\n",
      "Epoch 620/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0076\n",
      "Epoch 621/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0075\n",
      "Epoch 622/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0069\n",
      "Epoch 623/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0075\n",
      "Epoch 624/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0068\n",
      "Epoch 625/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0071\n",
      "Epoch 626/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 627/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0117 - val_loss: 0.0071\n",
      "Epoch 628/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0069\n",
      "Epoch 629/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0069\n",
      "Epoch 630/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0071\n",
      "Epoch 631/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0071\n",
      "Epoch 632/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0074\n",
      "Epoch 633/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0114 - val_loss: 0.0075\n",
      "Epoch 634/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0074\n",
      "Epoch 635/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0077\n",
      "Epoch 636/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0117 - val_loss: 0.0075\n",
      "Epoch 637/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0114 - val_loss: 0.0067\n",
      "Epoch 638/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 0.0068\n",
      "Epoch 639/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0111 - val_loss: 0.0065\n",
      "Epoch 640/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0118 - val_loss: 0.0078\n",
      "Epoch 641/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0069\n",
      "Epoch 642/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0075\n",
      "Epoch 643/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0072\n",
      "Epoch 644/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 645/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 646/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0074\n",
      "Epoch 647/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0061\n",
      "Epoch 648/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0071\n",
      "Epoch 649/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0069\n",
      "Epoch 650/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0074\n",
      "Epoch 651/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0069\n",
      "Epoch 652/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0064\n",
      "Epoch 653/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0070\n",
      "Epoch 654/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0073\n",
      "Epoch 655/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 656/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0069\n",
      "Epoch 657/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0067\n",
      "Epoch 658/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0070\n",
      "Epoch 659/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0069\n",
      "Epoch 660/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0067\n",
      "Epoch 661/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0064\n",
      "Epoch 662/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0069\n",
      "Epoch 663/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0072\n",
      "Epoch 664/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0070\n",
      "Epoch 665/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0063\n",
      "Epoch 666/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 667/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0073\n",
      "Epoch 668/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0070\n",
      "Epoch 669/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0067\n",
      "Epoch 670/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0067\n",
      "Epoch 671/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 672/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0066\n",
      "Epoch 673/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0071\n",
      "Epoch 674/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0071\n",
      "Epoch 675/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0068\n",
      "Epoch 676/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0111 - val_loss: 0.0072\n",
      "Epoch 677/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0068\n",
      "Epoch 678/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0113 - val_loss: 0.0072\n",
      "Epoch 679/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0066\n",
      "Epoch 680/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0113 - val_loss: 0.0063\n",
      "Epoch 681/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0072\n",
      "Epoch 682/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0069\n",
      "Epoch 683/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0064\n",
      "Epoch 684/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0066\n",
      "Epoch 685/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0072\n",
      "Epoch 686/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0070\n",
      "Epoch 687/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0071\n",
      "Epoch 688/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0070\n",
      "Epoch 689/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0077\n",
      "Epoch 690/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0072\n",
      "Epoch 691/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0071\n",
      "Epoch 692/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 693/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 694/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0069\n",
      "Epoch 695/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0063\n",
      "Epoch 696/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0072\n",
      "Epoch 697/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0070\n",
      "Epoch 698/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0064\n",
      "Epoch 699/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0064\n",
      "Epoch 700/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0072\n",
      "Epoch 701/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0073\n",
      "Epoch 702/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0076\n",
      "Epoch 703/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0073\n",
      "Epoch 704/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0077\n",
      "Epoch 705/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0073\n",
      "Epoch 706/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0076\n",
      "Epoch 707/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0066\n",
      "Epoch 708/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0079\n",
      "Epoch 709/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0072\n",
      "Epoch 710/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0066\n",
      "Epoch 711/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0111 - val_loss: 0.0068\n",
      "Epoch 712/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0071\n",
      "Epoch 713/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 0.0079\n",
      "Epoch 714/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0071\n",
      "Epoch 715/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0074\n",
      "Epoch 716/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0062\n",
      "Epoch 717/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0065\n",
      "Epoch 718/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0076\n",
      "Epoch 719/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 720/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0110 - val_loss: 0.0060\n",
      "Epoch 721/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0068\n",
      "Epoch 722/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0112 - val_loss: 0.0069\n",
      "Epoch 723/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0063\n",
      "Epoch 724/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0073\n",
      "Epoch 725/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0072\n",
      "Epoch 726/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0064\n",
      "Epoch 727/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0065\n",
      "Epoch 728/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0065\n",
      "Epoch 729/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0063\n",
      "Epoch 730/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 731/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0066\n",
      "Epoch 732/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0066\n",
      "Epoch 733/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0062\n",
      "Epoch 734/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0062\n",
      "Epoch 735/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0071\n",
      "Epoch 736/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 737/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 738/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0062\n",
      "Epoch 739/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 740/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 741/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0062\n",
      "Epoch 742/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0061\n",
      "Epoch 743/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0070\n",
      "Epoch 744/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 745/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0075\n",
      "Epoch 746/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0069\n",
      "Epoch 747/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0066\n",
      "Epoch 748/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0071\n",
      "Epoch 749/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0073\n",
      "Epoch 750/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0068\n",
      "Epoch 751/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0061\n",
      "Epoch 752/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0076\n",
      "Epoch 753/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0067\n",
      "Epoch 754/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 755/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0066\n",
      "Epoch 756/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0064\n",
      "Epoch 757/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0071\n",
      "Epoch 758/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0067\n",
      "Epoch 759/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0070\n",
      "Epoch 760/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0074\n",
      "Epoch 761/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0072\n",
      "Epoch 762/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0072\n",
      "Epoch 763/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0066\n",
      "Epoch 764/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0066\n",
      "Epoch 765/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0066\n",
      "Epoch 766/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0075\n",
      "Epoch 767/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 768/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 769/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0063\n",
      "Epoch 770/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0062\n",
      "Epoch 771/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0063\n",
      "Epoch 772/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0067\n",
      "Epoch 773/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0074\n",
      "Epoch 774/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0066\n",
      "Epoch 775/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0067\n",
      "Epoch 776/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0068\n",
      "Epoch 777/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0072\n",
      "Epoch 778/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0108 - val_loss: 0.0068\n",
      "Epoch 779/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0073\n",
      "Epoch 780/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0063\n",
      "Epoch 781/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0107 - val_loss: 0.0064\n",
      "Epoch 782/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0061\n",
      "Epoch 783/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0062\n",
      "Epoch 784/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0065\n",
      "Epoch 785/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0068\n",
      "Epoch 786/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0060\n",
      "Epoch 787/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0063\n",
      "Epoch 788/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0061\n",
      "Epoch 789/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 790/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0076\n",
      "Epoch 791/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0062\n",
      "Epoch 792/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0060\n",
      "Epoch 793/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0071\n",
      "Epoch 794/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 795/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0068\n",
      "Epoch 796/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0063\n",
      "Epoch 797/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0065\n",
      "Epoch 798/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0063\n",
      "Epoch 799/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0067\n",
      "Epoch 800/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0059\n",
      "Epoch 801/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 802/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0062\n",
      "Epoch 803/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0068\n",
      "Epoch 804/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0062\n",
      "Epoch 805/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0065\n",
      "Epoch 806/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0065\n",
      "Epoch 807/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0069\n",
      "Epoch 808/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0066\n",
      "Epoch 809/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0067\n",
      "Epoch 810/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0061\n",
      "Epoch 811/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0066\n",
      "Epoch 812/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0064\n",
      "Epoch 813/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0073\n",
      "Epoch 814/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0105 - val_loss: 0.0062\n",
      "Epoch 815/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0062\n",
      "Epoch 816/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0066\n",
      "Epoch 817/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0071\n",
      "Epoch 818/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 819/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0068\n",
      "Epoch 820/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0072\n",
      "Epoch 821/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0059\n",
      "Epoch 822/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0072\n",
      "Epoch 823/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0065\n",
      "Epoch 824/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 825/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0104 - val_loss: 0.0065\n",
      "Epoch 826/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0064\n",
      "Epoch 827/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0063\n",
      "Epoch 828/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0067\n",
      "Epoch 829/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0069\n",
      "Epoch 830/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0068\n",
      "Epoch 831/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0063\n",
      "Epoch 832/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 833/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0069\n",
      "Epoch 834/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0067\n",
      "Epoch 835/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 836/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0067\n",
      "Epoch 837/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0067\n",
      "Epoch 838/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0062\n",
      "Epoch 839/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0066\n",
      "Epoch 840/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0061\n",
      "Epoch 841/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 842/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0064\n",
      "Epoch 843/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0068\n",
      "Epoch 844/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0072\n",
      "Epoch 845/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0064\n",
      "Epoch 846/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0066\n",
      "Epoch 847/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0065\n",
      "Epoch 848/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 849/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 850/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0064\n",
      "Epoch 851/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 852/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 853/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0066\n",
      "Epoch 854/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0069\n",
      "Epoch 855/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0068\n",
      "Epoch 856/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0057\n",
      "Epoch 857/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0069\n",
      "Epoch 858/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0061\n",
      "Epoch 859/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0070\n",
      "Epoch 860/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0065\n",
      "Epoch 861/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0068\n",
      "Epoch 862/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.0068\n",
      "Epoch 863/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0065\n",
      "Epoch 864/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0063\n",
      "Epoch 865/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0062\n",
      "Epoch 866/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0062\n",
      "Epoch 867/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0060\n",
      "Epoch 868/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0063\n",
      "Epoch 869/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 870/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0101 - val_loss: 0.0067\n",
      "Epoch 871/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 872/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0061\n",
      "Epoch 873/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0062\n",
      "Epoch 874/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0064\n",
      "Epoch 875/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0103 - val_loss: 0.0070\n",
      "Epoch 876/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0104 - val_loss: 0.0069\n",
      "Epoch 877/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0066\n",
      "Epoch 878/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0102 - val_loss: 0.0059\n",
      "Epoch 879/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0057\n",
      "Epoch 880/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 881/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0061\n",
      "Epoch 882/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0068\n",
      "Epoch 883/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0062\n",
      "Epoch 884/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 885/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0104 - val_loss: 0.0064\n",
      "Epoch 886/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0065\n",
      "Epoch 887/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0065\n",
      "Epoch 888/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0059\n",
      "Epoch 889/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0071\n",
      "Epoch 890/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0063\n",
      "Epoch 891/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0065\n",
      "Epoch 892/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0071\n",
      "Epoch 893/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0062\n",
      "Epoch 894/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0103 - val_loss: 0.0069\n",
      "Epoch 895/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0057\n",
      "Epoch 896/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 0.0067\n",
      "Epoch 897/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 898/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0066\n",
      "Epoch 899/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0069\n",
      "Epoch 900/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0101 - val_loss: 0.0065\n",
      "Epoch 901/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 902/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0101 - val_loss: 0.0066\n",
      "Epoch 903/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0062\n",
      "Epoch 904/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 905/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0061\n",
      "Epoch 906/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0102 - val_loss: 0.0071\n",
      "Epoch 907/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 908/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 909/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0075\n",
      "Epoch 910/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0063\n",
      "Epoch 911/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0071\n",
      "Epoch 912/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0064\n",
      "Epoch 913/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0065\n",
      "Epoch 914/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0062\n",
      "Epoch 915/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 916/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0064\n",
      "Epoch 917/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0061\n",
      "Epoch 918/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0059\n",
      "Epoch 919/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 920/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0064\n",
      "Epoch 921/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 922/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0064\n",
      "Epoch 923/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0062\n",
      "Epoch 924/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0060\n",
      "Epoch 925/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0057\n",
      "Epoch 926/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0068\n",
      "Epoch 927/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0065\n",
      "Epoch 928/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 929/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 930/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0071\n",
      "Epoch 931/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0061\n",
      "Epoch 932/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 933/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0060\n",
      "Epoch 934/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0070\n",
      "Epoch 935/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0067\n",
      "Epoch 936/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0063\n",
      "Epoch 937/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0069\n",
      "Epoch 938/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0060\n",
      "Epoch 939/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0064\n",
      "Epoch 940/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 941/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0059\n",
      "Epoch 942/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0073\n",
      "Epoch 943/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0068\n",
      "Epoch 944/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0100 - val_loss: 0.0064\n",
      "Epoch 945/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 0.0068\n",
      "Epoch 946/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0072\n",
      "Epoch 947/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 948/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 949/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 950/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 951/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 952/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 953/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 954/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0064\n",
      "Epoch 955/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0062\n",
      "Epoch 956/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 957/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0062\n",
      "Epoch 958/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0064\n",
      "Epoch 959/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0057\n",
      "Epoch 960/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 961/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0066\n",
      "Epoch 962/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0065\n",
      "Epoch 963/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 964/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0061\n",
      "Epoch 965/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0070\n",
      "Epoch 966/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0066\n",
      "Epoch 967/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0062\n",
      "Epoch 968/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0061\n",
      "Epoch 969/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0062\n",
      "Epoch 970/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0061\n",
      "Epoch 971/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0063\n",
      "Epoch 972/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0057\n",
      "Epoch 973/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0058\n",
      "Epoch 974/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0072\n",
      "Epoch 975/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 976/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 977/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0065\n",
      "Epoch 978/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0101 - val_loss: 0.0057\n",
      "Epoch 979/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0070\n",
      "Epoch 980/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0061\n",
      "Epoch 981/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 982/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 983/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0058\n",
      "Epoch 984/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 985/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0062\n",
      "Epoch 986/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 987/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0056\n",
      "Epoch 988/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 989/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0064\n",
      "Epoch 990/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0062\n",
      "Epoch 991/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0061\n",
      "Epoch 992/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0063\n",
      "Epoch 993/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 994/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 995/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0099 - val_loss: 0.0060\n",
      "Epoch 996/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 997/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0062\n",
      "Epoch 998/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0065\n",
      "Epoch 999/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0059\n",
      "Epoch 1000/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0072\n",
      "Epoch 1001/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0058\n",
      "Epoch 1002/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0056\n",
      "Epoch 1003/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 1004/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0062\n",
      "Epoch 1005/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0062\n",
      "Epoch 1006/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0060\n",
      "Epoch 1007/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0061\n",
      "Epoch 1008/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0061\n",
      "Epoch 1009/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0063\n",
      "Epoch 1010/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0057\n",
      "Epoch 1011/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 1012/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 1013/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0061\n",
      "Epoch 1014/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0064\n",
      "Epoch 1015/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0061\n",
      "Epoch 1016/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0068\n",
      "Epoch 1017/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0064\n",
      "Epoch 1018/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0099 - val_loss: 0.0062\n",
      "Epoch 1019/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0097 - val_loss: 0.0057\n",
      "Epoch 1020/2000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0098 - val_loss: 0.0058\n",
      "Epoch 1021/2000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 1022/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0097 - val_loss: 0.0068\n",
      "Epoch 1023/2000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0100 - val_loss: 0.0065\n",
      "Epoch 1024/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0099 - val_loss: 0.0061\n",
      "Epoch 1025/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0059\n",
      "Epoch 1026/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0099 - val_loss: 0.0067\n",
      "Epoch 1027/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 1028/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0062\n",
      "Epoch 1029/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 1030/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0060\n",
      "Epoch 1031/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0060\n",
      "Epoch 1032/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 1033/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0068\n",
      "Epoch 1034/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0065\n",
      "Epoch 1035/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 1036/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0060\n",
      "Epoch 1037/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0059\n",
      "Epoch 1038/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0071\n",
      "Epoch 1039/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0065\n",
      "Epoch 1041/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 1042/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0065\n",
      "Epoch 1043/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 1044/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0065\n",
      "Epoch 1045/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 1046/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0059\n",
      "Epoch 1047/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 1048/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0059\n",
      "Epoch 1049/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 1050/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 1051/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0097 - val_loss: 0.0062\n",
      "Epoch 1052/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0056\n",
      "Epoch 1053/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0059\n",
      "Epoch 1054/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 1055/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0060\n",
      "Epoch 1056/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0057\n",
      "Epoch 1057/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0059\n",
      "Epoch 1058/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0060\n",
      "Epoch 1059/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0057\n",
      "Epoch 1060/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0067\n",
      "Epoch 1061/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0061\n",
      "Epoch 1062/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0067\n",
      "Epoch 1063/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 1064/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0059\n",
      "Epoch 1065/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 1066/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 1067/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0061\n",
      "Epoch 1068/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0065\n",
      "Epoch 1069/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 1070/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0064\n",
      "Epoch 1071/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 1072/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0061\n",
      "Epoch 1073/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0060\n",
      "Epoch 1074/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0060\n",
      "Epoch 1075/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0061\n",
      "Epoch 1076/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 1077/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 1078/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 1079/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 1080/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0059\n",
      "Epoch 1081/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 1082/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0061\n",
      "Epoch 1083/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0058\n",
      "Epoch 1084/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0053\n",
      "Epoch 1085/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 1086/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 1087/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0070\n",
      "Epoch 1088/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0096 - val_loss: 0.0065\n",
      "Epoch 1089/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0097 - val_loss: 0.0056\n",
      "Epoch 1090/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 1091/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0060\n",
      "Epoch 1092/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0063\n",
      "Epoch 1093/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0057\n",
      "Epoch 1094/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0060\n",
      "Epoch 1095/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0058\n",
      "Epoch 1096/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0057\n",
      "Epoch 1097/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 1098/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 1099/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0062\n",
      "Epoch 1100/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0059\n",
      "Epoch 1101/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0062\n",
      "Epoch 1102/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 1103/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0059\n",
      "Epoch 1104/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0062\n",
      "Epoch 1105/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0058\n",
      "Epoch 1106/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 1107/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0059\n",
      "Epoch 1108/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 1109/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0061\n",
      "Epoch 1110/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0060\n",
      "Epoch 1111/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0059\n",
      "Epoch 1112/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 1113/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0056\n",
      "Epoch 1114/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0058\n",
      "Epoch 1115/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1116/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0060\n",
      "Epoch 1117/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0060\n",
      "Epoch 1118/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0062\n",
      "Epoch 1119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0063\n",
      "Epoch 1120/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0060\n",
      "Epoch 1121/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0062\n",
      "Epoch 1122/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0057\n",
      "Epoch 1123/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0069\n",
      "Epoch 1124/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0058\n",
      "Epoch 1125/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 1126/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 1127/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 1128/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0058\n",
      "Epoch 1129/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0065\n",
      "Epoch 1130/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0063\n",
      "Epoch 1131/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0068\n",
      "Epoch 1132/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0062\n",
      "Epoch 1133/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 1134/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 1135/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 1136/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0059\n",
      "Epoch 1137/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0059\n",
      "Epoch 1138/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 1139/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0063\n",
      "Epoch 1140/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0058\n",
      "Epoch 1141/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 1142/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0063\n",
      "Epoch 1143/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 1144/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 1145/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0064\n",
      "Epoch 1146/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0057\n",
      "Epoch 1147/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0065\n",
      "Epoch 1148/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 1149/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0060\n",
      "Epoch 1150/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0058\n",
      "Epoch 1151/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 1152/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1153/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1154/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 1155/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 1156/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0062\n",
      "Epoch 1157/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0059\n",
      "Epoch 1158/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0059\n",
      "Epoch 1159/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0065\n",
      "Epoch 1160/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0063\n",
      "Epoch 1161/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0059\n",
      "Epoch 1162/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 1163/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 1164/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 1165/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0060\n",
      "Epoch 1166/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0063\n",
      "Epoch 1167/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0056\n",
      "Epoch 1168/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0063\n",
      "Epoch 1169/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 1170/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 1171/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0063\n",
      "Epoch 1172/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1173/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0060\n",
      "Epoch 1174/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1175/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 1176/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0059\n",
      "Epoch 1177/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0063\n",
      "Epoch 1178/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 1179/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0064\n",
      "Epoch 1180/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0055\n",
      "Epoch 1181/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 1182/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 1183/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0062\n",
      "Epoch 1184/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 1185/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 1186/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 1187/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1188/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0066\n",
      "Epoch 1189/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 1190/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 1191/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0058\n",
      "Epoch 1192/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0058\n",
      "Epoch 1193/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0065\n",
      "Epoch 1194/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0065\n",
      "Epoch 1195/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0065\n",
      "Epoch 1196/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0062\n",
      "Epoch 1197/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1198/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 1199/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 1200/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1201/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 1202/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0056\n",
      "Epoch 1203/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0065\n",
      "Epoch 1204/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 1205/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0062\n",
      "Epoch 1206/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0065\n",
      "Epoch 1207/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0065\n",
      "Epoch 1208/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 1209/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0059\n",
      "Epoch 1210/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0062\n",
      "Epoch 1211/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0060\n",
      "Epoch 1212/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 1213/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0059\n",
      "Epoch 1214/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1215/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1216/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0059\n",
      "Epoch 1217/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1218/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1219/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0057\n",
      "Epoch 1220/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0062\n",
      "Epoch 1221/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0052\n",
      "Epoch 1222/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 1223/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 1224/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 1225/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0065\n",
      "Epoch 1226/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 1227/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0060\n",
      "Epoch 1228/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0066\n",
      "Epoch 1229/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 1230/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 1231/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 1232/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1233/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0060\n",
      "Epoch 1234/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0057\n",
      "Epoch 1235/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0060\n",
      "Epoch 1236/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0062\n",
      "Epoch 1237/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1238/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0062\n",
      "Epoch 1239/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 1240/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0061\n",
      "Epoch 1241/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0060\n",
      "Epoch 1242/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 1243/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0066\n",
      "Epoch 1244/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1245/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 1246/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0060\n",
      "Epoch 1247/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0056\n",
      "Epoch 1248/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 1249/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1250/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0062\n",
      "Epoch 1251/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 1252/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1253/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0062\n",
      "Epoch 1254/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0062\n",
      "Epoch 1255/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 1256/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0063\n",
      "Epoch 1257/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 1258/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 1259/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1260/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0066\n",
      "Epoch 1261/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 1262/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 1263/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0067\n",
      "Epoch 1264/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0066\n",
      "Epoch 1265/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 1266/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1267/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 1268/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 1269/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0064\n",
      "Epoch 1270/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 1271/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 1272/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1273/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 1274/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 1275/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 1276/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 1277/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1278/2000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 1279/2000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 1280/2000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 1281/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0063\n",
      "Epoch 1282/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 1283/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 1284/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 1285/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 1286/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 1287/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 1288/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0062\n",
      "Epoch 1289/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0064\n",
      "Epoch 1290/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1291/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0058\n",
      "Epoch 1292/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 1293/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 1294/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 1295/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 1296/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 1297/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 1298/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 1299/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 1300/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 1301/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 1302/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0064\n",
      "Epoch 1303/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0056\n",
      "Epoch 1304/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0062\n",
      "Epoch 1305/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 1306/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0063\n",
      "Epoch 1307/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0092 - val_loss: 0.0065\n",
      "Epoch 1308/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0061\n",
      "Epoch 1309/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 1310/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0058\n",
      "Epoch 1311/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 1312/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 1313/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 1314/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1315/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 1316/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0093 - val_loss: 0.0063\n",
      "Epoch 1317/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0059\n",
      "Epoch 1318/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0065\n",
      "Epoch 1319/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1320/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 1321/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 1322/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 1323/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0057\n",
      "Epoch 1324/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 1325/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1326/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 1327/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 1328/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0058\n",
      "Epoch 1329/2000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1330/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 1331/2000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 1332/2000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 1333/2000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 1334/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 1335/2000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0059\n",
      "Epoch 1336/2000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 1337/2000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 1338/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 1339/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0092 - val_loss: 0.0064\n",
      "Epoch 1340/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 1341/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 1342/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1343/2000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 1344/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 1345/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 1346/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 1347/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 1348/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 1349/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 1350/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 1351/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 1352/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 1353/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1354/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0068\n",
      "Epoch 1355/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 1356/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0089 - val_loss: 0.0064\n",
      "Epoch 1357/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0060\n",
      "Epoch 1358/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 1359/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1360/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1361/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 1362/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 1363/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 1364/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0048\n",
      "Epoch 1365/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0091 - val_loss: 0.0056\n",
      "Epoch 1366/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 1367/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 1368/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 1369/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0092 - val_loss: 0.0057\n",
      "Epoch 1370/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1371/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0092 - val_loss: 0.0064\n",
      "Epoch 1372/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 1373/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1374/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1375/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1376/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1377/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1378/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 1379/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 1380/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 1381/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0067\n",
      "Epoch 1382/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1383/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0092 - val_loss: 0.0057\n",
      "Epoch 1384/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0064\n",
      "Epoch 1385/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1386/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 1387/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 1388/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0089 - val_loss: 0.0064\n",
      "Epoch 1389/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 1390/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 1391/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 1392/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1393/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1394/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0064\n",
      "Epoch 1395/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0091 - val_loss: 0.0063\n",
      "Epoch 1396/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 1397/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 1398/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 1399/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 1400/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0091 - val_loss: 0.0056\n",
      "Epoch 1401/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0091 - val_loss: 0.0056\n",
      "Epoch 1402/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 1403/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 1404/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 1405/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0093 - val_loss: 0.0063\n",
      "Epoch 1406/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 1407/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1408/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0058\n",
      "Epoch 1409/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0092 - val_loss: 0.0060\n",
      "Epoch 1410/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0057\n",
      "Epoch 1411/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1412/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1413/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 1414/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0064\n",
      "Epoch 1415/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1416/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 1417/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 1418/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1419/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1420/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 1421/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 1422/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 1423/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1424/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 1425/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0058\n",
      "Epoch 1426/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 1427/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0089 - val_loss: 0.0066\n",
      "Epoch 1428/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 1429/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 1430/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1431/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1432/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1433/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1434/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1435/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 1436/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 1437/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1438/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 1439/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 1440/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1441/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1442/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 1443/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 1444/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1445/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1446/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 1447/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 1448/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 1449/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 1450/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 1451/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0090 - val_loss: 0.0059\n",
      "Epoch 1452/2000\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1453/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 1454/2000\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 1455/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1456/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 1457/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 1458/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 1459/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0063\n",
      "Epoch 1460/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 1461/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 1462/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 1463/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0058\n",
      "Epoch 1464/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 1465/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 1466/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1467/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 1468/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1469/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 1470/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0063\n",
      "Epoch 1471/2000\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1472/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0087 - val_loss: 0.0061\n",
      "Epoch 1473/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0064\n",
      "Epoch 1474/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1475/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1476/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 1477/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 1478/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 0.0062\n",
      "Epoch 1479/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 1480/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 1481/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 1482/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 1483/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1484/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 1485/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1486/2000\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 1487/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 1488/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 1489/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1490/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1491/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 1492/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0066\n",
      "Epoch 1493/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 1494/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0064\n",
      "Epoch 1495/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 1496/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 1497/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1498/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0063\n",
      "Epoch 1499/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 1500/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 1501/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 1502/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1503/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1504/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 1505/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 1506/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 1507/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0091 - val_loss: 0.0060\n",
      "Epoch 1508/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 1509/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1510/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 1511/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 1512/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 1513/2000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0088 - val_loss: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1514/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1515/2000\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 1516/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 1517/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 1518/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 1519/2000\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1520/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 1521/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 1522/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 1523/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 1524/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 1525/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 1526/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 1527/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 1528/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 1529/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1530/2000\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 1531/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 1532/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0058\n",
      "Epoch 1533/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 1534/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 1535/2000\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1536/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 1537/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 1538/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1539/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 1540/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1541/2000\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 1542/2000\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1543/2000\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 1544/2000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 1545/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 1546/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1547/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0064\n",
      "Epoch 1548/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 1549/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0056\n",
      "Epoch 1550/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1551/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 1552/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1553/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1554/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 1555/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 1556/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1557/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 1558/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1559/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1560/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 1561/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 1562/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 1563/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1564/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 1565/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 1566/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1567/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 1568/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 1569/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 1570/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1571/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 1572/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 1573/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0058\n",
      "Epoch 1574/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 1575/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 1576/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1577/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0058\n",
      "Epoch 1578/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 1579/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 1580/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 1581/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 1582/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1583/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0058\n",
      "Epoch 1584/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1585/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 1586/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 1587/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 1588/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1589/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0063\n",
      "Epoch 1590/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1591/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 1592/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 1593/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1594/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1595/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1596/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1597/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 1598/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 1599/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 1600/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 1601/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1602/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1603/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 1604/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1605/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 1606/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1607/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0061\n",
      "Epoch 1608/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1609/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0062\n",
      "Epoch 1610/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0063\n",
      "Epoch 1611/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 1612/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1613/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1614/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1615/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 1616/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 1617/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1618/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 1619/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 1620/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1621/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 1622/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1623/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1624/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 1625/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 1626/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 1627/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 1628/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 1629/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 1630/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 1631/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1632/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 1633/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1634/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1635/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1636/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 1637/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 1638/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 1639/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1640/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 1641/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1642/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 1643/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1644/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 1645/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 1646/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1647/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 1648/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 1649/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 1650/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0057\n",
      "Epoch 1651/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1652/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1653/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 1654/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 1655/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 1656/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1657/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 1658/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 1659/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 1660/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 1661/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0060\n",
      "Epoch 1662/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 1663/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1664/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 1665/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1666/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1667/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1668/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 1669/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1670/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 1671/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0064\n",
      "Epoch 1672/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 1673/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 1674/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 1675/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 1676/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1677/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 1678/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 1679/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1680/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 1681/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 1682/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1683/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 1684/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 1685/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1686/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1687/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1688/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 1689/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 1690/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0058\n",
      "Epoch 1691/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1692/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 1693/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0058\n",
      "Epoch 1694/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1695/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 1696/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 1697/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 1698/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1699/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1700/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1701/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 1702/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1703/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1704/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0065\n",
      "Epoch 1705/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 1706/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 1707/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1708/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 1709/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 1710/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 1711/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 1712/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 1713/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1714/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1715/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 1716/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0058\n",
      "Epoch 1717/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 1718/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1719/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1720/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 1721/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1722/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1723/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1724/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1725/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1726/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 1727/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 1728/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1729/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1730/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 1731/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 1732/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1733/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 1734/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1735/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 1736/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 1737/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 1738/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 1739/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0067\n",
      "Epoch 1740/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1741/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 1742/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 1743/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 1744/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 1745/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1746/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 1747/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1748/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1749/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1750/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1751/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1752/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 1753/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1754/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 1755/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1756/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 1757/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1758/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 1759/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 1760/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 1761/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1762/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 1763/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1764/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 1765/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1766/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 1767/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 1768/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 1769/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 1770/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 1771/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 1772/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1773/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1774/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 1775/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 1776/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 1777/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 1778/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0051\n",
      "Epoch 1779/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 1780/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 1781/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 1782/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 1783/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 1784/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 1785/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 1786/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0061\n",
      "Epoch 1787/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1788/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0065\n",
      "Epoch 1789/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1790/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1791/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 1792/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1793/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 1794/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 1795/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 1796/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 1797/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1798/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 1799/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 1800/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 1801/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0067\n",
      "Epoch 1802/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 1803/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 1804/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 1805/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0064\n",
      "Epoch 1806/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1807/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 1808/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 1809/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 1810/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 1811/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 1812/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 1813/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 1814/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 1815/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 1816/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1817/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1818/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1819/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0047\n",
      "Epoch 1820/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1821/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1822/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1823/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1824/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 1825/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 1826/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0056\n",
      "Epoch 1827/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 1828/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 1829/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 1830/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 1831/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1832/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 1833/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 1834/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0057\n",
      "Epoch 1835/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1836/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0051\n",
      "Epoch 1837/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1838/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0059\n",
      "Epoch 1839/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 1840/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 1841/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 1842/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1843/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 1844/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 1845/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 1846/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0051\n",
      "Epoch 1847/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 1848/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0062\n",
      "Epoch 1849/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1850/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 1851/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 1852/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 1853/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0061\n",
      "Epoch 1854/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 1855/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 1856/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 1857/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 1858/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 1859/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1860/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1861/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 1862/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 1863/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 1864/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1865/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1866/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 1867/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 1868/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1869/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 1870/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 1871/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 1872/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 1873/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 1874/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 1875/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 1876/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 1877/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 1878/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0056\n",
      "Epoch 1879/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 1880/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 1881/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1882/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 1883/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 1884/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1885/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1886/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1887/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1888/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 1889/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 1890/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1891/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 1892/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 1893/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 1894/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1895/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 1896/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1897/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 1898/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1899/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 1900/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 1901/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 1902/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0058\n",
      "Epoch 1903/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0061\n",
      "Epoch 1904/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 1905/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 1906/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 1907/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 1908/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 1909/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 1910/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 1911/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1912/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 1913/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 1914/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 1915/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 1916/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 1917/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1918/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0051\n",
      "Epoch 1919/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 1920/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 1921/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1922/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 1923/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 1924/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1925/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1926/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1927/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 1928/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0055\n",
      "Epoch 1929/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 1930/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 1931/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1932/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 1933/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 1934/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 1935/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 1936/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1937/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0045\n",
      "Epoch 1938/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 1939/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 1940/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 1941/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0058\n",
      "Epoch 1942/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 1943/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1944/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 1945/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1946/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1947/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 1948/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 1949/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1950/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 1951/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1952/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 1953/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1954/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0083 - val_loss: 0.0047\n",
      "Epoch 1955/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0059\n",
      "Epoch 1956/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 1957/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 1958/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 1959/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 1960/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 1961/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1962/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 1963/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1964/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 1965/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 1966/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 1967/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 1968/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0047\n",
      "Epoch 1969/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 1970/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 1971/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 1972/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1973/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0060\n",
      "Epoch 1974/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1975/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 1976/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1977/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 1978/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 1979/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0056\n",
      "Epoch 1980/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 1981/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 1982/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0060\n",
      "Epoch 1983/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 1984/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0053\n",
      "Epoch 1985/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 1986/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1987/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 1988/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0056\n",
      "Epoch 1989/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 1990/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 1991/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0054\n",
      "Epoch 1992/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 1993/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 1994/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 1995/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 1996/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 1997/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1998/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0052\n",
      "Epoch 1999/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 2000/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0054\n"
     ]
    }
   ],
   "source": [
    "# Set early stopping monitor so the model stops training when it won't improve anymore\n",
    "esm = EarlyStopping(monitor = 'loss', patience = 70)\n",
    "# Set the optimizer\n",
    "opt = tf.optimizers.SGD(learning_rate = 0.001)\n",
    "#design network\n",
    "batch_size = int(round(X_train.shape[0]*0.1))\n",
    "# fit network\n",
    "model.compile(loss='mae', optimizer=opt)\n",
    "history = model.fit(X_train, y_train, epochs=2000, batch_size= batch_size, verbose=1,\n",
    "    shuffle=False, validation_split=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)\n",
    "predict = [float(predict[i]) for i in range(len(predict))]\n",
    "pred = eu.scale_back_pct(predict, close_test)\n",
    "updown_pred = eu.ud_pred(pred, close_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.6635160680529301\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(updown_pred)\n",
    "df[\"Close\"] = list(close_test)\n",
    "df[\"updown_pred\"] = df.iloc[:,0]\n",
    "df[\"updown_actual\"] = eu.ud(close_test)\n",
    "df[\"Scaled_pred\"] = pred\n",
    "df[\"Pred\"] = predict\n",
    "df = df.iloc[:,1:] \n",
    "acc = (df[\"updown_pred\"] == df[\"updown_actual\"]).sum()/df.shape[0]\n",
    "print('Model Accuracy: ', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>updown_pred</th>\n",
       "      <th>updown_actual</th>\n",
       "      <th>Scaled_pred</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6823.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6823.750000</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6813.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6830.924343</td>\n",
       "      <td>0.001051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6845.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6835.011865</td>\n",
       "      <td>0.003231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6931.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6859.825363</td>\n",
       "      <td>0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6965.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6941.756393</td>\n",
       "      <td>0.001552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>14654.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11370.366547</td>\n",
       "      <td>-0.208770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>14447.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14815.859279</td>\n",
       "      <td>0.011045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>14763.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12543.701790</td>\n",
       "      <td>-0.131743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>14755.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12595.206388</td>\n",
       "      <td>-0.146883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>14985.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14352.534830</td>\n",
       "      <td>-0.027326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Close  updown_pred  updown_actual   Scaled_pred      Pred\n",
       "0      6823.75            1              1   6823.750000  0.000954\n",
       "1      6813.00            1              0   6830.924343  0.001051\n",
       "2      6845.75            1              1   6835.011865  0.003231\n",
       "3      6931.00            1              1   6859.825363  0.002056\n",
       "4      6965.75            1              1   6941.756393  0.001552\n",
       "...        ...          ...            ...           ...       ...\n",
       "1053  14654.00            0              1  11370.366547 -0.208770\n",
       "1054  14447.00            1              0  14815.859279  0.011045\n",
       "1055  14763.75            0              1  12543.701790 -0.131743\n",
       "1056  14755.75            0              0  12595.206388 -0.146883\n",
       "1057  14985.25            0              1  14352.534830 -0.027326\n",
       "\n",
       "[1058 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['Scaled_pred'], label='pred')\n",
    "plt.plot(df[\"Close\"], label='Close')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commission = 0.00\n",
    "def long_equity(prediction, close):\n",
    "    long = [close[0]]\n",
    "    for i in range(1,len(prediction)-1):\n",
    "        if prediction[i] == 1:\n",
    "            long.append(long[i-1] + close[i] - close[i-1] - close[i-1]*commission)\n",
    "        else:\n",
    "            long.append(long[i-1] + 0)\n",
    "    return long\n",
    "\n",
    "def short_equity(prediction, close):\n",
    "    short = [close[0]]\n",
    "    for i in range(1,len(prediction)-1):\n",
    "        if prediction[i] == 0:\n",
    "            short.append(short[i-1] + close[i-1] - close[i] - close[i-1]*commission)\n",
    "        else:\n",
    "            short.append(short[i-1] + 0)\n",
    "    return short  \n",
    "\n",
    "def total_equity(prediction, close):\n",
    "    total = [close[0]]\n",
    "    for i in range(1,len(prediction)-1):\n",
    "        if prediction[i] == 1:\n",
    "            total.append(total[i-1] + close[i] - close[i-1] - close[i-1]*commission)\n",
    "        else:\n",
    "            total.append(total[i-1] + close[i-1] - close[i] - close[i-1]*commission)\n",
    "    return total\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a807ff77f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_equity = pd.DataFrame()\n",
    "df_equity[\"long_equity\"] = eu.long_equity(df[\"updown_pred\"], df[\"Close\"])\n",
    "df_equity[\"short_equity\"] = eu.short_equity(df[\"updown_pred\"], df[\"Close\"])\n",
    "df_equity[\"total_equity\"] = eu.total_equity(df[\"updown_pred\"], df[\"Close\"])\n",
    "plt.plot(np.array(df_equity.index), df_equity[\"short_equity\"])\n",
    "# df_equity[\"short_equity\"].plot()\n",
    "df_equity[\"long_equity\"].plot()\n",
    "df_equity[\"total_equity\"].plot()\n",
    "df[\"Close\"].plot()\n",
    "# df[\"Pred\"].shift(-1).plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEHCAYAAABV4gY/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABXx0lEQVR4nO3deVxU1f/48ddhk31VcUHFFZVFVNz3fU0rc0krLdPMNn+VafVp/bZY+anM1LIsrczlk6Vmmqa5r6HiEm6gqCCCgIDINjDn98cdB1D2bQY4z8fDBzN37vK+DL7nzrnnvI+QUqIoiqJULxamDkBRFEUpfyq5K4qiVEMquSuKolRDKrkriqJUQyq5K4qiVEMquSuKolRDVqYOAKB27drS29vb1GEoiqJUKUePHo2TUtbJ7zWzSO7e3t4EBwebOgxFUZQqRQhxuaDXVLOMoihKNaSSu6IoSjWkkruiKEo1ZBZt7vnR6XRERkaSnp5u6lCUGszW1hYvLy+sra1NHYqilIjZJvfIyEicnJzw9vZGCGHqcJQaSEpJfHw8kZGRNG3a1NThKEqJmG2zTHp6Oh4eHiqxKyYjhMDDw0N9e1SqJLNN7oBK7IrJqb9BJT+no5JIStWZOoxCmXVyN6X4+HgCAwMJDAykXr16NGzY0Pg8MzMzz7qff/45qampRe6zb9+++fbn79u3Lz4+PrRr144ePXpw7ty5cjuP4oqIiODnn3+u8OO8/fbbxt9l27ZtWbVqVaHrJyYmsnjx4gqPS1GKKyY5nZEL99Hu3W30/ngn5jonhkruBfDw8CAkJISQkBBmzJjB//t//8/43MbGJs+6xU3uhVm5ciUnTpxg8uTJzJ49u1jbSCnR6/VlOu4dlZXcAePvcsOGDTz11FPodAVfAZU2uWdnZ5clREXJ17nrt+jywQ7j8ysJqVyITTFhRAVTyb0EduzYQfv27fH39+eJJ54gIyODL774gmvXrtGvXz/69esHwNNPP01QUBC+vr689dZbJTpG7969CQsLA+CTTz6hU6dOBAQEGPcTERGBj48Pjz32GH5+fly9epWPPvoIf39/2rVrx9y5cwEIDw9n6NChdOzYkV69enH27FkApkyZwvPPP0/37t1p1qwZv/zyCwBz585l7969BAYG8tlnnxEREUGvXr3o0KEDHTp04MCBAwDo9XpmzpxJ69atGTRoEMOHDzfu4+jRo/Tp04eOHTsyZMgQoqOjCz3Xli1bYm9vz82bNws837lz5xIeHk5gYCCzZ89m165djBw50riPZ599luXLlwPaSOc5c+bQoUMH/ve//+Ht7c1bb71Fhw4d8Pf3N/4Odu/ebfwW1r59e27dulWi90ipmTKysrlv4T7j8/+MaANAeGwK6bpsHvn2MEcuJZgqvHuYbW+Z3N75/V9CryWX6z7bNnDmrft8i71+eno6U6ZMYceOHbRq1YrHHnuMJUuWMGvWLD799FN27txJ7dq1AXj//fdxd3cnOzubAQMGcPLkSQICAop1nN9//x1/f3+2bdvGhQsXOHLkCFJKRo0axZ49e2jcuDEXLlxgxYoVdO3alS1btrBhwwYOHz6Mvb09CQnaH9f06dP56quvaNmyJYcPH2bmzJn8/fffAERHR7Nv3z7Onj3LqFGjeOihh5g3bx7z589n06ZNAKSmpvLXX39ha2vLhQsXePjhhwkODubXX38lIiKC0NBQYmNjadOmDU888QQ6nY7nnnuODRs2UKdOHdasWcPrr7/Od999V+C5Hjt2jJYtW1K3bt0Cz3fevHmcPn2akJAQAHbt2lXo78/Dw4Njx44B2gdD7dq1OXbsGIsXL2b+/Pl8++23zJ8/n0WLFtGjRw9SUlKwtbUt1nuj1GzP/nyczGztm7JjLSse7ODFe3+c4emVx3iqTzP2hcVxKyOLDc/0MHGkmiqR3M1BdnY2TZs2pVWrVgBMnjyZRYsWMWvWrHvWXbt2LUuXLiUrK4vo6GhCQ0OLTO6TJk3Czs4Ob29vFi5cyIIFC9i2bRvt27cHICUlhQsXLtC4cWOaNGlC165dAdi+fTuPP/449vb2ALi7u5OSksKBAwcYO3ascf8ZGRnGx/fffz8WFha0bduWmJiYfOPR6XQ8++yzhISEYGlpyfnz5wHYt28fY8eOxcLCgnr16hm/rZw7d47Tp08zaNAg4++rfv36+e77s88+4/vvv+f8+fP8/vvvAGzbtq3A8y2J8ePH53n+4IMPAtCxY0d+/fVXAHr06MGLL77IpEmTePDBB/Hy8irRMZSa56/QGP4Kzfm/sm9OP1zscsY+fL37IgAnriaSla3HytL0jSJVIrmX5Arb1C5dusT8+fP5559/cHNzY8qUKcXqSrdy5UqCgoKMz6WUvPrqqzz11FN51ouIiMDBwaHQfen1elxdXY1Xu3erVatWnuPk57PPPsPT05MTJ06g1+uLvLqVUuLr68vBgwcLXQ+0NveXX36ZjRs3MnXqVMLDwws939ysrKzy3Ge4+3d79+/mzrlaWlqSlZUFaFf0I0aMYPPmzfTo0YOtW7fSunXrIuNWaq5pP+R0hPh4TACu9tp9t++ndOKNDaeJvJlmfP1i3G1aeTpVeox3M/3HSxVhaWlJRESEsT38xx9/pE+fPgA4OTkZ222Tk5NxcHDAxcWFmJgYtmzZUqrjDRkyhO+++46UFO1mTVRUFLGxsfesN2jQIL7//nvjDd2EhAScnZ1p2rQp//vf/wAt8Z44caLQ4+U+B4CkpCTq16+PhYUFP/74o/EGZY8ePVi3bh16vZ6YmBhjM4mPjw83btwwJnedTse///5b6DFHjRpFUFAQK1asKPB8746rSZMmhIaGkpGRQWJiIjt27Cho9wUKDw/H39+fOXPm0KlTJ2NbvKIUxKmWdh189v+GMq5TI+Pyfq3r8uKgVnnW/fjPyu/tlp8qceVuDmxtbfn+++8ZO3YsWVlZdOrUiRkzZgBa+/bQoUNp0KABO3fupH379rRu3ZpGjRrRo0fp2t8GDx7MmTNn6NatGwCOjo789NNPWFpa5llv6NChhISEEBQUhI2NDcOHD+eDDz5g5cqVPP3007z33nvodDomTJhAu3btCjxeQEAAlpaWtGvXjilTpjBz5kzGjBnDDz/8wNChQ41XxGPGjGHHjh20bduWRo0a0aFDB1xcXLCxseGXX37h+eefJykpiaysLGbNmoWvb+Hfut58800mTpzImTNn8j3f5s2b06NHD/z8/Bg2bBiffPIJ48aNw8/Pj6ZNmxqbcUri888/Z+fOnVhYWODr68uwYcNKvA+lZnjn939JStORpZdM7dkUW2vLe9ZpXscRgDlDW/PN3ouciS7f+4OlJcyhj2ZQUJC8u//3mTNnaNOmjYkiUgqTkpKCo6Mj8fHxdO7cmf3791OvXj1Th1Vh1N9izeU99w/j4yWTOjDMP//7SGGxKTSv48Cnf51n0c4wzr83rFLa3YUQR6WUQfm9pq7clRIbOXIkiYmJZGZm8sYbb1TrxK7ULNeT0pmw9CDN6jjSsYlbntd6tKxd4HYt6mpX7w1c7dBLiLmVQUNXuwqNtSgquSslVlR3REWpqnafjyUiPpWI+FT+Ppv3HpezbdGVQRsYEnp0YprJk3uxvjcIISKEEKeEECFCiGDDMnchxF9CiAuGn26G5UII8YUQIkwIcVII0aEiT0BRFKWkvt17kQ0hUYA2OEmvl5y9nsxbG7VOAB4OWm+YV4e15vEe3hx+bUCx9tvQVetV9v3+iPIPuoRKcuXeT0oZl+v5XGCHlHKeEGKu4fkcYBjQ0vCvC7DE8FNRFMVksrL1vPy/E6wPuWZc1qKuI2O/OsikLo2REtJ1ejY/34s29Z3YeyGObs09sC5B2/mdK/c/TkXzUUYWjrVM1zhSlhb/0cAKw+MVwP25lv8gNYcAVyFE/nchFEVRKsn5mJQ8iR1gxBf7SM3M5pu9l/h23yV6taxN2wbOCCHo3apOiRI7gL2NFd2bewAQn5JRxNoVq7iRS2CbEOKoEGK6YZmnlPJO8ZDrgKfhcUPgaq5tIw3L8hBCTBdCBAshgm/cuFGK0BVFUYpHr5es+eeK8Xkjdzua1dG69/o2cDYun9qz7JOyTOvdDIAXVocwZskBjl25WeZ9lkZxk3tPKWUHtCaXZ4QQvXO/KLX+lCXqUymlXCqlDJJSBtWpU6ckm1YaR0fHSjuWKvtbMFX2VymrJ38IZsXBywAsntSBdU93576ABgB8Oi6Qj8cE8PFDAfT1qVvmY9Vx1EZFh1xN5Ojlmzy4+ECZ91kaxUruUsoow89Y4DegMxBzp7nF8PPOreUooFGuzb0My5QiqLK/+VNlf5Wy2h+m3S58vn8LhvvXp66TLbMGtmTvK/3wqefEuE6NGBfUqIi9FE/rek7Y3TXYKTm98if2KDK5CyEchBBOdx4Dg4HTwEZgsmG1ycAGw+ONwGOGXjNdgaRczTdVXkhICF27diUgIIAHHnjAWK62b9++zJkzh86dO9OqVSv27t0LaNUVx40bR9u2bXnggQfo0qVLvhN25KbK/qqyv0r5iU/JICNLz/8b2IoXB/sYlwshaORuX+7Hs7K0MPZ7vyMi7na5H6fIOIqxjifwm2G6MSvgZynln0KIf4C1QoipwGVgnGH9zcBwIAxIBR4vc5Rb5sL1U2XeTR71/GHYvBJv9thjj7Fw4UL69OnDm2++yTvvvMPnn38OQFZWFkeOHGHz5s288847bN++ncWLF+Pm5kZoaCinT58mMDCwyGOosr+q7K9SPtJ12Yz9Sqt31MSj/BN5QV4a3Iop3//Duqe7M/arA2z99zoBXq6VdnwoRnKXUl4E7ilKIqWMB+7p/Glof3+mXKIzM0lJSSQmJhoLhk2ePDlPWd3c5WXvVDPct28fL7zwAgB+fn6Flv5VZX9V2V+lfMSlZLDvQhyz1oQAMKlLY0YEVF6nvb4+dYmYNwKALk092Hn2BrOHVG7l0aoxQrUUV9imkF952ZJQZX9V2V+l7LL1ktFf7icqUSvDO6NPc+YOM91727aBMysPXyYtMxuJxN6mctKuKvlbAi4uLri5uRnb03OX/S1Ijx49WLt2LQChoaGcOlX85iVV9leV/VVK5silBJq/tpmoxDTGdPDiwNz+Jk3soFWNTNfp6frhjjzzr1a0qnHlbiKpqal5vq6/+OKLrFixghkzZpCamkqzZs34/vvvC93HzJkzmTx5Mm3btqV169b4+vri4uJSrOOrsr+q7K9SuNTMLBb+Hcb641HosvXEpWQC4GRrxbujfXEw4QjRO+70p09K0xl/5p7FqaKokr8VLDs7G51Oh62tLeHh4QwcOJBz585hY2Nj6tDKpCaV/a0uf4vVzaKdYXyy9d7xIJYWgrD3h2HoBGJyN25l0On97cbnf87qRet6zoVsUXyq5K8Jpaam0q9fP3Q6HVJKFi9eXOUTO6iyv4ppxSanGxP7mA5ePNatCZYWgsRUHT0LKc1rCrUd8/5/j05KL7fkXhiV3CuYk5NTkf3aqyJV9lcxpWX7LwGw6bme+DUsXjOnqQghmD3Eh93nb3DkUgLbQ2PoVw4jYYuibqgqilKlJKXpWHX4CoPaepp9Yr/jmX4tWPtUNzo0dmVt8NUCe6iVJ5XcFUWpUrb9e53k9Cye7tvc1KGU2LErieiyJbvOV3yxRJXcFUWpEpJSdZyMTGT1P1dp5G5H+0aupg6pxF4e3AqAWatDePqnoxV6Ba+Su6IoZi/hdib9/7uLUV/u5+jlm0zt0dRsesOUxDP9WmBtKUhK07Hl9HVib1VczXeV3Avx/vvv4+vrS0BAAIGBgRw+fBjQilPFxcUVsXXBQkJC2Lx5c76v7dq1CxcXFwIDA2nTpg3vvPNOqY9TFsuXL+fatWtFr1hGlpaWBAYG4ufnx3333UdiYmKh669fv57Q0NAKj0upHNmGOutpmdoAudsZWRy9nLf+eUxyOkM/30P8ba0Pe8cmbozrVD4VHCubEAJbq5xxKqcikyrsWCq5F+DgwYNs2rSJY8eOcfLkSbZv306jRmX/g8rKyio0uQP06tWLkJAQgoOD+emnn4xFsIqz7/JSWcndzs6OkJAQTp8+jbu7O4sWLSp0/dIk9/L8vSjlJyz2Fo8uO8ycdafwfetP1h+PwvetrYxZcoBRX+7De+4fnI5KYtiCvcTeymB0YAMi5o1g3dPdK20If0VwzjWA6fQ1ldwrXXR0NLVr1zbWJalduzYNGjQwvr5w4cJ7ysgmJCRw//33ExAQQNeuXTl58iSgTU7x6KOP0qNHDx599FHefPNN1qxZQ2BgIGvWrCkwBgcHBzp27EhYWFih5XtnzJhBly5deOWVVwgLC2PgwIG0a9eODh06EB4eDhRcOrhNmzZMmzYNX19fBg8eTFpaGr/88gvBwcFMmjSJwMBA0tLSePfdd+nUqRN+fn5Mnz7d2Fb4zz//GL/ZzJ49Gz8/P0AbvDV79mzjMb/++usif+fdunUjKkor/Z/f+R44cICNGzcye/ZsAgMDCQ8Pp2/fvsaupnFxcXh7ewPah9OoUaPo378/AwYMYPny5Tz44IMMHTqUli1b8sorrxjjnDJlCn5+fvj7+/PZZ58VGadSdtl6ycBP93AgPB4AvcRY5AvgpOGKduTCfSTczuTBDg1ZMKHkI5HN0XB/bUyIYy0rTkdVXHKvEh9/Hx35iLMJ5Vv7o7V7a+Z0nlPg64MHD+bdd9+lVatWDBw4kPHjx+epI5NfGdm33nqL9u3bs379ev7++28ee+wxY+Gu0NBQ9u3bh52dHcuXLyc4OJgvv/yy0Bjj4+M5dOgQb7zxRqHleyMjIzlw4ACWlpZ06dKFuXPn8sADD5Ceno5ery+ydPCqVav45ptvGDduHOvWreORRx7hyy+/ZP78+cZCZs8++yxvvvkmAI8++iibNm3ivvvu4/HHH+ebb76hW7duxjryAMuWLcPFxYV//vmHjIwMevToweDBg2naNP9pzLKzs9mxYwdTp04FCi5XPGrUKEaOHMlDDz1UxDuM8VuXu7s7y5cvJyQkhOPHj1OrVi18fHx47rnniI2NJSoqitOnTwMU2SyklN3pqCSeX30839fC3h/G9/sjuJGSQVhsCn+fjaWvTx0+eajgshlVzdxhbZjQuTELd1zgr9AYbmdkVUiZhCqR3E3B0dGRo0ePsnfvXnbu3Mn48eOZN28eU6ZMAfIvI7tv3z7WrVsHQP/+/YmPjyc5ORnQCmTZ2dkV69h79+6lffv2WFhYMHfuXJo0aVJo+d6xY8diaWnJrVu3iIqK4oEHHgAwVnEsrJRu06ZNjTXmc5cqvtvOnTv5+OOPSU1NJSEhAV9fX3r16sWtW7eMtWAmTpxorAW/bds2Tp48aZzEIykpiQsXLtyT3NPS0ggMDCQqKoo2bdowaNCgIssVF9egQYNwd3c3Ph8wYICxrk/btm25fPkyvr6+XLx4keeee44RI0YwePDgEh9HKb5NJ6/x7M85ib2hqx2fjA3gelI6DrWssLK0MM5BqsvWcyA8nm7NPLC0qHo3TwtiaSFoXscRfy9X1odc49djkTzazbvcj1MlknthV9gVydLSkr59+9K3b1/8/f1ZsWKFMbmXtLxvUSV6c+vVq5cxSQIkJycXWr63qH0XVko3d+lfS0tL0tLS7tk+PT2dmTNnEhwcTKNGjXj77bfvKbOb3zEXLlzIkCFDCl3vTpt7amoqQ4YMYdGiRUyZMqXQ880td/nf4pb+hZz3zc3NjRMnTrB161a++uor1q5dW+jkIkrpxSSnGxN7h8aujA5syOTu3gWub21pQZ9W5jm/cnkYG+SFtaWgc1OPCtm/anMvwLlz57hw4YLxeUhICE2aNCl0m169erFy5UpA6/VSu3ZtnJ3vrSFxdwnbohS3fK+TkxNeXl6sX78e0K527yTN4pQOLijGO0mzdu3apKSkGK/GXV1dcXJyMvYiWr16tXH7IUOGsGTJEuPcqOfPn+f27YKnGrO3t+eLL77gv//9L/b29gWe792/O29vb44ePQpgjKsk4uLi0Ov1jBkzhvfee6/YN6+Vkpv+g3Zv5L52Dfh1Zo9CE3tN4GxrzWPdvPGp51Qh+1fJvQApKSnGUr0BAQGEhoby9ttvF7rN22+/zdGjRwkICGDu3LmsWLEi3/X69etHaGhokTdUc1u5ciXLli2jXbt2+Pr6smHDhnzX+/HHH/niiy8ICAige/fuXL9+ncGDBzNx4kS6deuGv78/Dz30UJEfLndu1AYGBlKrVi2mTZuGn58fQ4YMoVOnTsb1li1bxrRp0wgMDOT27dvGZo8nn3yStm3b0qFDB/z8/HjqqaeK/IbTvn17AgICWLVqVYHnO2HCBD755BPat29PeHg4L7/8MkuWLKF9+/al6p4aFRVF3759CQwM5JFHHuHDDz8s8T6Uoh0Ij+OE4Sbp68NVhc3KoEr+KmVyp/QvwLx584iOjmbBggUmjqp8qb/F0vvoz7O08nQk5EoiPxy6zOm3h5hFjfXqQpX8VSrMH3/8wYcffkhWVhZNmjRh+fLlpg5JMRO3M7JYsivc+Lx/67oqsVci9ZtWymT8+PH3TEitKMA9I00HtKn4MrdKDpXcFUUpd5lZet7a+C921pa8eV9bLsSkMD6oapYMqKrMOrlLKatkcSCl+jCHe1JVzY8HI3hjgzYx+rujfXm4c2MTR1QzmW1vGVtbW+Lj49V/LsVkpJTEx8cbB4MpRdt5NtaY2AEmdFKJ3VTM9srdy8uLyMhIbtyo+KL2ilIQW1tbvLy8TB1GlRB7K53Hl/9jfD6jT3NsrMz2+rHaM9vkbm1tXWAdEkVRzM/Ph68YH7872pdHuxY+6E+pWGab3BVFqRp02XrGfnWQkKuJAOyb0w8vN3vTBqUUv81dCGEphDguhNhkeN5UCHFYCBEmhFgjhLAxLK9leB5meN27gmJXFMXEUjOzaPn6FmNiB1RiNxMlaRB7ATiT6/lHwGdSyhbATWCqYflU4KZh+WeG9RRFqYauJuQtNNe6guqkKCVXrOQuhPACRgDfGp4LoD9wp1LTCuB+w+PRhucYXh8gVH9GRamWriXlJPfh/vVYNKmDCaNRcitum/vnwCvAnY9lDyBRSnmnElQk0NDwuCFwFUBKmSWESDKsX/pJRxVFMUt3bqL2almbLx/ugEU1qrte1RV55S6EGAnESimPlueBhRDThRDBQohg1d1RUaqedF0228/EMD6oET9O7aISu5kpTrNMD2CUECICWI3WHLMAcBVC3Lny9wKiDI+jgEYAhtddgPi7dyqlXCqlDJJSBtWpU30L8itKdXQ7I4snVwQjJXRvUTGTTShlU2Ryl1K+KqX0klJ6AxOAv6WUk4CdwJ2JLCcDdwqMbzQ8x/D631INM1WUauPQxXh839rKvrA43B1sqvVsSVVZWYaPzQFeFEKEobWpLzMsXwZ4GJa/CMwtYHtFUaqYQxfjmbD0EACPdWvCjhf74GpvY+KolPyUaBCTlHIXsMvw+CLQOZ910oGxdy9XFKXqe/on7dbb78/2xN/LxcTRKIVRhR8URSkWKSVpumzaN3ZVib0KUMldUZRiuZqQRrpOz9iOqi57VaCSu6IoxfLVHm3KPL+GziaORCkOldwVRSmWOwOWfFSJgSpBJXdFUYqUlKoDoHNTd2pZWZo4GqU4VHJXFKVQaZnZtHt3GwAz+zY3cTRKcankrihKofZc0MqDjO3oRV+fuiaORikuldwVRSnU2ehbALwz2tfEkSgloZK7oigFCr2WzGfbz9O8jgP2NmritqpEJXdFUfKVlpnN8C/2AjCmo5okvKpRyV1RlHwdvKhNwfDioFY83UfdSK1qVHJXFOUeUkreWP8vFgKe6tMMNZla1aMa0RRFucemk9FEJWpT6Kl+7VWTunJXFCWPsNgUFu/SSg080aOpiaNRSktduSuKYpSZpefFtSGciU5m9hAfnunXwtQhKaWkkruiKEYfbD7DycgkPh8fyP3tGxa9gWK2VHJXFAWA9cejWH4ggqk9m6rEXhgpYf3TYO8Bbe6Dxl1NHVG+VHJXFIXUzCze3HCaoCZuzB3W2tThmLf4cDixSnt88EuYexVsza8Msrqhqig1XGpmFu3e2UZyehavDm+NtaVKC4UK35H3+bVjpomjCOrKXVFquJCrieiyJcP969GxibupwzFP//4Gp37RHkefBPdm8Miv8EUgJEWZNLSCqOSuKDWUXi/55VgkH/95Dld7az54wN/UIZmvQ19BzGlwbQK1nKDTE+BUT3vt5GoQFhD4sGljvItK7opSg2TrJQfC46hlZcn8rec4EpEAwG8zu+Nqb2Pi6MzIrRiIDYWTa7TniVeg9Uh48Ou86zUMgkt74dIeaDsKbBwqP9YCqOSuKDVEui6b1m/8ec/y9c/0ILCRa+UHZG4ybsHhryAhAkJ+uvd1l3yKp03bASfWwG/T4YMGMGkdtBxY4aEWh7pzoig1xIaQvG3DPp5OBP9noErsdxxfCX+/p7WvO3vB/V/BE1vByk5rdvG9P//tGgTmPL77ZqsJqSt3RakhNp+6DsBrw1szvbeq8niPC1vBoyU8F5x3+ZwIQIK1Xf7b1fGB16Lhg/pwaDEMehcsrSs62iKpK3dFqSGu3kxlYJu6KrHnps+Gk2th1zwI/xvajr53HWvbghP7HTb2ULet9jg2tPzjLAWV3BWlGrlxK4OjlxPQ62We5fEpGVy8cZvmdR1NFJmZiT4Bt+Ng3ZPw6zTY9SE07ga9Z5d+n/cv1n5+3RsWdYHsrPKJtZRUs4yiVCPDFuwlLiUDgIOv9qe+ix0XYm4x6LM9ADR0LeIKtLrKuAX7PofUeAjdAGkJYG0PulSo3w4eXgOOnmBRhuvdBu21q/fYULhxVjuWk2e5nUJJFXkmQghbIcQRIcQJIcS/Qoh3DMubCiEOCyHChBBrhBA2huW1DM/DDK97V/A5KIpicCexA3y9+yIAr68/bVxWY7o7ZtyCc3/CnvmwdjJ86AV758PR77XEDlpit7aH8T+Bc/2yJfY7pu+Cvq9pj7e/Dee2mOwKvjhX7hlAfyllihDCGtgnhNgCvAh8JqVcLYT4CpgKLDH8vCmlbCGEmAB8BIyvoPgVRQGS0nT8vzUheZYtPxBByNVEQq4mAvBU72aM8K9f+cFVNr1eaxpJuJizzM4dgp6ALjNgfgtwqAsvhGi9YIpqTy8Jq1rg3VN7fOJn7V+dNvDMofI7RnFDKWoFKaUEUgxPrQ3/JNAfmGhYvgJ4Gy25jzY8BvgF+FIIIQz7URSlAgxfsNc4c9Km53qyYMcF/gqNMSZ2gFeHtzFRdJXodjx82gayM8BnOPSYpS1vEKglXoCHV4OnX8UNOKp71+/5xhnIygSryv3WVKw2dyGEJXAUaAEsAsKBRCnlne8bkcCdGqENgasAUsosIUQS4AHElWPciqIAYbG3GPjpHuPzTt5u+DV04YsJ7Xlk2WHGdPDiUlwKA9uYru23QmVlwt7/wvk/wb0pnN+mJXYEPPAV2Lrcu43PsIqNyd4dpu2Eb/rlLEu6Ch6V20upWMldSpkNBAohXIHfgDLXBBVCTAemAzRu3Lisu1OUGun9P84YH/s3dOGHJ7oAYGdjybqnu5sqrIqXmgBbX8spvQsQHaL9dGsKzxzOuVI3hYYdYM5lOLgI9nyslScwx+R+h5QyUQixE+gGuAohrAxX717AneFvUUAjIFIIYQW4APH57GspsBQgKChINdkoSgltOnmNneduaI+f64lvA2eEECaOqpIcWZqT2P3GQKdpkHId4sKgw2OmTex32LlCv9cgdL32z81bm+CjfkClHL7I5C6EqAPoDIndDhiEdpN0J/AQsBqYDGwwbLLR8Pyg4fW/VXu7opS/Z38+DsCrw1rj1zCf5ofqKjMVgr+Dpn1g8kZTR1M4IaBRZ/h3A/x4P1hYwxs3tOUVrDhX7vWBFYZ2dwtgrZRykxAiFFgthHgPOA4sM6y/DPhRCBEGJAATKiBuRanRcl8vjQioAT1gAK4dh7gLcOwHSImBB5eaOqLiqdMGMg2FyPQ6SImtlP7vxektcxJon8/yi0DnfJanA2PLJTpFUfIIuZrIzduZdGjsBkBdp1p4udmbOKpKELYdfhqT89yjJXj3Ml08JdFxilb7PfxvCFkJt66ZR3JXFMU8HL18kzFLDgCw8GHtemv+2HamDKlynP4Vfnkc7Nxgyh/g3FDrBVNV7i/UcgT/h7TePCErtcFVh5ZoH1iD34PAiUXvoxRUcleUKkCXrTcmdoDnVmnt7a08nUwVUsXKSNGaXm7HaYnd1gUe+g48fU0dWel5tAQLK9g9L2fZ+qe1UbIFlRMuA5XcFcXMSSkZ+OluQOvHHp2UTuRNbcCSh2MVLiegS9faoGsZPqDSkyA5Wisd8NMYyEjKWXf0Imje3zRxlhdbZ3j6ACwytGYHTtK6dFbQYCqV3BXFzF1NSONyfCqt6znx87SupKRn0f7//gLA2rKKFXa9cQ7+N0Ub8n/jPGSmaEm77WjY+jpk3spZt/VI7Qbq0A+ghXnMblRmdXxyHneephUbqyAquSuKmTt4URvcvWBCe6wtLXBzsMHH04nMbL2JIyuB7Cw4/Qv89abW3JJb+I6cGYwe+FprprB3z6nRUt34jIBzf2j93iuQSu6KYsaklHyz9xL1XWxpmasW+6bne6KvSsNHjv8Im2Zpj4Omgt+D8OercP2ktszZS1vWrgb0nB63Qmt6snOr0MOo5K4oZmx9SBRhsSl88IA/FhY5vUOqVHNMWmJOYp9zOaeny/TdcP2EVrHRrYkpI6xcltbaN5MKppK7opip+JQMXv31FM62Vgz3r2fqcEpn2xtw4Avtcb//aEPy77CwqNA255pOJXdFMUNZ2Xo+336BdJ2eDc/0rJqTbGSmaoWzrGzhvgUQoKZ1qEwquSuKGfpixwV+PHSZprUd8KlXRfuy7/oQZDaMXwMtB5k6mhpHJXdFMUO/HteKrP7faD8TR1JC6Ulw5TAkR+Y0xzTqYtqYaiiV3BXFzMQka4OUZg/xoWfL2qYOp/gSLsHCjtrV+h3Td2mDd5RKp5K7opiZFQciAOjRogokdinh1nXQZ2ldG2U29HwR2j8CtZzBsY6pI6yxVHJXlGI6GZlIm/rOFd4NcW3wVQa0rks7LzOt0a7PhsNfw7EVWn3ymFN5X+/7aqXPF6rcqwp1llUU07kSn8qoL/fzf5tCK/Q4CbcziUvJpFtzD/OcVUlKWPsYbH0VbpzV/nm0yHndqb5K7GZCXbkrSiFuZ2TxydZz+BtmOtp9/kaFHOeXo5H8eOgytzO0OecDG7lWyHHKbO2jcHYTNOsH932eM4T+7B+weiLUq5wp5JSiqeSuKIVY889VlhvawAEux6cSHJFAkHf5jjB8+X8njI9trS3o2KRih6aX2vmt2s8JK/NWM2w9Aib9Al5BpolLuYdqllGUQsQkp9+z7MudYeV6jDPRyXmeb3mht3k2ydyOh+xMrU09vzK1LQdVeL0UpfjUlbuiFEBKycrDV+5ZvuvcDTafima4f/nMXbrqyBVqWVmw55V+WFoIajvWKpf9lqtVD8O5zdrjBh1MG4tSLOrKXVEKcCMlg5SMLBxr3XsN9OuxqHI5xu2MLDaEXGNQW088nW3NM7FHHs1J7KO+rPqTZtQQKrkrSgHOXdcmjlj6aEfOvDuUfj45fbajEtPK5Rj7wuJIStMxsXPjctlfhYg6qv2cdRo6PAqW6gt/VaCSu6IUYN8FbZIMn3pO2NlYsvSxnJuF+bXFl8baf67iZGtFR28zbKu+0599y2yo5QIuXqaOSCkBldwV5S6xt9J5cU0IX++5CICHoanE2tKCiHkjeGlQKxJuZ5Kuyy5sN0XaHxbHjrOxTOjUiFpWlmWOu9z9+xtseUV77Dtaq8GuVBnq+5WiGGRm6Tl9LYkHFx8wLps1sOU963m62AIQFpuCX8PSjSI9cimBR5cdxsbKgse6eZdqHxUqPQnWTdUev3QOHFQZgapGJXdFQeux8uqvOcPo3xnly+Tu3vmuW8dJu5KftSaE7S/2KfGxpJS8/0coQgg2PNODRu72pYq5woSsgvUzcp47VdGJQmo4ldyVGi1bL1l/PCpPYl/4cHvua9egwG26NvUo0zF3nInlRGQSU7p706a+GVVMzMrQin8dXa61sTvXh36vmToqpZRUcldqrHlbzvLV7vB7lvdrXbfQ7exsLBkf1IjtZ2JKfMyY5HSe/CEYgJl9m5d4+wq17Q0IXgYtB8PQeeBhZvEpJaKSu1JjpOuyWbbvEmGxKfx2PKef+suDWzHUrx5u9jakZmbn26/9bi09HVkTfJX4lAzjDdfiWJxrdGtdZ9uSnUBF0aVDyE9w5GsImgojPzV1REo5KPKvWAjRCPgB8AQksFRKuUAI4Q6sAbyBCGCclPKm0MZNLwCGA6nAFCnlsYoJX1GKZ8/5G7y+/hRXE3L6pwc1cWPJIx2NbegAxW1wuTP13ZJd4fxnZNtibfPn6eusCb4KwNSeTYt5pAoWexY2vwwRe8HWFXq9aOqIqiS91PPJP58QkxpDh7odeKTtI6YOqVhX7lnAS1LKY0IIJ+CoEOIvYAqwQ0o5TwgxF5gLzAGGAS0N/7oASww/FaXSZWbpmb/tHMv3R+BsZ81/x7YjMU1Hh8autG9c+r7lvg20XjLf7rtUZHI/ez2ZDzefZc+FG/g3dOHbx4LM46r9dhx80x90t2HoRxA4Uc2aVAxxaXG427pjIXJ6kp+KO8VPZ37C1tKWw9GHzSK5F9nPXUoZfefKW0p5CzgDNARGAysMq60A7jc8Hg38IDWHAFchRPkU4VCUEriVrqPf/F0s3XOR7i082DqrF2M6ejG1Z9MyJXYAdwcb+rTSugcmpekKXfe1X0+x+/wN2nm58t2UTqZN7FJCxD44tAQ+D9AS+7CPoesMldiL4Uz8Gfqt7cf6sPWA1vPpUtIl9kTuwUJYMLHNRJIzk0nVpZo2UErY5i6E8AbaA4cBTylltOGl62jNNqAl/qu5Nos0LIvOtQwhxHRgOkDjxmY89FqpcqSUpOv0zP31FFGJabw0qBXPDbi3v3pZDfWrx+7zN3h02WE2Ptsz3ziW7A7n2JVERgTUZ9FEExfcOrEGfpued9mgd6HLU6aJp4pJz0pn3KZxAGyN2Eo9+3oExwTzzalvAPBx88HHzQeA67ev08y1mclihRIkdyGEI7AOmCWlTM5dklRKKYUQsiQHllIuBZYCBAUFlWhbRblbbHI6RyISOHQxnk0no0lM1a6m5w5rzYw+FdPrY7hffV799RQZOn2+r286Gc3Hf57T4hjaukJiKJHgZTmP247WZk3qNM108ZhQqi6V+LR4Gjk3KvY2T29/2vj4wLUDHLh2IM/rjZ0bU99Ra6SIvh1dNZK7EMIaLbGvlFL+algcI4SoL6WMNjS7xBqWRwG5f2NehmWKUu6uJabx1I9HORWVBIClhaBNfSeaeDgwoVMjHq7Aglwu9tb0blWHPedvkK7LxtZaKyEQFnuL7/ZH8LOhXPCCCYHmMVAp0fCFevh86FzzknpGdgYv736ZhPQEQuNDydJnsWjAInp79S50u8zsTD7+52OCY4KNy34Y9gMCgYWw4MC1A/zv/P/o7dWb+g5act8btZeu9btyO+s2ALaWtthYVu70g8XpLSOAZcAZKWXuPlIbgcnAPMPPDbmWPyuEWI12IzUpV/ONopSLyJupPLkimLOGyo0eDjZ88KA/fVrVMSbZyuDj6cie8zdo/cafXHh/GNaWFkz69jAxyRmA1itmdGDDSosHgJRYWNoXXBrB45vBwlLr7ngrGvq+ViMTO0B4Yji7ru6ijXsbutXvxt6ovWyN2IqdlR2NnBpRz0EbiZuWlYadlR0AHx35iJ/O/JRnP5/0+YT2ddsbnwfUCWBGO21Eb7Y+m3oO9Vh5ZiUrz6w0ruNSy4W/HvrLuN/KUJwr9x7Ao8ApIUSIYdlraEl9rRBiKnAZGGd4bTNaN8gwtK6Qj5dnwErNJqXkt+NRvLg2Z1q6eQ/6M8FEJXNfGdqab/ZeAmDZvksM96tvTOwPtm/IG8XsJllufnwQLu+HrHRIjoIPG2k3SgPGAxLcmlRuPGbi9/Df+SH0BwDe7v42bT3aMnP7TDaGb2Rj+Ebq2tVl+9jtRCRHMGr9KJ4KeIpnAp/Jk9jf7f4u9zW/DyuLgtOmpYUla0auoc8arSyFf21/mrk0Y0P4BrZGbOVayjX6N+5Pa/eKb6YTUpq+uTsoKEgGBwcXvaJSo+04E8PUFTl/J0sf7UjvSr5Sz8/RywmMWXIwz7KPxvgzvlMlfODo9RBzGuoHwNrJELoeWg6Bpr0h7hyE/Q3JkTnrz9gP9fwqPi4z0/HHjmTqMwE48PABnGycOBJ9hNf2vUZMqjbS+KWOL5GcmWy8QZpbb6/eLBqwqNjH++bkN3xx/Aueb/88QfWCeGzLY8bX+jbqy8L+C8t4RhohxFEpZb4T16oRqkqVkJqZlSexb3mhl9nUZenQ2I1JXRrnmZJvREDBtWnK1YEFsP1tGPy+ltgBxnybt1vj3v9Cndbg1Rkca151x/SsdGNif6XTKzjZaAPQOtfvzPax25FSct/6+/jv0f8CYGdlh52VHQnpCdR3qM+kNpMY7zO+RMec6j+VLvW70Nq9Nbcyb+V5bdfVXSw9uZTpAdPz37icqCt3pUp4Y/1pfjx0mf+MaMPUnk3NcgJp77l/ABD2/jCsLCtoqgS9HpJy9TRe9yREHsl5PnEttBpSMceuAO8deo/wxHAmtpnIwMYDy/S+pupS+fTopwzxHkKnep0A2B+1n5k7ZqKXet7t/i4PtHwg320vJV3i3/h/scCCrg26kpGVwUu7X+Ktbm/h4+5T6pju6PpzV27rbtPMpRkXky7ibOPM/of3l3m/hV25q+SumKVjV26y+9wNWtR1JCUji1d/PcXDnRvz4YP+pg6tQLG3tNmZ6jpV0CAlvR5+Hgth2/Mub9Be66/u0QKcK+kbQznI0mfR/secG5PfDfmOPy/9SXBMML/c9wvWltaFbv/tqW/ZF7UP0Hq0nIrLqezp56E1PZ1JOIO9lT1PtXuKh1o9hIO1QwWcSdGSMpJIytB6dL2460XO3TzHk/5P8kKHF8q0X5XcFbN0OyOLP05GM6ajF5YWOVds0Ulp9PpoJ1n6nL/Nhq52bH+xD3Y2ZjhjUWX5b2utx0u3Z6Gu4UatENB8ADh5Fr6tmdkftZ9ZO2eRnp3O8KbD2Xxpc57Xx7Qcg29tXwY3GYxLrbwTomyN2MqSkCVcTr5MPYd6xr7ltW1rcyHxgrHXC2hdEJ8JfIYWbi0q/qSK6VjMMSb/ORmA/Q/vx9mm9M2LKrkrZuFS3G3SMrNpXc+JQxfjmfjtYQDaNXLl4zEBtPJ05Ojlmzz23RFSM7P5eEwAsbfSaVHXiU7ebiWqvljt7P0UdryjPX4jDoq4qjVXWfoswhPDmbptKpnZmbzQ4QVGNhvJnsg9xKTGkJGdwbcnvyVLZgHQpX4XpvhOAeBswlmu377Onsg9CATt6rZjZruZeLt4m+6ESml/1H5mbJ/Bd0O+MzYhlYZK7kqlS07X4WxrjV4vmb/tHIt33Vs3PTcvNzvmDmvNsz8fB+CFAS35f4NaVUao5i89GeYZxgW+eMbsm150eh2pulT2Re1jQ9gGHmz1IEO9hxISG8KjWx41rjeq+Sje7/n+PdvrpZ6Q2BDj1W1+Pu/7OQOaDKiQ+CtDXFoc/db2o69XXxYOKH3PGdVbRqk0er1k2b5LvL/5DA92aMjJyCTCYlMA8PF04lyM1nMgqIkbXZq5c/TyTQ5dTCDyZhpLDRNSL5gQWPkDf8xVUhR8ZmiCmfCz2Sf29Kx0Zu+eza7IXcZlB6MP4mHrwRNbnwDA29mbT/p8QkvX/Ov9WAgLOnh24MikI1y4eQFJzgXo6bjTpOpS6duob0WeRoWrbVcbB2sHQm6EoMvWFXl/oTTUlbtSrt7e+C/LD0TkWfZ4D29mDWyFs60VUsI/EQl0aOKGtaFHyYaQKF5YHQLAZ+Pb8UB7r0qO2kxlZ8HCDpB4WWtnH/gOWJrn9diOyzv4N/7fe/qIj/cZz5pza4zPx7Qcw+tdXq+QZFbVrPh3BfOD5/NG1zcY5zOu6A3yoa7clUpxIeYWq45coVszD76ZHMTy/Zfw93I1lsYF7f5fl2Z5p8QY7l+fVUeu0LS2o0rsuZ3brCX2we9B9+dMHU2+7kxScfcQfdDqr/h6+JKqS+Xw9cM80uYRHvdTA9bvuK/5faTqUmnrUTGjmNWVu1JuHlpygIj42/w2s4d5FMqqyiL2wfIR4FAHXjqn1YcxQ1EpUQxdNxSA17u8zlDvoaw6t4pRzUfR0FE1rVU0deWuVLhriWkcu3KT5we0VIm9rHL3jGn3sNkmdoAryTmjcpu5NMPV1pWn2z1dyBZKZVHJXSkVKSXf7r1E5M1UVhy8TGN3eyQwpoNqVikTvR52fwyO9bQaMAPeNHVEhfrP/v8YH/vVrnk1a8yZSu5Koa4lprE2+ConI5M4FZXElO7eJKfr+GbPRXKNMeJKQipTezZVV+2llXAJrh2Hm5cgKw36fghB5t0+nZKZQmxqLCObjeSloJewt1bvvTlRyV3JY/f5G3y1K5zvH+/Ejwcvs2DHBVIysrC0EGTrJZ9sPXfPNiue6IxeL+nrU/OKUpWbdVMh6qj22MoWWg4ybTz5kFISlhhGWlYaEsmuq7sAGNRkELXtaps0NuVeKrkrXEtM4+z1ZACeWK7d2G79xp8A9GlVhzlDW9OmvhOxtzL49VgUt9J1+DZw4VpiGo/38K64Ilk1xa3rcC0EgqZC5+lg52aW5QQOXDvAjO0z8izr6NmRng3vnT9WMT2V3GuY5HQduiw9ey7c4M/T17mSkMaZ6GTj6w1d7ejjU4d/ryXTtr4z79/vh4Wh7ounsy1P962Y+UhrtKPLQeqh2zPgYb6/3zuJ/bO+n1HLshYO1g4E1g3EQqgPd3OkknsNkZSmY9xXB40jRO9oVtuBgW3qcvhiAt1bePD+A/7Ursk1XCpb2k04uBia9jLbxK7L1nEj7Ybx+cAmA00YjVJcKrlXI+m6bNYfj6Kxuz3dW+RtA126J9yY2Jt42PNU7+YEebvRoo6j8cpcKURqAtRyLt8RohH74edxkJkCXcyz++Cas2tYfGIxCekJALzV7S0TR6QUl0ru1cSV+FR6f7LT+Dx3fZbUzCx+PRZFxyZu/DKjm1lOdGFWpITLB2Dfp9BqKBz/CaJDtNfuWwAdp5T9GFePwA+jQJ8F43+C1sPLvs9yFJ8Wz68XfuWL418A8Ljf47R0bamu2qsQldyrASklD39zKM+yzaeiuS+gASuPXOGN9acB+HRcoErsRdGlw/dDtW6JcO/EGIe/Lp/kvvtj0GfD9F3aZBtmIkufxd9X/mbzpc3suLKDWpa1WDdqHU2ca+bE2lWZSu5V3JFLCczfeo6oxDTjsl4ta3PsSiLfH4jg/zaFAjChUyO6NfcoaDcKaIl95UNaYnesB/cbJkQ+9mPO/KSxoVqlRpdSDq2/+o/WFJOWoNWLMZPEvjViK5eTL7Pm3BpiU2MB6N6gO18O+BJrC1XkqypSyb0KS9dlM+7rg4DWy2XTcz2Jv51BcMRN9l6IMyb276YE0b+1+XWtMwv6bDixCjY8k7PMowXM2A/WhunyWgyEmFBY0k17fvR76P+fe/dVlKxM2P0RZCRDnzla18dylqXPQqfXYWdlZ1wmpWRrxFYkki2XtnD99nWcbZxp5d6KgNoBtK/bnpd3v2xc//4W9zOz3Uxq29VWib0KU8m9itp3IY71IVGANtHF78/2xM3BBjcHG7w9HDgRmYSNpeD5AS1r9gxGhdn6Ohz88t7lk/6Xk9jv8MxVue/2De1Dobg1X/TZ2qTWqx+BmFPQ+xXo91rp485H8PVgdlzZQURyBPui9rGg3wL6N+4PwLoL63jn4DvGdW0tbdHpdRy+rs2EJdCa6j7u/TG9vXqbbJ5RpXyp5F4FbT4VzcyVx4zP/5zVG8daOW+llaWFWU8kbVLXQuDiLtieq9fHwLehxSCIv6ANKHJvVvg+ji6HbB3cv7h4x/x+OFw9BAh44GtoN6FUoRckOiWax7fmLVXwws4XOPjwQRxtHFkftt643NrCmi1jtuBi48Jt3W1WnV2FTq/DpZYLQ7yHqD7r1YhK7lWMXi/zJPbn+7fIk9iVAiRFwc73IWRlzjLvXjB2BTgY7kXUK6LwlXszSNBmiyL6ZPGOe2mvltgd6sDEtdCwQ8ljL8DN9JtE345m/Kbx+b6+KGQR129fJy4tDoAtD27BzdbNeGXuaunK04Hm2QVTKTuVFaqYv87EAPB/9/vxSJfGqvdLUaSEC3/Bn3O0xNzpSWjcTUvUJU20U/8ieGFb3vdw44uYMzTa+UHBzSvZOlg+MqcL5bSd4NqoTKdyt95reud5vqDfAuo51MPb2Ztuq7oZJ9DwdvZmmv80vJxUxc6aRCX3KiQxNZMXVh/Hzd6aUe0aqMRemKxMOLQYTv8C10+BrSs8vgWadC/V7o5EH+GFnS+QUl+7MT25fl127P4IEfQEONXLu3LIKq0I2NVDEDABWg0u98Se28tBLzOx9cQ8U9d18uzE4euHmdt5LpPaTKqwYyvmSyX3KuBWuo63Nv7LwfB40nV63h3th4ud6sWQx60YuHJAm8HowjZINEwiYV8bOk3TerfYuZZ4t//G/8vHRz7G08GTFF0KU3ynsPzf5dywsiJVCBx+ewoe26DNdxpzWqsRs95QXKt2Kxi9qFxGtV6/fZ20LK27a32H+liKnJu5E9tMvKdXyzeDtblM1QVAzVXkX50Q4jtgJBArpfQzLHMH1gDeQAQwTkp5U2h/SQuA4UAqMEVKeSy//SrF983eS/x6TOsZ07S2A+OCKu4qsMpJioLVE3OaPxDg5g0eLaHj5DLPPbrj8g6OxWp/wg7WDrwU9BKt3Frx2r7XiKjvi+/10/D7C9pN1twGvAVdniqXxH405ihT/pxifN7MpRnzes0D4IOeH+TbXVEldaU4f3nLgS+BH3ItmwvskFLOE0LMNTyfAwwDWhr+dQGWGH4qpZSRlc2qIzlTmb02vI0JozEjx3+C2DPaVXrcebD3gJGfa3XQre2K3Ly4ziacNT6uY6fVq3et5QrAf5yt+e1anJbYnRtCsvYBjFN96Drz3u6UJaCXem6m3wTgqxNfYWNhwzs93uFI9BF+C/uN9w+/D4Cvh2+pj6FUb0UmdynlHiGE912LRwN9DY9XALvQkvto4Aepzbp9SAjhKoSoL6WMLreIa5jxXx/ixq0MVj7ZBd8Gzrja25g6JNOKD4fg73L6p9u5aUm94xQo56tVXbaOvVF7AZjmP40gT20e4o6eHQGI0WfCy2Egs8GhLnzmC7euwYtnyhzL838/z+7I3cbnU/2mMrLZSDrX68xvYb9x4sYJAOo51CtoF0oNV9rvjJ65EvZ14M7wx4bA1VzrRRqW3ZPchRDTgekAjRs3LmUY1U9Sqo5hC/YwKrAhIwPqE3I1kfoutvS4q8pjjXMtBA58AafXac/rtoUnt4NNxQ24uZikdXt8rctrPNz6YeNye2t7+jXqx86rOwnTJdHCrYX2wrP/aD/LmNhjbsewO3I33Rt0p1+jflhZWDG8qVZYrK59XT7v+zmzds0CyDMSVVFyK3ODoJRSCiFk0Wves91SYClAUFBQibevrkKjk7mWlM5Xu8OxsdIGlKye3tXEUZWTzFTIztRubMaFgb279u9u+mxY+5h2la7PguyMnBukTg2g69PQaWqFJnaA8zfPA1rPk7tN9p3Mzqs7eWDjAywfuly7mq/lWOpjZWRnEJUShVstN17d9yoAz7d/Ht/a9za73Bl5CqptXSlYaZN7zJ3mFiFEfSDWsDwKyH23z8uwTCmGzCw9s385YXz+xY4LNPGwp3FVn3T61C+w91NICIes9JzlFtYw5AOtq6BDHS1Z69Lgh/u1boTN+oKdO1hYaaV3O0+H2i1LfPhsfTYSaexhkl9CXH12NTuv7mSa/zQaOWl/widunMDKwoomLvdWRAyoE4BrLVcSMxJ5bsdzHJh4oMRxgdYLZsKmCcSnx+dZPq7VuHwT+534V49Ybayxrij5KW1y3whMBuYZfm7ItfxZIcRqtBupSaq9vXgu3kjh5f+dIPJmGpO7NWHFwcsArHu6e9W7OtPr4cJWSE/S6pYHL9OWW+T6c+vwmDZ6c8ts7Z+jJ3h1gsh/ICUGavvAI78Wv35LPmJTY3l2x7NcTLpIRnaGcbmnvWdOU4rB0etHSc9O58C1vEm6a/2u+fZGsbawZvf43bT7oR2t3FuVOsZP/vmE+PR4BjQewI4rOwDo49WHN7q9Ueh2BSV+RbmjOF0hV6HdPK0thIgE3kJL6muFEFOBy8A4w+qb0bpBhqF1hXz8nh0qRmmZ2Tzz8zEOhseTpssGoFszD94e5csQv3ogqXpT3v37G2yZoyXoO5r2hj5ztRGh1naQkaI1YSRFwqU92r8Tq+DsJmjUFXq8oPU2uetDbU/kHt4/9D6NnBvRoW4HlpxYAkCnep2QUqKXeiQ5P6NTormRdoOBjQfSwq0FFlhwKfkSZ+LPkJyRnGffPu4+DGg8ACcbpzzLu9YvuEnMQlgYk3Jsaix17esW61cUGh/Kf/b/B0drR0LjQ/G09+Szvp+xIXwDofGhvNalfIuKKTWT0Dq2mFZQUJAMDg42dRiVaue5WB7//h/j8+f7t2B0+4Y0r1P6dttKI6U2WOfuq2pdOizsqFVNHPSu1i3R0gZcvAq8yajT67BOioLfZ0HrEdB5Wr7rXb99nUG/DMr3tQ51O2AhLLAQFgghEAgshAWWwpIxLccwoMmAspxtoTZd3MSre18loE4APw770Vh4S6fXYW1hTVJGEjaWNuyP2k8z12ZcSrrE/H/mE5kSSRv3NrjWcuWFji+oLo1KqQghjkopg/J7TY1QrUS6bD3zt57j9LUk9odpbaxv39eWyd29zbfpJeMWnP0jp0+5Lg1uXtJubD69X2t2SU+CVkO0ErrJkfDob9C8f5G73h+1nxnbZ7Bi6AraPbIOSwtLEtMTsbe258SNE1xKukRbj7YkZyYza+csACa3ncz9Le6nrkNd7CztsLKwMunvbmSzkWwI28Ch6EOcjjtNQJ0Afg//ndf2vcb7Pd/n9X2vF7jt2vvWVmKkSk2jrtwrwZnoZD7ffp4TV5O4nqzdUGzoasefs3rhZGtmZQSun4Lg77UbnXvnw8HFoLsNwgLq+kLcOa3HSz50gK79RM50fZIj148w3mc8brXc8k2+Ukoe3PggYYlhAAz1HsroFqN5envBVQq/H/I9QfXyvUgxqYPXDjL9r+kAjGo+ir2Re7mZcdP4eku3ljhZOzHeZzzWltYsPL6QtKw0/nroL1OFrFQThV25q+ReQc7H3CJbL/nvtnPsPn8DXbbEv6ELQ3w9ad/Yjbb1nXFzMLMBSbFnYfFdA4qb9AT/MdBqGDjX15bditHqqFzcCa5NIDmK21cOMsIqjnh5b+L3sM07vZ+DtQN6qScyJTLfMPo26ku3+t2wsbThXMI5Gjs3plv9bvfcBDUXmdmZ9Frdi2yZTW07bTyCtYU1rd1b08yl2T1ldXV6HUjyFPpSlNJQzTKV6FpiGk/9eJRTUUkA2FlbMsyvPrMGtqSZObWnx4drk1ZcO67VZXFqAFcOgZUtODcAYQn+Y6HvnHu3dfIEJ09Ou3rSwLEBN1Jv8LVVMvGX/2Ka/zTq2tclIT3BeMOzX+N+xtl+kjKS2BO5B3dbd6b6TeVxv8c5m3CWz49+zvXU68zpNIehTYdW3u+hHNhY2nB40uFir6+mrlMqg7pyL0fL9l0yzlsK4FTLinUzu9PK06mQrcrHrcxbzN49m8PXD9PQsSEvB71M30Z9c1bIztIKXIXvgFs5vVP1QIqlDZtc3Rjg4oPn8M+gdtFXyAnpCfRZ0yfPsk71OrFs8DJjM8zN9JvYWNrcM22bLluHpYWlmvVHUcpINctUgu2hMTz5QzCezrX4bkonfBu4IKWstJt9k7dM5ljsMUY1H8XG8I00dGzIn2P+BCDsZhif75jFseRLZAvIRpBtYYE2tCcvT3utkoSFsMDH3YekjCQib2nNJw7WDkwLmEZ6VjpLTy4lJlXr7uhk48RHvT6iR8MeKmErSiVSzTIV7NiVm8z8+Riu9tZsm9UHF3vta3dlJPY9kXtYe24tx2KPMajJIN5vO5Xm1q58dvYHXtr1EtsubzOuOyw9kzqBj2JpYYmljSOWwlL7Z2HJiRsnSMtKo4FDAyyEBbFpsZxPOI+7rTvdGnQjIzuDrRFbjb0/mjg3oUv9Loz3GU//Rv2xLMNgI0VRyp+6ci8jXbaeh5Yc4OKN2/z+XE+8a1f8zPGn406z6eImOtvW44Xj/wXATi/ZHBlF7Ww9iRYWTGnhS7guCc+sLFKFBW/F32TwmFWIZn2K2HvB4tPiuX77OrZWtjRzaWa+3TcVpYZQV+4V4EBYHFOW/0Nmlh6A+WPbVUpil1LyxNYnSMtK485Uzz2yBK87t6N2tlaQ01WvZ935U2QJqCWskZN+QdTzz5kIupQ87DzwsCvbPhRFqRwquZfQpbjbvPP7v+w6d8O47Ln+LRjToWHFHVRKSE0AJJt2vkpaVhqeWVnEWFlhZ2HDZ5P3aaVfbw3Tppp76DssY89g2bAjePdClKFaoaIoVZNK7sUkpeSz7Rf4YscFhIAnezbFr6EL/dvUxbmiByLtmc+BQ/MJqVWLJW4u2OolP9fpR3a3Z3Fw8cqp6T12uVawy29MxcajKIrZU8m9CFJKjl1JZPmBCH4/cY2RAfWZO6w1Xm7lXIb3Vgxc2g13ClrVaweNOnHxxErmnl/GmXo5Ran+HLEaj7p+9+7DyVOrtqgoSo2nknsBEm5nEp+SwQurQwiN1hJur5a1WTChPZYW5XQjMeZfOLcFTv8Ksf8aF5+2saFhVhbpLl6MdgVscr4ZzAycmX9iVxRFyUUl97vEJKez7lgkH/95DgAPBxv+M6INw/3r08C1jFOa6dJh2+sQd0Grz3LloLbcxgm6zIBWQ4l0dOfhPx/BGsGTOhsggxlNR/NY1zn8cfEPHmj5QNliUBSlRlDJPZcjlxIY9/VB4/MuTd158762+DZwKd0OdWlw7AdIuAg3zkLkUci8BV6dtYkrmg+A3i9Dgw5gbQvAwfP/0zZFssQ6A0drR2b0fAdLC0smtJ5Q5nNUFKVmUMndICUjy5jYuzR1Z8kjHXEvaWGvW9fhyFI4sRoQWvnbO+r6QqNO4PtAnnbxzOxMbCy148SmxvLBoQ/y7PLHYT+qAUKKopSYSu4Gc345CcDTfZszZ2jrku/gzO+w5pF7lz/4rdZ7xSLvsPyQ2BAORR9i2alluNRywc3WjbMJZwH4bsh3JGYk4lbLzWwrISqKYt5UcgcW7wrjj1PRPNy5Ma8M8Sn5Di7uykns41dCy0FcjgmhjqU9dp5+bL+ynQ1hG4xX6Nn6bP6++rdx84bWDannUI8GDg3oVK8Tnep1KoezUhSlJqvxyX17aAyf/3WBrs3ceXe0b/GG1IduhODvIDkKbBzgxnmwr03Sw6vYlRHNsSMf8OuFX+/ZrLlLcy4nXyZLZuFp78lPw3/C095TDeNXFKXc1djkrsvWcz0pnZk/H8O7tj2LJnbA2rKQioZSwu6PtRukhrb0dCG4ZmXJemdnzjUJ4sDfU/NsMrbVWJxtnKlrX5cRzUbgUsuFVF0qx2OP08ajDe627hV5ioqi1GA1KrnvvXCD2f87aZzqzs1QvfHrR4PwcKyV/0bZWXB+C5z6H4RuQNe0D8lBUzjfpCOvH36PG2laGQLn25EMbjKY4c2G09urd4ETMthb29OjYY/yPzlFUZRcakxy/+yv8yzYcSHPspupOp7v34KmhoJfUkqWnV5GWnoinaJCaZgUw9rkM1yzgEwhSGvaihDLa2Rc+gEu/QBAj4Y9mOI7hS71uqjmFUVRzEaNSO5/nIxmwY4L9GlVhwc7NOSF1SEANK/jwKyBrQA4f/M8Yzbm1GRZeueBswPetdypZeuGtZUdPR086ejZkYaODWnq0pQmzk3UBBWKopidap3cs7L1jFy4j7PXb9GiriMLJ7bH2daa0YENydZL9FJyOyuFfy7v5ON/PgJgSMptBt9OJTHgIU45uTGm5RgC6waa9kQURVFKqFon92/3XeLs9Vu0a+TKmmldsLUS6LMy+DxkEafiTmEhLDhy/QgAQko+iIvnvjaToP/rYOfGOBPHryiKUlrVLrn/cjSS2xlZHLoYz5bT1xnYpi7fTvSH5UNIij7GTM86nLTNuXlaN1vy9o0b+HR5nroPPw82jqDazhVFqeKqVXI/dDGeOVtWIbMc0ac3pqF9NsO9D/DbytnEp4SzoImXcV1HvZ75sXH4Z2TgPOAd6PGCCSNXFEUpX9UquS/ZewL7RlovlpEOz+B7ayVvRSSCANxdqWdfj0eajmB4YjwO+xdiLyVMXAuthpg0bkVRlPJWIcldCDEUWABYAt9KKedVxHHudj77K+2IwKbbi9hkAS7Cmo+D5uBS148Wbi2oZWlokmnUHfTZKrErilItlXtyF0JYAouAQUAk8I8QYqOUMrS8jwUQHxNJ+KrZON6+jF29RBplZPN/N+KJt7Iko8vTtOs0E3eHuvdu6DOsIsJRFEUxCxVx5d4ZCJNSXgQQQqwGRgPlnty/Wv8qh6//ipVtNin2FtywqsWUpGR8mg+B7s9B467lfUhFUZQqoSKSe0Pgaq7nkUCXu1cSQkwHpgM0bty4VAfS6dK5ZWFLlp0H9i51CUy9zYix30Kjew6nKIpSo5jshqqUcimGgaBBQUGyNPt4buxnPFeuUSmKolQPFTFuPgpolOu5l2GZoiiKUkkqIrn/A7QUQjQVQtgAE4CNFXAcRVEUpQDl3iwjpcwSQjwLbEXrmPidlPLf8j6OoiiKUrAKaXOXUm4GNlfEvhVFUZSiqVq1iqIo1ZBK7oqiKNWQSu6KoijVkEruiqIo1ZCQslTjh8o3CCFuAJdLuXltIK4cwzFX6jyrj5pwjqDOszI0kVLWye8Fs0juZSGECJZSBpk6joqmzrP6qAnnCOo8TU01yyiKolRDKrkriqJUQ9UhuS81dQCVRJ1n9VETzhHUeZpUlW9zVxRFUe5VHa7cFUVRlLuo5K4oilINqeSuKIpSDVXJ5C6E8BFCdBNCWBsm5FaqKSGEMHUMSvmoSe+lEMLkubXK3VAVQjwIfIA2u1MUEAwsl1ImmzSwCiaE6AvUBayklD+bNpqKI4ToAdgBUkq5w9TxVAT1XlZPQogmgGPu+SuEEEKaKMma/NOlJIQQ1sB4YKqUcgCwAW1KvzlCCGeTBleBhBD9gFVAY+BFIcRiIUQDE4dV7oQQg9HOczDwvhBiiYlDKnfqvayehBBjgG3AIiHEKiHE/UIIRymlNNU3liqV3A2cgZaGx78BmwBrYGJ1/NpnOKdhwMdSyvlAT8AFmCuE8My1TpVmaF6bBLwjpXwF6A8ECCG+zLVOlT5P9V5Wn/cyNyGEA/AYMElK2Rc4BPQBJt1J8KaIq0oldymlDvgUeFAI0UtKqQf2ASFo/1GqHcMfxjHARwjhKaVMB6ahfa1/K9c6VdKd/+RSymzgCOAuhLCVUqYCQ4COQohFhnWq7HmCei+pRu/lXfSAK9AcQEq5AO38W6MleZO0wVep5G6wF+3rz6NCiN5SymxDu2UDoJ1pQys/QohGQohaQgg74CDghHb1Y2f4z/I40EUIMcqkgZZd3VyPTwEDgSYAUsoUtKQQIIToYoLYyoV6L6vPe5mb0FhKKdOAhUBvIUQHw8urgWtoV/QYLkQrVYXMoVqRpJTpQoiVgAReFUK0BjIATyDapMGVEyHECOAj4ABaIngRrf3yBe1lcUpKGS2E2AFkmy7SshFCjAReF0KcRnvv5qM1tf0ghJgMXJZSJgshzlIF/1ZBvZdUo/cyNyHEaOB+w+NvgcOALzDKcBP1KPCJEGKHEKKZlPJipcdYVb8dCSFsgB7AU0A6sEBKedy0UZWN4WutF9rk4s8BZ4DJhsddgUC0G8qg9RR6FOgvpTxf6cGWkRCiOfAX8ARaUuuHdvPtPmAcMBrtP4we7cp2kJQy3DTRlo4QoiGwFXgW9V5W6fcyNyFEO2AN2gd1E2Am8AaQBPRC6+SxB8gC/gP0klImVHacVfYTVEqZCewUQuzRnlb+157yZrizfg3tq/sFIFZK+bEQIgvtyq8rcBzohNYENaAqJgODOGCnlHKX4UNtH9p/hg3ASOAkWptlEDCiqiUDQxNMHFoz4nmq93sZD2ypru9lPuoBZ6WUmwGEEJfRPsC/NvzrAkwHbgGPmCKxQxW+cq9uhBAtADfgIrAYOCql/DjX66+i9RJ6WkqZYZooy04I0RPwBlaiXd38IaWcZ3jNAu3GYrqU8kPDMpP1Ey4tw1f2wWhNE/OAk1LK93O9Xl3ey65o5xGHNvbkRynlp4bXqsV7mR9Dz6ZPgEXAP1JKvRBiuGHZk1LKg0KIWmjXa5mmirPKXrlXJ4b2yg+Am2g3olYCXxhu1nxoWG0V8Bpgsj+WsjD8Z7dHu7KxAlLQvrJvE0KkSSkXGP6THMDQlglVr1eFEKIPWhv7C1LKS0KI2cBewzl+alitSr+XAIabv++hXZUnAm+j9WdPl1Iurg7vZW6Gm8C2wG0pZbAQIgKtWS1GCHFVSrnZcIE2VghxyBw+tFVyNzEhRHe0T/yJUsrjQoilQGegO3DI0Gd4NVpXzw5oXa5umijcUjM0m6UIIVagtcuOQ/um0h84IITIklIuAuoDrYQQTlLKW6aLuNQ6At9KKbcKIRoDjmjtrouFEOnADqAbVfi9FEJ4AM+g/c2eFkL8AKSh3U9YYegRuYSq/14CIIQYBnwB7ATqCSHCpJQvCiG+Ap5Hu3G8F+2eQi1z+RBTyd08fJTrZvDraOUUrgltmPp/0G7cdAGmSCmrXDK4Sxba6MxlaH28vdC+rYwXQnRG+2AbV4WTQRZgY3h8pztcONo5DgZ80D64H6/C72UWWlmB1kKIq2g3ET2AULQBPFOBALQ+3lX5vbwzIGsy8K6U8kehjYTfJoT4Rko5TQjxBvCUEOJ1tBupE00Zb26qzd3EDH88DoZuYpZoVzu/A8MNXeSaoPWmcJBSJpky1vJg6FkxVko5TwjxElqb9HtSyncMPaCcpZSmmkm+zIQQ/sAvaDdLt0opvxdCtELrJXJISrlBCOFWhRM7AEKIh4BXAR2wWUr5rtBKDgwENqLVfHKSUt4wYZjlQggxB7gmpfwx17IDwH4p5WwhhBvgB1ySUkaaKs67VcVBTNWKYRDWnaJnAq39MsGQ2B9Ba5u1rg6J3SANbYTmNGAGWrttZyHEDCllZlVO7ABSylPAy2jftJoalp1HG+DjYlgt0STBlSMp5S9oiXwv2qhbpJTb0G6wekgp06tyYjd8IN8RhVa/qnGuZaOA5kKItlLKm1LKveaU2EE1y5gVKWUWWrv0VSHEh2hf46cYRsBVC4bmpqto/YKfkVL+LrRiWmEmDq08bUHrKfK2oZscaN0dP4CqfWMxNynlTSHE38A4IUQm2g3HJsAJ00ZWNoYODmuFEBullBOklD8JIXyA/UKIHlLKK1LKOMM5O5o43AKpZhkzYugjbI024MUare/zBdNGVf6EEI2AuoZRfAghLKrDOIW7CW0o+kNALbT7KKdMHFK5E0K4og2xH4M2mPAVKWWVTe5CKwK2DvgV7d5ILSnlw4bX/g/tin0xUButONoIKeUlE4VbKJXczZAQYgpa/9l/i1q3Kqsu/Z4VEEI4oeWTKj+vgtBKMCejfRP5CtDlSvAPoA1i6gh8LqU8bbJAi6CSuxlSSU9RzIOh2+dSIFNK+bAQwhdIkVJeLmJTk1M3VM2QSuyKYh6klPEY6lcJIc6hlVSoEgXeVHJXFEUphKEH10m03k4PmFuvmIKo5K4oilIIQz/24cDgqnRTXLW5K4qiFEFoM0qlmzqOklDJXVEUpRpSzTKKoijVkEruiqIo1ZBK7oqiKNWQSu6KoijVkEruiqIo1ZBK7oqiKNXQ/wcloc1nkRUlzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dates = pd.to_datetime(yahoo_df['Date'].iloc[n_val_days+1:].reset_index()['Date'])\n",
    "df_equity['percentage_total_return'] = eu.percentage_returns(df_equity['total_equity'])\n",
    "df_equity['percentage_long_return'] = eu.percentage_returns(df_equity['long_equity'])\n",
    "df_equity['percentage_short_return'] = eu.percentage_returns(df_equity['short_equity'])\n",
    "df_equity['percentage_total_return_for_dd'] = eu.percentage_returns_for_dd(df_equity['total_equity'])\n",
    "df_equity['percentage_long_return_for_dd'] = eu.percentage_returns_for_dd(df_equity['long_equity'])\n",
    "df_equity['percentage_short_return_for_dd'] = eu.percentage_returns_for_dd(df_equity['short_equity'])\n",
    "df_equity['updown_actual'] = df['updown_actual']\n",
    "df_equity[\"updown_pred\"] = df[\"updown_pred\"]\n",
    "plt.plot( df_equity['percentage_total_return'], label = 'Total Percentage Returns')\n",
    "plt.plot( df_equity['percentage_long_return'], label = 'Long Percentage Returns')\n",
    "plt.plot( df_equity['percentage_short_return'], label = 'Short Percentage Returns')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max drawdown:  52.874451208080444 %\n",
      "Average drwadown:  3.643631318480831 %\n",
      "Number of days a long position was held:  608\n",
      "Number of days a short position was held:  449\n"
     ]
    }
   ],
   "source": [
    "print('Max drawdown: ', eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[0], '%')  \n",
    "print('Average drwadown: ', eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[1], '%')\n",
    "print('Number of days a long position was held: ', eu.long_short_market_time(df_equity['updown_pred'])[0])       \n",
    "print('Number of days a short position was held: ', eu.long_short_market_time(df_equity['updown_pred'])[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trades:  341\n",
      "Average profit per trade:  1.3005490240765716\n",
      "#####################\n",
      "### SHORT RESULTS ###\n",
      "#####################\n",
      "\n",
      "\n",
      "Number of short trades:  171\n",
      "Number of winning short trades:  67\n",
      "Win ratio:  0.391812865497076\n",
      "Short trades average loss:  -181.45970939867425\n",
      "Short trades average profit:  176.6417910447761\n",
      "Short trades profit/loss ratio:  0.9734491013467184\n",
      "Short trades best profit:  1075.25\n",
      "Short trades worst loss:  -600.25\n",
      "Short trades average % loss:  -1.2114631742342752 %\n",
      "Short trades average % profit:  1.379959218880129 %\n",
      "Short trades best % profit:  7.955542450611091 %\n",
      "Short trades worst % loss:  -4.571326789689373 %\n",
      "\n",
      "\n",
      "####################\n",
      "### LONG RESULTS ###\n",
      "#####################\n",
      "\n",
      "\n",
      "Number of long trades:  170\n",
      "Number of winning long trades:  87\n",
      "Win ratio:  0.5117647058823529\n",
      "Long trades average loss:  -209.06535993303572\n",
      "Long trades average profit:  210.96275592672413\n",
      "Long trades profit/loss ratio:  1.0090756115422284\n",
      "Long trades best profit:  694.8203125\n",
      "Long trades worst loss:  -926.25\n",
      "Long trades average % loss:  -1.02321890008978 %\n",
      "Long trades average % profit:  1.3403747456007546 %\n",
      "Long trades best % profit:  4.069924049602534 %\n",
      "Long trades worst % loss:  -5.528279578727435 %\n"
     ]
    }
   ],
   "source": [
    "total_short = eu.number_of_trades(df_equity['short_equity'],df_equity['updown_pred'])\n",
    "winning_short = eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[0]\n",
    "total_long = eu.number_of_trades(df_equity['long_equity'],df_equity['updown_pred'])\n",
    "winning_long = eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[0]\n",
    "\n",
    "print('Total number of trades: ', eu.number_of_trades(df_equity['total_equity'],df_equity['updown_pred']))\n",
    "print('Average profit per trade: ', df_equity['percentage_total_return'][len(df_equity)-1]/(total_short + total_long))\n",
    "\n",
    "print('#####################')\n",
    "print('### SHORT RESULTS ###')\n",
    "print('#####################')\n",
    "print('\\n')\n",
    "print('Number of short trades: ', eu.number_of_trades(df_equity['short_equity'],df_equity['updown_pred']))\n",
    "print('Number of winning short trades: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[0])\n",
    "print('Win ratio: ', winning_short/total_short)\n",
    "print('Short trades average loss: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[2])\n",
    "print('Short trades average profit: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[1])\n",
    "print('Short trades profit/loss ratio: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[3])\n",
    "print('Short trades best profit: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[4])\n",
    "print('Short trades worst loss: ', eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[5])\n",
    "print('Short trades average % loss: ', eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[2], '%')\n",
    "print('Short trades average % profit: ', eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[1], '%')\n",
    "print('Short trades best % profit: ', eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[4], '%')\n",
    "print('Short trades worst % loss: ', eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[5], '%')\n",
    "\n",
    "print('\\n')\n",
    "print('####################')\n",
    "print('### LONG RESULTS ###')\n",
    "print('#####################')\n",
    "print('\\n')\n",
    "print('Number of long trades: ', eu.number_of_trades(df_equity['long_equity'],df_equity['updown_pred']))\n",
    "print('Number of winning long trades: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[0])\n",
    "print('Win ratio: ', winning_long/total_long)\n",
    "print('Long trades average loss: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[2])\n",
    "print('Long trades average profit: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[1])\n",
    "print('Long trades profit/loss ratio: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[3])\n",
    "print('Long trades best profit: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[4])\n",
    "print('Long trades worst loss: ', eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[5])\n",
    "print('Long trades average % loss: ', eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[2], '%')\n",
    "print('Long trades average % profit: ',eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[1], '%')\n",
    "print('Long trades best % profit: ', eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[4], '%')\n",
    "print('Long trades worst % loss: ', eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[5], '%')\n",
    "# print('Totale trades average profit: ', number_of_trades(df_equity['total_equity'],df_equity['updown_pred'])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average compounded daily returns:  0.16028309401476815  %\n",
      "Average compounded annual returns:  49.958977553497654  %\n",
      "Max drawdown:  52.874451208080444 %\n",
      "Average drwadown:  3.643631318480831 %\n",
      "Total period return:  443.4872172101109 %\n"
     ]
    }
   ],
   "source": [
    "daily_yield = ((1+df_equity['percentage_total_return'][len(df_equity)-1]/100)**(1/len(df_equity))-1)*100\n",
    "daily_yield\n",
    "annualized_yield = (((1+daily_yield/100)**253)-1)*100\n",
    "annualized_yield\n",
    "print('Average compounded daily returns: ', daily_yield, ' %')\n",
    "print('Average compounded annual returns: ', annualized_yield, ' %')\n",
    "print('Max drawdown: ', eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[0], '%')  \n",
    "print('Average drwadown: ', eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[1], '%')\n",
    "print('Total period return: ', df_equity['percentage_total_return'][len(df_equity)-1], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = pd.DataFrame({'Total (375 days) %': [df_equity['percentage_total_return'][len(df_equity)-1]],\n",
    "                       'Compounded Annual %' : [annualized_yield],\n",
    "                       'Compounded Daily %': [daily_yield]}, index = None)\n",
    "\n",
    "run_down = pd.DataFrame({'Maximum Drawdown %': [eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[0]],\n",
    "                       'Average Drawdown %' : [eu.max_drawdown(df_equity['percentage_total_return_for_dd'])[1]]})\n",
    "\n",
    "efficiency_long = pd.DataFrame({'Average Win %': [eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[1]],\n",
    "                       'Average Loss %' : [eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[2]],\n",
    "                        'Time at market (days)' : [long_short_market_time(df_equity['updown_pred'])[0]]})\n",
    "\n",
    "efficiency_short = pd.DataFrame({'Average Win %': [eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[1]],\n",
    "                       'Average Loss %' : [eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[2]],\n",
    "                        'Time at market (days)' : [long_short_market_time(df_equity['updown_pred'])[1]]})\n",
    "\n",
    "# efficiency_total = pd.concat({\"Efficiency\": efficiency_long}, axis=1, names=[\"l1\", \"l2\"])\n",
    "\n",
    "trade_analysis_long = pd.DataFrame({'Total trades': [eu.number_of_trades(df_equity['long_equity'],df_equity['updown_pred'])],\n",
    "                                   'Positive': [eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[0]],\n",
    "                                   'Negative': [eu.number_of_trades(df_equity['long_equity'],df_equity['updown_pred'])-eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[0]],\n",
    "                                    'Positive trades %': [eu.number_of_winning_long_trades(df_equity['long_equity'],df_equity['updown_pred'])[0]/eu.number_of_trades(df_equity['long_equity'],df_equity['updown_pred'])*100],\n",
    "                                   'Best Profit %': [eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[4]],\n",
    "                                   'Worst Loss %': [eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[5]],\n",
    "                                   'Average Profit/Loss ratio': [eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[1]/eu.number_of_winning_long_trades(df_equity['percentage_long_return_for_dd'],df_equity['updown_pred'])[2]]})\n",
    "\n",
    "trade_analysis_short = pd.DataFrame({'Total trades': [eu.number_of_trades(df_equity['short_equity'],df_equity['updown_pred'])],\n",
    "                                   'Positive': [eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[0]],\n",
    "                                   'Negative': [eu.number_of_trades(df_equity['short_equity'],df_equity['updown_pred'])-eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[0]],\n",
    "                                    'Positive trades %': [eu.number_of_winning_short_trades(df_equity['short_equity'],df_equity['updown_pred'])[0]/eu.number_of_trades(df_equity['short_equity'],df_equity['updown_pred'])*100],\n",
    "                                   'Best Profit %': [eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[4]],\n",
    "                                   'Worst Loss %': [eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[5]],\n",
    "                                   'Average Profit/Loss ratio': [eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[1]/eu.number_of_winning_short_trades(df_equity['percentage_short_return_for_dd'],df_equity['updown_pred'])[2]]})\n",
    "\n",
    "efficiency_total = pd.concat({\"Long\" : efficiency_long, \"Short\" : efficiency_short})\n",
    "\n",
    "trade_analysis_total = pd.concat({\"Long\" : trade_analysis_long, \"Short\" : trade_analysis_short})\n",
    "                                \n",
    "final = pd.concat({\"Returns\" : returns,\"Run Down\": run_down,\"Efficiency long\": efficiency_long, \"Efficiency short\": efficiency_short, \"Trade Analysis Long\": trade_analysis_long, \"Trade Analysis Short\": trade_analysis_short}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('../data/Report_NSQ.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_prediction = pd.read_csv(\"../data/model_accuracy_gold.csv\", index_col = False)\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_prediction[\"LSTM_price_accuracy\"] = [acc for x in range(len(df_prediction))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_prediction.to_csv(\"../data/model_accuracy_gold.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
