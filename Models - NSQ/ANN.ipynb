{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image \n",
    "#import package.utilities as ut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.utils import resample\n",
    "from six import StringIO\n",
    "from pydot import graph_from_dot_data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import datetime as datetime\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance\n",
    "import pandas_ta as ta\n",
    "#from package import indicator as idr\n",
    "#from package import euklid as eu\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Neural network libraries\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Visualization\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "#config = tf.compat.v1.ConfigProto(device_count = {'GPU': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary work on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_df = pd.read_csv(\"../data/NSQ.csv\")\n",
    "#yahoo_df = yahoo_df.set_index(\"Date\")\n",
    "yahoo_df = yahoo_df.set_index(\"Date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = yahoo_df[['ROC_1', 'ROC_4', 'ROC_7', 'Momentum', '1 Day ROI', '3 Day ROI',\n",
    "       '5 Day ROI', '20 Day ROI', '6_day_RSI', 'MACD_12_26', 'SRSI_30',\n",
    "       'Williams_1', 'Williams_3', 'Williams_14', 'ATR_14', 'CCI']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = yahoo_df[['ROC_30', '4 Day ROI', 'EMA_12', 'MACD_12_26_9', 'SRSI_30',\n",
    "       'Williams_14', 'ATR_14', 'Previous_differenced']]\n",
    "y = yahoo_df[\"Up down\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5446124763705104"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in 80/20 the dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    #df = data\n",
    "    for column in df:\n",
    "        df[column]=((df[column]-df[column].mean())/df[column].std())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set early stopping monitor so the model stops training when it won't improve anymore\n",
    "esm = EarlyStopping(monitor = 'val_binary_accuracy',patience=50)\n",
    "\n",
    "# Set the optimizer\n",
    "opt = keras.optimizers.SGD(learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[keras.metrics.Accuracy(),\n",
    "    keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.49),\n",
    "    keras.metrics.MeanSquaredError(name='my_mse'),\n",
    "    keras.metrics.BinaryCrossentropy(),\n",
    "    keras.metrics.Hinge()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "77/77 [==============================] - 2s 11ms/step - loss: 8.2553 - accuracy: 0.4648 - binary_accuracy: 0.4648 - my_mse: 0.5352 - binary_crossentropy: 8.2553 - hinge: 1.0000 - val_loss: 9.1677 - val_accuracy: 0.4057 - val_binary_accuracy: 0.4057 - val_my_mse: 0.5943 - val_binary_crossentropy: 9.1677 - val_hinge: 1.0000\n",
      "Epoch 2/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 8.2553 - accuracy: 0.4648 - binary_accuracy: 0.4648 - my_mse: 0.5352 - binary_crossentropy: 8.2553 - hinge: 1.0000 - val_loss: 9.1677 - val_accuracy: 0.4057 - val_binary_accuracy: 0.4057 - val_my_mse: 0.5943 - val_binary_crossentropy: 9.1677 - val_hinge: 1.0000\n",
      "Epoch 3/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 8.2553 - accuracy: 0.4648 - binary_accuracy: 0.4648 - my_mse: 0.5352 - binary_crossentropy: 8.2553 - hinge: 1.0000 - val_loss: 9.1677 - val_accuracy: 0.4057 - val_binary_accuracy: 0.4057 - val_my_mse: 0.5943 - val_binary_crossentropy: 9.1677 - val_hinge: 1.0000\n",
      "Epoch 4/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 8.2553 - accuracy: 0.4648 - binary_accuracy: 0.4648 - my_mse: 0.5352 - binary_crossentropy: 8.2553 - hinge: 1.0000 - val_loss: 9.1677 - val_accuracy: 0.4057 - val_binary_accuracy: 0.4057 - val_my_mse: 0.5943 - val_binary_crossentropy: 9.1677 - val_hinge: 1.0000\n",
      "Epoch 5/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 8.2553 - accuracy: 0.4648 - binary_accuracy: 0.4648 - my_mse: 0.5352 - binary_crossentropy: 8.2553 - hinge: 1.0000 - val_loss: 9.1677 - val_accuracy: 0.4057 - val_binary_accuracy: 0.4057 - val_my_mse: 0.5943 - val_binary_crossentropy: 9.1677 - val_hinge: 1.0000\n",
      "Epoch 6/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 7.9158 - accuracy: 0.4346 - binary_accuracy: 0.4648 - my_mse: 0.5337 - binary_crossentropy: 7.9158 - hinge: 1.0001 - val_loss: 2.7203 - val_accuracy: 0.0283 - val_binary_accuracy: 0.4057 - val_my_mse: 0.5392 - val_binary_crossentropy: 2.7203 - val_hinge: 0.9917\n",
      "Epoch 7/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 2.1615 - accuracy: 0.0538 - binary_accuracy: 0.4648 - my_mse: 0.4584 - binary_crossentropy: 2.1615 - hinge: 0.9944 - val_loss: 1.2692 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.4559 - val_binary_crossentropy: 1.2692 - val_hinge: 0.9763\n",
      "Epoch 8/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 1.3212 - accuracy: 0.0116 - binary_accuracy: 0.4648 - my_mse: 0.4114 - binary_crossentropy: 1.3212 - hinge: 0.9903 - val_loss: 1.1364 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.4231 - val_binary_crossentropy: 1.1364 - val_hinge: 0.9689\n",
      "Epoch 9/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 1.1287 - accuracy: 0.0058 - binary_accuracy: 0.4648 - my_mse: 0.3819 - binary_crossentropy: 1.1287 - hinge: 0.9873 - val_loss: 1.0599 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.4006 - val_binary_crossentropy: 1.0599 - val_hinge: 0.9635\n",
      "Epoch 10/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 1.0578 - accuracy: 0.0032 - binary_accuracy: 0.4648 - my_mse: 0.3682 - binary_crossentropy: 1.0578 - hinge: 0.9865 - val_loss: 1.0156 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3863 - val_binary_crossentropy: 1.0156 - val_hinge: 0.9599\n",
      "Epoch 11/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.9916 - accuracy: 0.0032 - binary_accuracy: 0.4648 - my_mse: 0.3552 - binary_crossentropy: 0.9916 - hinge: 0.9850 - val_loss: 0.9808 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3743 - val_binary_crossentropy: 0.9808 - val_hinge: 0.9568\n",
      "Epoch 12/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.9376 - accuracy: 0.0016 - binary_accuracy: 0.4648 - my_mse: 0.3446 - binary_crossentropy: 0.9376 - hinge: 0.9838 - val_loss: 0.9515 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3637 - val_binary_crossentropy: 0.9515 - val_hinge: 0.9540\n",
      "Epoch 13/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.9134 - accuracy: 0.0011 - binary_accuracy: 0.4648 - my_mse: 0.3365 - binary_crossentropy: 0.9134 - hinge: 0.9829 - val_loss: 0.9276 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3547 - val_binary_crossentropy: 0.9276 - val_hinge: 0.9515\n",
      "Epoch 14/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.8940 - accuracy: 2.6261e-04 - binary_accuracy: 0.4648 - my_mse: 0.3278 - binary_crossentropy: 0.8940 - hinge: 0.9820 - val_loss: 0.9058 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3463 - val_binary_crossentropy: 0.9058 - val_hinge: 0.9491\n",
      "Epoch 15/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.8670 - accuracy: 0.0016 - binary_accuracy: 0.4648 - my_mse: 0.3215 - binary_crossentropy: 0.8670 - hinge: 0.9809 - val_loss: 0.8881 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3392 - val_binary_crossentropy: 0.8881 - val_hinge: 0.9470\n",
      "Epoch 16/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.8458 - accuracy: 7.8782e-04 - binary_accuracy: 0.4648 - my_mse: 0.3150 - binary_crossentropy: 0.8458 - hinge: 0.9796 - val_loss: 0.8723 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3327 - val_binary_crossentropy: 0.8723 - val_hinge: 0.9450\n",
      "Epoch 17/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.8297 - accuracy: 0.0011 - binary_accuracy: 0.4648 - my_mse: 0.3100 - binary_crossentropy: 0.8297 - hinge: 0.9793 - val_loss: 0.8586 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3271 - val_binary_crossentropy: 0.8586 - val_hinge: 0.9432\n",
      "Epoch 18/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.8194 - accuracy: 2.6261e-04 - binary_accuracy: 0.4648 - my_mse: 0.3056 - binary_crossentropy: 0.8194 - hinge: 0.9788 - val_loss: 0.8463 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3218 - val_binary_crossentropy: 0.8463 - val_hinge: 0.9415\n",
      "Epoch 19/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.8091 - accuracy: 5.2521e-04 - binary_accuracy: 0.4648 - my_mse: 0.3014 - binary_crossentropy: 0.8091 - hinge: 0.9781 - val_loss: 0.8353 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3171 - val_binary_crossentropy: 0.8353 - val_hinge: 0.9399\n",
      "Epoch 20/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7992 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2969 - binary_crossentropy: 0.7992 - hinge: 0.9770 - val_loss: 0.8248 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3125 - val_binary_crossentropy: 0.8248 - val_hinge: 0.9383\n",
      "Epoch 21/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7876 - accuracy: 2.6261e-04 - binary_accuracy: 0.4648 - my_mse: 0.2938 - binary_crossentropy: 0.7876 - hinge: 0.9768 - val_loss: 0.8158 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3085 - val_binary_crossentropy: 0.8158 - val_hinge: 0.9369\n",
      "Epoch 22/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7829 - accuracy: 2.6261e-04 - binary_accuracy: 0.4648 - my_mse: 0.2902 - binary_crossentropy: 0.7829 - hinge: 0.9762 - val_loss: 0.8073 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3047 - val_binary_crossentropy: 0.8073 - val_hinge: 0.9354\n",
      "Epoch 23/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7736 - accuracy: 5.2521e-04 - binary_accuracy: 0.4648 - my_mse: 0.2876 - binary_crossentropy: 0.7736 - hinge: 0.9758 - val_loss: 0.7997 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.3012 - val_binary_crossentropy: 0.7997 - val_hinge: 0.9341\n",
      "Epoch 24/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7658 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2844 - binary_crossentropy: 0.7658 - hinge: 0.9749 - val_loss: 0.7928 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2981 - val_binary_crossentropy: 0.7928 - val_hinge: 0.9329\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7619 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2825 - binary_crossentropy: 0.7619 - hinge: 0.9749 - val_loss: 0.7862 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2951 - val_binary_crossentropy: 0.7862 - val_hinge: 0.9317\n",
      "Epoch 26/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7583 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2796 - binary_crossentropy: 0.7583 - hinge: 0.9740 - val_loss: 0.7804 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2924 - val_binary_crossentropy: 0.7804 - val_hinge: 0.9306\n",
      "Epoch 27/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7524 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2781 - binary_crossentropy: 0.7524 - hinge: 0.9739 - val_loss: 0.7749 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2898 - val_binary_crossentropy: 0.7749 - val_hinge: 0.9295\n",
      "Epoch 28/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2767 - binary_crossentropy: 0.7489 - hinge: 0.9742 - val_loss: 0.7698 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2874 - val_binary_crossentropy: 0.7698 - val_hinge: 0.9285\n",
      "Epoch 29/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7433 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2742 - binary_crossentropy: 0.7433 - hinge: 0.9732 - val_loss: 0.7650 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2852 - val_binary_crossentropy: 0.7650 - val_hinge: 0.9275\n",
      "Epoch 30/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7404 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2727 - binary_crossentropy: 0.7404 - hinge: 0.9729 - val_loss: 0.7606 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2831 - val_binary_crossentropy: 0.7606 - val_hinge: 0.9265\n",
      "Epoch 31/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2713 - binary_crossentropy: 0.7371 - hinge: 0.9727 - val_loss: 0.7565 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2811 - val_binary_crossentropy: 0.7565 - val_hinge: 0.9256\n",
      "Epoch 32/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2705 - binary_crossentropy: 0.7355 - hinge: 0.9728 - val_loss: 0.7526 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2792 - val_binary_crossentropy: 0.7526 - val_hinge: 0.9247\n",
      "Epoch 33/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7320 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2683 - binary_crossentropy: 0.7320 - hinge: 0.9718 - val_loss: 0.7481 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2771 - val_binary_crossentropy: 0.7481 - val_hinge: 0.9236\n",
      "Epoch 34/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7275 - accuracy: 2.6261e-04 - binary_accuracy: 0.4648 - my_mse: 0.2667 - binary_crossentropy: 0.7275 - hinge: 0.9711 - val_loss: 0.7447 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2755 - val_binary_crossentropy: 0.7447 - val_hinge: 0.9228\n",
      "Epoch 35/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7257 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2659 - binary_crossentropy: 0.7257 - hinge: 0.9713 - val_loss: 0.7416 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2739 - val_binary_crossentropy: 0.7416 - val_hinge: 0.9220\n",
      "Epoch 36/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7235 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2647 - binary_crossentropy: 0.7235 - hinge: 0.9709 - val_loss: 0.7386 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2725 - val_binary_crossentropy: 0.7386 - val_hinge: 0.9213\n",
      "Epoch 37/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7220 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2640 - binary_crossentropy: 0.7220 - hinge: 0.9709 - val_loss: 0.7359 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2711 - val_binary_crossentropy: 0.7359 - val_hinge: 0.9206\n",
      "Epoch 38/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2629 - binary_crossentropy: 0.7194 - hinge: 0.9703 - val_loss: 0.7332 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2699 - val_binary_crossentropy: 0.7332 - val_hinge: 0.9199\n",
      "Epoch 39/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7198 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2629 - binary_crossentropy: 0.7198 - hinge: 0.9709 - val_loss: 0.7307 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2686 - val_binary_crossentropy: 0.7307 - val_hinge: 0.9192\n",
      "Epoch 40/1000\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.7153 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2609 - binary_crossentropy: 0.7153 - hinge: 0.9694 - val_loss: 0.7284 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2675 - val_binary_crossentropy: 0.7284 - val_hinge: 0.9185\n",
      "Epoch 41/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7177 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2603 - binary_crossentropy: 0.7177 - hinge: 0.9696 - val_loss: 0.7262 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2664 - val_binary_crossentropy: 0.7262 - val_hinge: 0.9179\n",
      "Epoch 42/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2599 - binary_crossentropy: 0.7135 - hinge: 0.9696 - val_loss: 0.7241 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2654 - val_binary_crossentropy: 0.7241 - val_hinge: 0.9173\n",
      "Epoch 43/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7114 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2590 - binary_crossentropy: 0.7114 - hinge: 0.9693 - val_loss: 0.7222 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2645 - val_binary_crossentropy: 0.7222 - val_hinge: 0.9167\n",
      "Epoch 44/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7098 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2582 - binary_crossentropy: 0.7098 - hinge: 0.9686 - val_loss: 0.7203 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2635 - val_binary_crossentropy: 0.7203 - val_hinge: 0.9161\n",
      "Epoch 45/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7091 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2578 - binary_crossentropy: 0.7091 - hinge: 0.9687 - val_loss: 0.7186 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2627 - val_binary_crossentropy: 0.7186 - val_hinge: 0.9156\n",
      "Epoch 46/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2575 - binary_crossentropy: 0.7121 - hinge: 0.9685 - val_loss: 0.7169 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2618 - val_binary_crossentropy: 0.7169 - val_hinge: 0.9150\n",
      "Epoch 47/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7081 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2573 - binary_crossentropy: 0.7081 - hinge: 0.9688 - val_loss: 0.7153 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2610 - val_binary_crossentropy: 0.7153 - val_hinge: 0.9145\n",
      "Epoch 48/1000\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.7067 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2565 - binary_crossentropy: 0.7067 - hinge: 0.9682 - val_loss: 0.7138 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2603 - val_binary_crossentropy: 0.7138 - val_hinge: 0.9140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7046 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2557 - binary_crossentropy: 0.7046 - hinge: 0.9677 - val_loss: 0.7124 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2596 - val_binary_crossentropy: 0.7124 - val_hinge: 0.9135\n",
      "Epoch 50/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7046 - accuracy: 2.6261e-04 - binary_accuracy: 0.4648 - my_mse: 0.2556 - binary_crossentropy: 0.7046 - hinge: 0.9679 - val_loss: 0.7110 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2589 - val_binary_crossentropy: 0.7110 - val_hinge: 0.9130\n",
      "Epoch 51/1000\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.7045 - accuracy: 0.0000e+00 - binary_accuracy: 0.4648 - my_mse: 0.2555 - binary_crossentropy: 0.7045 - hinge: 0.9681 - val_loss: 0.7098 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4057 - val_my_mse: 0.2583 - val_binary_crossentropy: 0.7098 - val_hinge: 0.9126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20ccb978580>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(256,  activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(Dense(128,  activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(Dense(64,  activation = 'relu'))\n",
    "classifier.add(Dense(32,  activation = 'relu'))\n",
    "classifier.add(Dense(16,  activation = 'relu'))\n",
    "classifier.add(Dense(8,  activation = 'relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(1,  activation = 'relu'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = metrics)\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 50, epochs = 1000, validation_split = 0.10, callbacks = [esm],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training and validation loss\n",
    "plt.plot(classifier.history.history[\"loss\"], label='train')\n",
    "plt.plot(classifier.history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "#x1,y1 =plt.axis()\n",
    "#plt.axis([0,0])\n",
    "#plt.ylim([0.5, 0.7])\n",
    "plt.title('Training/Validation Loss');\n",
    "# Evaluate the model >> model.metrics_names\n",
    "#print(f'{model.metrics_names}: {model.evaluate(Bitcoin_train, y_train , verbose=1)}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = classifier.predict(X_test)\n",
    "y_pred = list(map(lambda x: 0 if x<0.5 else 1, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44139886578449905\n"
     ]
    }
   ],
   "source": [
    "# Computing Accuracy, Precision and Recall\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF_pred</th>\n",
       "      <th>RF_accuracy</th>\n",
       "      <th>RF_prob</th>\n",
       "      <th>SVC_pred</th>\n",
       "      <th>SVC_accuracy</th>\n",
       "      <th>SVC_prob</th>\n",
       "      <th>XGB_pred</th>\n",
       "      <th>XGB_accuracy</th>\n",
       "      <th>XGB_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.657543</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.544082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.536098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.324182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.544076</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.390463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.496864</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.545460</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.552227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.574333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.545009</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.596263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.543872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.483318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.679418</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.539406</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.598255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.555801</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.537904</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.567730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.573323</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.540966</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.561254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.719503</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.536726</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.590790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.531916</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.541307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.569102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RF_pred  RF_accuracy   RF_prob  SVC_pred  SVC_accuracy  SVC_prob  \\\n",
       "0           1     0.523629  0.657543         1      0.558601  0.544082   \n",
       "1           0     0.523629  0.324182         1      0.558601  0.544076   \n",
       "2           0     0.523629  0.496864         1      0.558601  0.545460   \n",
       "3           1     0.523629  0.574333         1      0.558601  0.545009   \n",
       "4           0     0.523629  0.421569         1      0.558601  0.543872   \n",
       "...       ...          ...       ...       ...           ...       ...   \n",
       "1053        1     0.523629  0.679418         1      0.558601  0.539406   \n",
       "1054        1     0.523629  0.555801         1      0.558601  0.537904   \n",
       "1055        1     0.523629  0.573323         1      0.558601  0.540966   \n",
       "1056        1     0.523629  0.719503         1      0.558601  0.536726   \n",
       "1057        1     0.523629  0.531916         1      0.558601  0.541307   \n",
       "\n",
       "      XGB_pred  XGB_accuracy  XGB_prob  \n",
       "0            1      0.533081  0.536098  \n",
       "1            0      0.533081  0.390463  \n",
       "2            1      0.533081  0.552227  \n",
       "3            1      0.533081  0.596263  \n",
       "4            0      0.533081  0.483318  \n",
       "...        ...           ...       ...  \n",
       "1053         1      0.533081  0.598255  \n",
       "1054         1      0.533081  0.567730  \n",
       "1055         1      0.533081  0.561254  \n",
       "1056         1      0.533081  0.590790  \n",
       "1057         1      0.533081  0.569102  \n",
       "\n",
       "[1058 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction = pd.read_csv(\"../data/model_accuracy_nsq.csv\", index_col = False)\n",
    "df_prediction =  df_prediction.drop(columns=[\"Unnamed: 0\"])\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction[\"ANN_pred\"] = y_pred\n",
    "df_prediction[\"ANN_accuracy\"] = [accuracy for x in range(len(y_pred))]\n",
    "df_prediction[\"ANN_prob\"] = y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF_pred</th>\n",
       "      <th>RF_accuracy</th>\n",
       "      <th>RF_prob</th>\n",
       "      <th>SVC_pred</th>\n",
       "      <th>SVC_accuracy</th>\n",
       "      <th>SVC_prob</th>\n",
       "      <th>XGB_pred</th>\n",
       "      <th>XGB_accuracy</th>\n",
       "      <th>XGB_prob</th>\n",
       "      <th>ANN_pred</th>\n",
       "      <th>ANN_accuracy</th>\n",
       "      <th>ANN_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.657543</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.544082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.536098</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.324182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.544076</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.390463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.496864</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.545460</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.552227</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.574333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.545009</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.596263</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.543872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.483318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.679418</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.539406</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.598255</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.555801</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.537904</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.567730</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.573323</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.540966</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.561254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.463568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.719503</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.536726</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.590790</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.531916</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.541307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.569102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.462834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RF_pred  RF_accuracy   RF_prob  SVC_pred  SVC_accuracy  SVC_prob  \\\n",
       "0           1     0.523629  0.657543         1      0.558601  0.544082   \n",
       "1           0     0.523629  0.324182         1      0.558601  0.544076   \n",
       "2           0     0.523629  0.496864         1      0.558601  0.545460   \n",
       "3           1     0.523629  0.574333         1      0.558601  0.545009   \n",
       "4           0     0.523629  0.421569         1      0.558601  0.543872   \n",
       "...       ...          ...       ...       ...           ...       ...   \n",
       "1053        1     0.523629  0.679418         1      0.558601  0.539406   \n",
       "1054        1     0.523629  0.555801         1      0.558601  0.537904   \n",
       "1055        1     0.523629  0.573323         1      0.558601  0.540966   \n",
       "1056        1     0.523629  0.719503         1      0.558601  0.536726   \n",
       "1057        1     0.523629  0.531916         1      0.558601  0.541307   \n",
       "\n",
       "      XGB_pred  XGB_accuracy  XGB_prob  ANN_pred  ANN_accuracy  ANN_prob  \n",
       "0            1      0.533081  0.536098         0      0.441399  0.464561  \n",
       "1            0      0.533081  0.390463         0      0.441399  0.464505  \n",
       "2            1      0.533081  0.552227         0      0.441399  0.464505  \n",
       "3            1      0.533081  0.596263         0      0.441399  0.464505  \n",
       "4            0      0.533081  0.483318         0      0.441399  0.464505  \n",
       "...        ...           ...       ...       ...           ...       ...  \n",
       "1053         1      0.533081  0.598255         0      0.441399  0.464011  \n",
       "1054         1      0.533081  0.567730         0      0.441399  0.464421  \n",
       "1055         1      0.533081  0.561254         0      0.441399  0.463568  \n",
       "1056         1      0.533081  0.590790         0      0.441399  0.464013  \n",
       "1057         1      0.533081  0.569102         0      0.441399  0.462834  \n",
       "\n",
       "[1058 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv(\"../data/model_accuracy_nsq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
