{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from package import euklid_regressor as eu\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_df = pd.read_csv('../data/NSQ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>SO</th>\n",
       "      <th>RSI_1</th>\n",
       "      <th>RSI_2</th>\n",
       "      <th>RSI_3</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>1 Day ROI</th>\n",
       "      <th>2 Day ROI</th>\n",
       "      <th>3 Day ROI</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>Previous_differenced</th>\n",
       "      <th>Differenced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1791.00</td>\n",
       "      <td>71.689895</td>\n",
       "      <td>21.862764</td>\n",
       "      <td>39.404226</td>\n",
       "      <td>47.783316</td>\n",
       "      <td>52.064839</td>\n",
       "      <td>-0.015393</td>\n",
       "      <td>-0.083184</td>\n",
       "      <td>-0.083184</td>\n",
       "      <td>14.845864</td>\n",
       "      <td>48.764418</td>\n",
       "      <td>-33.918554</td>\n",
       "      <td>-0.068851</td>\n",
       "      <td>-0.015393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1824.00</td>\n",
       "      <td>77.439024</td>\n",
       "      <td>49.007054</td>\n",
       "      <td>50.908448</td>\n",
       "      <td>54.563943</td>\n",
       "      <td>53.590307</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>-0.066291</td>\n",
       "      <td>19.312162</td>\n",
       "      <td>42.584572</td>\n",
       "      <td>-23.272411</td>\n",
       "      <td>-0.015393</td>\n",
       "      <td>0.018425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1774.00</td>\n",
       "      <td>63.103803</td>\n",
       "      <td>23.874383</td>\n",
       "      <td>35.563467</td>\n",
       "      <td>43.224632</td>\n",
       "      <td>50.957746</td>\n",
       "      <td>-0.027412</td>\n",
       "      <td>-0.009492</td>\n",
       "      <td>-0.024739</td>\n",
       "      <td>18.602712</td>\n",
       "      <td>33.500098</td>\n",
       "      <td>-14.897386</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>-0.027412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1823.00</td>\n",
       "      <td>73.175745</td>\n",
       "      <td>62.035182</td>\n",
       "      <td>55.348283</td>\n",
       "      <td>55.349391</td>\n",
       "      <td>53.363270</td>\n",
       "      <td>0.027621</td>\n",
       "      <td>-0.000548</td>\n",
       "      <td>0.017867</td>\n",
       "      <td>21.743711</td>\n",
       "      <td>29.312877</td>\n",
       "      <td>-7.569167</td>\n",
       "      <td>-0.027412</td>\n",
       "      <td>0.027621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1866.50</td>\n",
       "      <td>80.837004</td>\n",
       "      <td>79.913226</td>\n",
       "      <td>68.306695</td>\n",
       "      <td>64.358818</td>\n",
       "      <td>55.442106</td>\n",
       "      <td>0.023862</td>\n",
       "      <td>0.052142</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>27.426901</td>\n",
       "      <td>27.996854</td>\n",
       "      <td>-0.569953</td>\n",
       "      <td>0.027621</td>\n",
       "      <td>0.023862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>14654.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.741922</td>\n",
       "      <td>91.613859</td>\n",
       "      <td>85.112742</td>\n",
       "      <td>57.846042</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>0.039637</td>\n",
       "      <td>0.038425</td>\n",
       "      <td>-62.553224</td>\n",
       "      <td>155.357918</td>\n",
       "      <td>-217.911141</td>\n",
       "      <td>0.019524</td>\n",
       "      <td>0.019728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>14447.00</td>\n",
       "      <td>87.130867</td>\n",
       "      <td>53.329366</td>\n",
       "      <td>64.595899</td>\n",
       "      <td>66.791862</td>\n",
       "      <td>54.672003</td>\n",
       "      <td>-0.014126</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.024951</td>\n",
       "      <td>-21.673629</td>\n",
       "      <td>156.990010</td>\n",
       "      <td>-178.663639</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>-0.014126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>14763.75</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>80.477412</td>\n",
       "      <td>78.887258</td>\n",
       "      <td>76.925560</td>\n",
       "      <td>58.413145</td>\n",
       "      <td>0.021925</td>\n",
       "      <td>0.007489</td>\n",
       "      <td>0.027365</td>\n",
       "      <td>35.869343</td>\n",
       "      <td>171.626385</td>\n",
       "      <td>-135.757043</td>\n",
       "      <td>-0.014126</td>\n",
       "      <td>0.021925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>14755.75</td>\n",
       "      <td>99.534410</td>\n",
       "      <td>78.180231</td>\n",
       "      <td>77.699029</td>\n",
       "      <td>76.143093</td>\n",
       "      <td>58.282974</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.021371</td>\n",
       "      <td>0.006943</td>\n",
       "      <td>79.905923</td>\n",
       "      <td>172.530373</td>\n",
       "      <td>-92.624449</td>\n",
       "      <td>0.021925</td>\n",
       "      <td>-0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>14985.25</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>91.727842</td>\n",
       "      <td>86.469111</td>\n",
       "      <td>82.825256</td>\n",
       "      <td>60.957224</td>\n",
       "      <td>0.015553</td>\n",
       "      <td>0.015003</td>\n",
       "      <td>0.037257</td>\n",
       "      <td>131.804602</td>\n",
       "      <td>179.543241</td>\n",
       "      <td>-47.738639</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.015553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5290 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Close          SO      RSI_1      RSI_2      RSI_3     RSI_14  \\\n",
       "0      1791.00   71.689895  21.862764  39.404226  47.783316  52.064839   \n",
       "1      1824.00   77.439024  49.007054  50.908448  54.563943  53.590307   \n",
       "2      1774.00   63.103803  23.874383  35.563467  43.224632  50.957746   \n",
       "3      1823.00   73.175745  62.035182  55.348283  55.349391  53.363270   \n",
       "4      1866.50   80.837004  79.913226  68.306695  64.358818  55.442106   \n",
       "...        ...         ...        ...        ...        ...        ...   \n",
       "5285  14654.00  100.000000  97.741922  91.613859  85.112742  57.846042   \n",
       "5286  14447.00   87.130867  53.329366  64.595899  66.791862  54.672003   \n",
       "5287  14763.75  100.000000  80.477412  78.887258  76.925560  58.413145   \n",
       "5288  14755.75   99.534410  78.180231  77.699029  76.143093  58.282974   \n",
       "5289  14985.25  100.000000  91.727842  86.469111  82.825256  60.957224   \n",
       "\n",
       "      1 Day ROI  2 Day ROI  3 Day ROI  MACD_12_26_9  MACDh_12_26_9  \\\n",
       "0     -0.015393  -0.083184  -0.083184     14.845864      48.764418   \n",
       "1      0.018425   0.002749  -0.066291     19.312162      42.584572   \n",
       "2     -0.027412  -0.009492  -0.024739     18.602712      33.500098   \n",
       "3      0.027621  -0.000548   0.017867     21.743711      29.312877   \n",
       "4      0.023862   0.052142   0.023300     27.426901      27.996854   \n",
       "...         ...        ...        ...           ...            ...   \n",
       "5285   0.019728   0.039637   0.038425    -62.553224     155.357918   \n",
       "5286  -0.014126   0.005323   0.024951    -21.673629     156.990010   \n",
       "5287   0.021925   0.007489   0.027365     35.869343     171.626385   \n",
       "5288  -0.000542   0.021371   0.006943     79.905923     172.530373   \n",
       "5289   0.015553   0.015003   0.037257    131.804602     179.543241   \n",
       "\n",
       "      MACDs_12_26_9  Previous_differenced  Differenced  \n",
       "0        -33.918554             -0.068851    -0.015393  \n",
       "1        -23.272411             -0.015393     0.018425  \n",
       "2        -14.897386              0.018425    -0.027412  \n",
       "3         -7.569167             -0.027412     0.027621  \n",
       "4         -0.569953              0.027621     0.023862  \n",
       "...             ...                   ...          ...  \n",
       "5285    -217.911141              0.019524     0.019728  \n",
       "5286    -178.663639              0.019728    -0.014126  \n",
       "5287    -135.757043             -0.014126     0.021925  \n",
       "5288     -92.624449              0.021925    -0.000542  \n",
       "5289     -47.738639             -0.000542     0.015553  \n",
       "\n",
       "[5290 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yahoo_df =yahoo_df[[\"Close\",'SO',\n",
    "                       'RSI_1', 'RSI_2', 'RSI_3', 'RSI_14', '1 Day ROI', '2 Day ROI',\n",
    "                       '3 Day ROI', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9',\n",
    "                     \"Previous_differenced\",\n",
    "                    \"Differenced\"]]\n",
    "price = yahoo_df['Differenced'] \n",
    "close = yahoo_df['Close']\n",
    "yahoo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.7910000e+03,  7.1689896e+01,  2.1862764e+01, ...,\n",
       "        -3.3918552e+01, -6.8850778e-02, -1.5393073e-02],\n",
       "       [ 1.8240000e+03,  7.7439026e+01,  4.9007053e+01, ...,\n",
       "        -2.3272411e+01, -1.5393073e-02,  1.8425461e-02],\n",
       "       [ 1.7740000e+03,  6.3103802e+01,  2.3874382e+01, ...,\n",
       "        -1.4897387e+01,  1.8425461e-02, -2.7412280e-02],\n",
       "       ...,\n",
       "       [ 1.4763750e+04,  1.0000000e+02,  8.0477409e+01, ...,\n",
       "        -1.3575705e+02, -1.4125836e-02,  2.1924967e-02],\n",
       "       [ 1.4755750e+04,  9.9534409e+01,  7.8180229e+01, ...,\n",
       "        -9.2624451e+01,  2.1924967e-02, -5.4186775e-04],\n",
       "       [ 1.4985250e+04,  1.0000000e+02,  9.1727844e+01, ...,\n",
       "        -4.7738640e+01, -5.4186775e-04,  1.5553259e-02]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert series to supervised learning\n",
    "values = yahoo_df.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  yahoo_df[[  'SO',\n",
    "                       'RSI_1', 'RSI_2', 'RSI_3', 'RSI_14', '1 Day ROI', '2 Day ROI',\n",
    "                       '3 Day ROI', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9',\n",
    "                     \"Previous_differenced\",\n",
    "                    ]]\n",
    "\n",
    "y = yahoo_df[\"Differenced\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in 80/20 the dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.20,shuffle=False)\n",
    "close_train, close_test = train_test_split(close,test_size = 0.20, shuffle=False)\n",
    "\n",
    "close_train, close_test = list(close_train), list(close_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4232, 1, 12)\n",
      "(4232,)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(75, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(40))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "10/10 [==============================] - 2s 94ms/step - loss: 0.3104 - val_loss: 0.2592\n",
      "Epoch 2/2000\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.2786 - val_loss: 0.2266\n",
      "Epoch 3/2000\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.2608 - val_loss: 0.1954\n",
      "Epoch 4/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2440 - val_loss: 0.1748\n",
      "Epoch 5/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2344 - val_loss: 0.1600\n",
      "Epoch 6/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2341 - val_loss: 0.1526\n",
      "Epoch 7/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2320 - val_loss: 0.1409\n",
      "Epoch 8/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2169 - val_loss: 0.1383\n",
      "Epoch 9/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2183 - val_loss: 0.1350\n",
      "Epoch 10/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2146 - val_loss: 0.1298\n",
      "Epoch 11/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2088 - val_loss: 0.1209\n",
      "Epoch 12/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2056 - val_loss: 0.1210\n",
      "Epoch 13/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2062 - val_loss: 0.1171\n",
      "Epoch 14/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2057 - val_loss: 0.1145\n",
      "Epoch 15/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1992 - val_loss: 0.1133\n",
      "Epoch 16/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1905 - val_loss: 0.1168\n",
      "Epoch 17/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1952 - val_loss: 0.1154\n",
      "Epoch 18/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1874 - val_loss: 0.1184\n",
      "Epoch 19/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1889 - val_loss: 0.1162\n",
      "Epoch 20/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1846 - val_loss: 0.1184\n",
      "Epoch 21/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1831 - val_loss: 0.1181\n",
      "Epoch 22/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1794 - val_loss: 0.1187\n",
      "Epoch 23/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1812 - val_loss: 0.1153\n",
      "Epoch 24/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1779 - val_loss: 0.1130\n",
      "Epoch 25/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1729 - val_loss: 0.1099\n",
      "Epoch 26/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1725 - val_loss: 0.1089\n",
      "Epoch 27/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1733 - val_loss: 0.1089\n",
      "Epoch 28/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1727 - val_loss: 0.1065\n",
      "Epoch 29/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1718 - val_loss: 0.1072\n",
      "Epoch 30/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1707 - val_loss: 0.1055\n",
      "Epoch 31/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1661 - val_loss: 0.1052\n",
      "Epoch 32/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1689 - val_loss: 0.1060\n",
      "Epoch 33/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1638 - val_loss: 0.1009\n",
      "Epoch 34/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1613 - val_loss: 0.1026\n",
      "Epoch 35/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1624 - val_loss: 0.1017\n",
      "Epoch 36/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1621 - val_loss: 0.0977\n",
      "Epoch 37/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1585 - val_loss: 0.0996\n",
      "Epoch 38/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1550 - val_loss: 0.0993\n",
      "Epoch 39/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1609 - val_loss: 0.0980\n",
      "Epoch 40/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1589 - val_loss: 0.0932\n",
      "Epoch 41/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1518 - val_loss: 0.0907\n",
      "Epoch 42/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1551 - val_loss: 0.0892\n",
      "Epoch 43/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1515 - val_loss: 0.0860\n",
      "Epoch 44/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1516 - val_loss: 0.0849\n",
      "Epoch 45/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1451 - val_loss: 0.0850\n",
      "Epoch 46/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1477 - val_loss: 0.0847\n",
      "Epoch 47/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1510 - val_loss: 0.0829\n",
      "Epoch 48/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1479 - val_loss: 0.0794\n",
      "Epoch 49/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1447 - val_loss: 0.0791\n",
      "Epoch 50/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1437 - val_loss: 0.0785\n",
      "Epoch 51/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1392 - val_loss: 0.0786\n",
      "Epoch 52/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1405 - val_loss: 0.0808\n",
      "Epoch 53/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1407 - val_loss: 0.0763\n",
      "Epoch 54/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1376 - val_loss: 0.0761\n",
      "Epoch 55/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1375 - val_loss: 0.0745\n",
      "Epoch 56/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1351 - val_loss: 0.0744\n",
      "Epoch 57/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1340 - val_loss: 0.0754\n",
      "Epoch 58/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1346 - val_loss: 0.0721\n",
      "Epoch 59/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1351 - val_loss: 0.0715\n",
      "Epoch 60/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1326 - val_loss: 0.0728\n",
      "Epoch 61/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1298 - val_loss: 0.0759\n",
      "Epoch 62/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1286 - val_loss: 0.0750\n",
      "Epoch 63/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1266 - val_loss: 0.0738\n",
      "Epoch 64/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1278 - val_loss: 0.0747\n",
      "Epoch 65/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1235 - val_loss: 0.0697\n",
      "Epoch 66/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1220 - val_loss: 0.0724\n",
      "Epoch 67/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1203 - val_loss: 0.0660\n",
      "Epoch 68/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1182 - val_loss: 0.0679\n",
      "Epoch 69/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1166 - val_loss: 0.0645\n",
      "Epoch 70/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1138 - val_loss: 0.0682\n",
      "Epoch 71/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1178 - val_loss: 0.0636\n",
      "Epoch 72/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1138 - val_loss: 0.0665\n",
      "Epoch 73/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1080 - val_loss: 0.0693\n",
      "Epoch 74/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1069 - val_loss: 0.0643\n",
      "Epoch 75/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1069 - val_loss: 0.0630\n",
      "Epoch 76/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1082 - val_loss: 0.0627\n",
      "Epoch 77/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1090 - val_loss: 0.0646\n",
      "Epoch 78/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1055 - val_loss: 0.0617\n",
      "Epoch 79/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1052 - val_loss: 0.0622\n",
      "Epoch 80/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1055 - val_loss: 0.0626\n",
      "Epoch 81/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1012 - val_loss: 0.0652\n",
      "Epoch 82/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1018 - val_loss: 0.0664\n",
      "Epoch 83/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1025 - val_loss: 0.0630\n",
      "Epoch 84/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1005 - val_loss: 0.0616\n",
      "Epoch 85/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0997 - val_loss: 0.0632\n",
      "Epoch 86/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0966 - val_loss: 0.0609\n",
      "Epoch 87/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0964 - val_loss: 0.0613\n",
      "Epoch 88/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0986 - val_loss: 0.0628\n",
      "Epoch 89/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0960 - val_loss: 0.0630\n",
      "Epoch 90/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0951 - val_loss: 0.0632\n",
      "Epoch 91/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0947 - val_loss: 0.0598\n",
      "Epoch 92/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0930 - val_loss: 0.0588\n",
      "Epoch 93/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0949 - val_loss: 0.0585\n",
      "Epoch 94/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0953 - val_loss: 0.0586\n",
      "Epoch 95/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0915 - val_loss: 0.0599\n",
      "Epoch 96/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0891 - val_loss: 0.0597\n",
      "Epoch 97/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0898 - val_loss: 0.0577\n",
      "Epoch 98/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0894 - val_loss: 0.0584\n",
      "Epoch 99/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0902 - val_loss: 0.0575\n",
      "Epoch 100/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0872 - val_loss: 0.0569\n",
      "Epoch 101/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0850 - val_loss: 0.0568\n",
      "Epoch 102/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0851 - val_loss: 0.0562\n",
      "Epoch 103/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0845 - val_loss: 0.0539\n",
      "Epoch 104/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0839 - val_loss: 0.0542\n",
      "Epoch 105/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0828 - val_loss: 0.0541\n",
      "Epoch 106/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0825 - val_loss: 0.0523\n",
      "Epoch 107/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0809 - val_loss: 0.0506\n",
      "Epoch 108/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0798 - val_loss: 0.0500\n",
      "Epoch 109/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0814 - val_loss: 0.0515\n",
      "Epoch 110/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0800 - val_loss: 0.0486\n",
      "Epoch 111/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0766 - val_loss: 0.0476\n",
      "Epoch 112/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0774 - val_loss: 0.0492\n",
      "Epoch 113/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0773 - val_loss: 0.0495\n",
      "Epoch 114/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0779 - val_loss: 0.0458\n",
      "Epoch 115/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0739 - val_loss: 0.0460\n",
      "Epoch 116/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0724 - val_loss: 0.0456\n",
      "Epoch 117/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0732 - val_loss: 0.0443\n",
      "Epoch 118/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0730 - val_loss: 0.0443\n",
      "Epoch 119/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0714 - val_loss: 0.0428\n",
      "Epoch 120/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0703 - val_loss: 0.0427\n",
      "Epoch 121/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0717 - val_loss: 0.0417\n",
      "Epoch 122/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0688 - val_loss: 0.0413\n",
      "Epoch 123/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0659 - val_loss: 0.0406\n",
      "Epoch 124/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0659 - val_loss: 0.0401\n",
      "Epoch 125/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0666 - val_loss: 0.0394\n",
      "Epoch 126/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0659 - val_loss: 0.0390\n",
      "Epoch 127/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0654 - val_loss: 0.0380\n",
      "Epoch 128/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0645 - val_loss: 0.0374\n",
      "Epoch 129/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0627 - val_loss: 0.0368\n",
      "Epoch 130/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0615 - val_loss: 0.0367\n",
      "Epoch 131/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0618 - val_loss: 0.0363\n",
      "Epoch 132/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0614 - val_loss: 0.0347\n",
      "Epoch 133/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0595 - val_loss: 0.0343\n",
      "Epoch 134/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0588 - val_loss: 0.0338\n",
      "Epoch 135/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0576 - val_loss: 0.0336\n",
      "Epoch 136/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0578 - val_loss: 0.0327\n",
      "Epoch 137/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0578 - val_loss: 0.0322\n",
      "Epoch 138/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0564 - val_loss: 0.0322\n",
      "Epoch 139/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0552 - val_loss: 0.0328\n",
      "Epoch 140/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0555 - val_loss: 0.0325\n",
      "Epoch 141/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0554 - val_loss: 0.0309\n",
      "Epoch 142/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0552 - val_loss: 0.0314\n",
      "Epoch 143/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0537 - val_loss: 0.0300\n",
      "Epoch 144/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0532 - val_loss: 0.0302\n",
      "Epoch 145/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0526 - val_loss: 0.0293\n",
      "Epoch 146/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0510 - val_loss: 0.0294\n",
      "Epoch 147/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0524 - val_loss: 0.0292\n",
      "Epoch 148/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0509 - val_loss: 0.0288\n",
      "Epoch 149/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0510 - val_loss: 0.0281\n",
      "Epoch 150/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0484 - val_loss: 0.0281\n",
      "Epoch 151/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0510 - val_loss: 0.0288\n",
      "Epoch 152/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0497 - val_loss: 0.0271\n",
      "Epoch 153/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0493 - val_loss: 0.0271\n",
      "Epoch 154/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0472 - val_loss: 0.0266\n",
      "Epoch 155/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0473 - val_loss: 0.0265\n",
      "Epoch 156/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0469 - val_loss: 0.0265\n",
      "Epoch 157/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0447 - val_loss: 0.0258\n",
      "Epoch 158/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0452 - val_loss: 0.0263\n",
      "Epoch 159/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0449 - val_loss: 0.0267\n",
      "Epoch 160/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0449 - val_loss: 0.0259\n",
      "Epoch 161/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0443 - val_loss: 0.0256\n",
      "Epoch 162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0437 - val_loss: 0.0258\n",
      "Epoch 163/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0435 - val_loss: 0.0252\n",
      "Epoch 164/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0429 - val_loss: 0.0251\n",
      "Epoch 165/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.0247\n",
      "Epoch 166/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0422 - val_loss: 0.0248\n",
      "Epoch 167/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0413 - val_loss: 0.0248\n",
      "Epoch 168/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.0243\n",
      "Epoch 169/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0413 - val_loss: 0.0243\n",
      "Epoch 170/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0393 - val_loss: 0.0240\n",
      "Epoch 171/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0400 - val_loss: 0.0241\n",
      "Epoch 172/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0386 - val_loss: 0.0238\n",
      "Epoch 173/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0389 - val_loss: 0.0237\n",
      "Epoch 174/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.0236\n",
      "Epoch 175/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0386 - val_loss: 0.0232\n",
      "Epoch 176/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0381 - val_loss: 0.0237\n",
      "Epoch 177/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0234\n",
      "Epoch 178/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0372 - val_loss: 0.0233\n",
      "Epoch 179/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0361 - val_loss: 0.0223\n",
      "Epoch 180/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0353 - val_loss: 0.0225\n",
      "Epoch 181/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0351 - val_loss: 0.0222\n",
      "Epoch 182/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0361 - val_loss: 0.0218\n",
      "Epoch 183/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0345 - val_loss: 0.0221\n",
      "Epoch 184/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0345 - val_loss: 0.0223\n",
      "Epoch 185/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0337 - val_loss: 0.0224\n",
      "Epoch 186/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0341 - val_loss: 0.0220\n",
      "Epoch 187/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0337 - val_loss: 0.0225\n",
      "Epoch 188/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0326 - val_loss: 0.0216\n",
      "Epoch 189/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0329 - val_loss: 0.0218\n",
      "Epoch 190/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0328 - val_loss: 0.0221\n",
      "Epoch 191/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0321 - val_loss: 0.0221\n",
      "Epoch 192/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0317 - val_loss: 0.0212\n",
      "Epoch 193/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0316 - val_loss: 0.0213\n",
      "Epoch 194/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0312 - val_loss: 0.0208\n",
      "Epoch 195/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0319 - val_loss: 0.0211\n",
      "Epoch 196/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0309 - val_loss: 0.0212\n",
      "Epoch 197/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0309 - val_loss: 0.0209\n",
      "Epoch 198/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0308 - val_loss: 0.0214\n",
      "Epoch 199/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0302 - val_loss: 0.0206\n",
      "Epoch 200/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0300 - val_loss: 0.0208\n",
      "Epoch 201/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0291 - val_loss: 0.0205\n",
      "Epoch 202/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0294 - val_loss: 0.0205\n",
      "Epoch 203/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0301 - val_loss: 0.0204\n",
      "Epoch 204/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0290 - val_loss: 0.0205\n",
      "Epoch 205/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0287 - val_loss: 0.0197\n",
      "Epoch 206/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0293 - val_loss: 0.0199\n",
      "Epoch 207/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0290 - val_loss: 0.0197\n",
      "Epoch 208/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0281 - val_loss: 0.0202\n",
      "Epoch 209/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0280 - val_loss: 0.0203\n",
      "Epoch 210/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0281 - val_loss: 0.0190\n",
      "Epoch 211/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0283 - val_loss: 0.0192\n",
      "Epoch 212/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0285 - val_loss: 0.0194\n",
      "Epoch 213/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0189\n",
      "Epoch 214/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0274 - val_loss: 0.0192\n",
      "Epoch 215/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0276 - val_loss: 0.0192\n",
      "Epoch 216/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0280 - val_loss: 0.0185\n",
      "Epoch 217/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0275 - val_loss: 0.0189\n",
      "Epoch 218/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0267 - val_loss: 0.0185\n",
      "Epoch 219/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.0187\n",
      "Epoch 220/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0275 - val_loss: 0.0186\n",
      "Epoch 221/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0186\n",
      "Epoch 222/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0182\n",
      "Epoch 223/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0184\n",
      "Epoch 224/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0178\n",
      "Epoch 225/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0181\n",
      "Epoch 226/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0264 - val_loss: 0.0179\n",
      "Epoch 227/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0260 - val_loss: 0.0180\n",
      "Epoch 228/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0178\n",
      "Epoch 229/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0183\n",
      "Epoch 230/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0263 - val_loss: 0.0179\n",
      "Epoch 231/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0249 - val_loss: 0.0173\n",
      "Epoch 232/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0258 - val_loss: 0.0177\n",
      "Epoch 233/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0258 - val_loss: 0.0172\n",
      "Epoch 234/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0258 - val_loss: 0.0176\n",
      "Epoch 235/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0250 - val_loss: 0.0169\n",
      "Epoch 236/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0261 - val_loss: 0.0168\n",
      "Epoch 237/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0255 - val_loss: 0.0170\n",
      "Epoch 238/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.0170\n",
      "Epoch 239/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0253 - val_loss: 0.0167\n",
      "Epoch 240/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0244 - val_loss: 0.0167\n",
      "Epoch 241/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0241 - val_loss: 0.0164\n",
      "Epoch 242/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0166\n",
      "Epoch 243/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0247 - val_loss: 0.0167\n",
      "Epoch 244/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0246 - val_loss: 0.0165\n",
      "Epoch 245/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0248 - val_loss: 0.0168\n",
      "Epoch 246/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0241 - val_loss: 0.0167\n",
      "Epoch 247/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0245 - val_loss: 0.0162\n",
      "Epoch 248/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0243 - val_loss: 0.0163\n",
      "Epoch 249/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0243 - val_loss: 0.0161\n",
      "Epoch 250/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0248 - val_loss: 0.0165\n",
      "Epoch 251/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0240 - val_loss: 0.0159\n",
      "Epoch 252/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0231 - val_loss: 0.0160\n",
      "Epoch 253/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0245 - val_loss: 0.0161\n",
      "Epoch 254/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0239 - val_loss: 0.0157\n",
      "Epoch 255/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.0160\n",
      "Epoch 256/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0160\n",
      "Epoch 257/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0239 - val_loss: 0.0159\n",
      "Epoch 258/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0234 - val_loss: 0.0159\n",
      "Epoch 259/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0242 - val_loss: 0.0152\n",
      "Epoch 260/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0238 - val_loss: 0.0155\n",
      "Epoch 261/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0239 - val_loss: 0.0154\n",
      "Epoch 262/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0222 - val_loss: 0.0152\n",
      "Epoch 263/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0228 - val_loss: 0.0155\n",
      "Epoch 264/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0157\n",
      "Epoch 265/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.0152\n",
      "Epoch 266/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.0153\n",
      "Epoch 267/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0226 - val_loss: 0.0154\n",
      "Epoch 268/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.0153\n",
      "Epoch 269/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0230 - val_loss: 0.0151\n",
      "Epoch 270/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0150\n",
      "Epoch 271/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0225 - val_loss: 0.0153\n",
      "Epoch 272/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0147\n",
      "Epoch 273/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0151\n",
      "Epoch 274/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0150\n",
      "Epoch 275/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0222 - val_loss: 0.0147\n",
      "Epoch 276/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0220 - val_loss: 0.0148\n",
      "Epoch 277/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0222 - val_loss: 0.0148\n",
      "Epoch 278/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0152\n",
      "Epoch 279/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0145\n",
      "Epoch 280/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0223 - val_loss: 0.0143\n",
      "Epoch 281/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0222 - val_loss: 0.0143\n",
      "Epoch 282/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0146\n",
      "Epoch 283/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0213 - val_loss: 0.0141\n",
      "Epoch 284/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0142\n",
      "Epoch 285/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0216 - val_loss: 0.0141\n",
      "Epoch 286/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0142\n",
      "Epoch 287/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0140\n",
      "Epoch 288/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0142\n",
      "Epoch 289/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.0136\n",
      "Epoch 290/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0144\n",
      "Epoch 291/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0211 - val_loss: 0.0138\n",
      "Epoch 292/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0138\n",
      "Epoch 293/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0221 - val_loss: 0.0134\n",
      "Epoch 294/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0213 - val_loss: 0.0134\n",
      "Epoch 295/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0204 - val_loss: 0.0135\n",
      "Epoch 296/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.0135\n",
      "Epoch 297/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0135\n",
      "Epoch 298/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0136\n",
      "Epoch 299/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0139\n",
      "Epoch 300/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0212 - val_loss: 0.0136\n",
      "Epoch 301/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0137\n",
      "Epoch 302/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0135\n",
      "Epoch 303/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0134\n",
      "Epoch 304/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0134\n",
      "Epoch 305/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0204 - val_loss: 0.0134\n",
      "Epoch 306/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0134\n",
      "Epoch 307/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.0134\n",
      "Epoch 308/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0132\n",
      "Epoch 309/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.0133\n",
      "Epoch 310/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0204 - val_loss: 0.0128\n",
      "Epoch 311/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0133\n",
      "Epoch 312/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.0129\n",
      "Epoch 313/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0201 - val_loss: 0.0130\n",
      "Epoch 314/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.0128\n",
      "Epoch 315/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0128\n",
      "Epoch 316/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0123\n",
      "Epoch 317/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.0125\n",
      "Epoch 318/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0127\n",
      "Epoch 319/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0124\n",
      "Epoch 320/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0198 - val_loss: 0.0126\n",
      "Epoch 321/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.0126\n",
      "Epoch 322/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0125\n",
      "Epoch 323/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0122\n",
      "Epoch 324/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0125\n",
      "Epoch 325/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0125\n",
      "Epoch 326/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0120\n",
      "Epoch 327/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0124\n",
      "Epoch 328/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0120\n",
      "Epoch 329/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0124\n",
      "Epoch 330/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0125\n",
      "Epoch 331/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0124\n",
      "Epoch 332/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0122\n",
      "Epoch 333/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0120\n",
      "Epoch 334/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0118\n",
      "Epoch 335/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0118\n",
      "Epoch 336/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0120\n",
      "Epoch 337/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0114\n",
      "Epoch 338/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0119\n",
      "Epoch 339/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0120\n",
      "Epoch 340/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0122\n",
      "Epoch 341/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0120\n",
      "Epoch 342/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0118\n",
      "Epoch 343/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0116\n",
      "Epoch 344/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0117\n",
      "Epoch 345/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.0112\n",
      "Epoch 346/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0114\n",
      "Epoch 347/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0111\n",
      "Epoch 348/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0110\n",
      "Epoch 349/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0117\n",
      "Epoch 350/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0114\n",
      "Epoch 351/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0111\n",
      "Epoch 352/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0111\n",
      "Epoch 353/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0112\n",
      "Epoch 354/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0117\n",
      "Epoch 355/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0112\n",
      "Epoch 356/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0112\n",
      "Epoch 357/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0108\n",
      "Epoch 358/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0109\n",
      "Epoch 359/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0111\n",
      "Epoch 360/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0112\n",
      "Epoch 361/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0112\n",
      "Epoch 362/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0184 - val_loss: 0.0110\n",
      "Epoch 363/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0110\n",
      "Epoch 364/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0112\n",
      "Epoch 365/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.0108\n",
      "Epoch 366/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0181 - val_loss: 0.0108\n",
      "Epoch 367/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0109\n",
      "Epoch 368/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0105\n",
      "Epoch 369/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0111\n",
      "Epoch 370/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0107\n",
      "Epoch 371/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0106\n",
      "Epoch 372/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0106\n",
      "Epoch 373/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0108\n",
      "Epoch 374/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0112\n",
      "Epoch 375/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0110\n",
      "Epoch 376/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0105\n",
      "Epoch 377/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0106\n",
      "Epoch 378/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0106\n",
      "Epoch 379/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0103\n",
      "Epoch 380/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0174 - val_loss: 0.0103\n",
      "Epoch 381/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0100\n",
      "Epoch 382/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0104\n",
      "Epoch 383/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0101\n",
      "Epoch 384/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0101\n",
      "Epoch 385/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.0104\n",
      "Epoch 386/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0105\n",
      "Epoch 387/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0107\n",
      "Epoch 388/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0101\n",
      "Epoch 389/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0104\n",
      "Epoch 390/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.0101\n",
      "Epoch 391/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0102\n",
      "Epoch 392/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0103\n",
      "Epoch 393/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0099\n",
      "Epoch 394/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0171 - val_loss: 0.0101\n",
      "Epoch 395/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0098\n",
      "Epoch 396/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0096\n",
      "Epoch 397/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0101\n",
      "Epoch 398/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0099\n",
      "Epoch 399/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.0099\n",
      "Epoch 400/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0101\n",
      "Epoch 401/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0099\n",
      "Epoch 402/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0100\n",
      "Epoch 403/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0096\n",
      "Epoch 404/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0103\n",
      "Epoch 405/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.0101\n",
      "Epoch 406/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0096\n",
      "Epoch 407/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0094\n",
      "Epoch 408/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0102\n",
      "Epoch 409/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0168 - val_loss: 0.0097\n",
      "Epoch 410/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0097\n",
      "Epoch 411/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0095\n",
      "Epoch 412/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0095\n",
      "Epoch 413/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0092\n",
      "Epoch 414/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0095\n",
      "Epoch 415/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0094\n",
      "Epoch 416/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0095\n",
      "Epoch 417/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0093\n",
      "Epoch 418/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0095\n",
      "Epoch 419/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.0091\n",
      "Epoch 420/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0094\n",
      "Epoch 421/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0092\n",
      "Epoch 422/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0163 - val_loss: 0.0093\n",
      "Epoch 423/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0088\n",
      "Epoch 424/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0091\n",
      "Epoch 425/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0162 - val_loss: 0.0094\n",
      "Epoch 426/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.0092\n",
      "Epoch 427/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.0089\n",
      "Epoch 428/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0093\n",
      "Epoch 429/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0159 - val_loss: 0.0090\n",
      "Epoch 430/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0158 - val_loss: 0.0095\n",
      "Epoch 431/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0090\n",
      "Epoch 432/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0094\n",
      "Epoch 433/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0089\n",
      "Epoch 434/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0093\n",
      "Epoch 435/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0089\n",
      "Epoch 436/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.0091\n",
      "Epoch 437/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0157 - val_loss: 0.0089\n",
      "Epoch 438/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0091\n",
      "Epoch 439/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.0088\n",
      "Epoch 440/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0089\n",
      "Epoch 441/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0093\n",
      "Epoch 442/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0090\n",
      "Epoch 443/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0158 - val_loss: 0.0087\n",
      "Epoch 444/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0086\n",
      "Epoch 445/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0093\n",
      "Epoch 446/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0087\n",
      "Epoch 447/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0088\n",
      "Epoch 448/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0088\n",
      "Epoch 449/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0089\n",
      "Epoch 450/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0087\n",
      "Epoch 451/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0087\n",
      "Epoch 452/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0089\n",
      "Epoch 453/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0154 - val_loss: 0.0088\n",
      "Epoch 454/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0087\n",
      "Epoch 455/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0090\n",
      "Epoch 456/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0088\n",
      "Epoch 457/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0087\n",
      "Epoch 458/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0086\n",
      "Epoch 459/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.0085\n",
      "Epoch 460/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0082\n",
      "Epoch 461/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0087\n",
      "Epoch 462/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0084\n",
      "Epoch 463/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0086\n",
      "Epoch 464/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0084\n",
      "Epoch 465/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0084\n",
      "Epoch 466/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0084\n",
      "Epoch 467/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0088\n",
      "Epoch 468/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0082\n",
      "Epoch 469/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0086\n",
      "Epoch 470/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0085\n",
      "Epoch 471/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0082\n",
      "Epoch 472/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0082\n",
      "Epoch 473/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0086\n",
      "Epoch 474/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0152 - val_loss: 0.0084\n",
      "Epoch 475/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0081\n",
      "Epoch 476/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0082\n",
      "Epoch 477/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0080\n",
      "Epoch 478/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0081\n",
      "Epoch 479/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0083\n",
      "Epoch 480/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0082\n",
      "Epoch 481/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0083\n",
      "Epoch 482/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0080\n",
      "Epoch 483/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0083\n",
      "Epoch 484/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0084\n",
      "Epoch 485/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0079\n",
      "Epoch 486/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0082\n",
      "Epoch 487/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0081\n",
      "Epoch 488/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0078\n",
      "Epoch 489/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0083\n",
      "Epoch 490/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0081\n",
      "Epoch 491/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0147 - val_loss: 0.0079\n",
      "Epoch 492/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0150 - val_loss: 0.0079\n",
      "Epoch 493/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0084\n",
      "Epoch 494/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0077\n",
      "Epoch 495/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0082\n",
      "Epoch 496/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0079\n",
      "Epoch 497/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0078\n",
      "Epoch 498/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0149 - val_loss: 0.0084\n",
      "Epoch 499/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0082\n",
      "Epoch 500/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0076\n",
      "Epoch 501/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0146 - val_loss: 0.0082\n",
      "Epoch 502/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0084\n",
      "Epoch 503/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0077\n",
      "Epoch 504/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0078\n",
      "Epoch 505/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0145 - val_loss: 0.0079\n",
      "Epoch 506/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0082\n",
      "Epoch 507/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0077\n",
      "Epoch 508/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0076\n",
      "Epoch 509/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0079\n",
      "Epoch 510/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0079\n",
      "Epoch 511/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0074\n",
      "Epoch 512/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0075\n",
      "Epoch 513/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0082\n",
      "Epoch 514/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0074\n",
      "Epoch 515/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0077\n",
      "Epoch 516/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0078\n",
      "Epoch 517/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0080\n",
      "Epoch 518/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0075\n",
      "Epoch 519/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0076\n",
      "Epoch 520/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0075\n",
      "Epoch 521/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0077\n",
      "Epoch 522/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0077\n",
      "Epoch 523/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0140 - val_loss: 0.0077\n",
      "Epoch 524/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0075\n",
      "Epoch 525/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0074\n",
      "Epoch 526/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0074\n",
      "Epoch 527/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0075\n",
      "Epoch 528/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0074\n",
      "Epoch 529/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0078\n",
      "Epoch 530/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0079\n",
      "Epoch 531/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0074\n",
      "Epoch 532/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0138 - val_loss: 0.0072\n",
      "Epoch 533/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0073\n",
      "Epoch 534/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0076\n",
      "Epoch 535/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0072\n",
      "Epoch 536/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0074\n",
      "Epoch 537/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0076\n",
      "Epoch 538/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0078\n",
      "Epoch 539/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0141 - val_loss: 0.0075\n",
      "Epoch 540/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0070\n",
      "Epoch 541/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0071\n",
      "Epoch 542/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0071\n",
      "Epoch 543/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 544/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0075\n",
      "Epoch 545/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0139 - val_loss: 0.0071\n",
      "Epoch 546/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0070\n",
      "Epoch 547/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0074\n",
      "Epoch 548/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0074\n",
      "Epoch 549/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0076\n",
      "Epoch 550/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0072\n",
      "Epoch 551/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - val_loss: 0.0072\n",
      "Epoch 552/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0072\n",
      "Epoch 553/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - val_loss: 0.0073\n",
      "Epoch 554/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0071\n",
      "Epoch 555/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0074\n",
      "Epoch 556/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0074\n",
      "Epoch 557/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0071\n",
      "Epoch 558/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0071\n",
      "Epoch 559/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0073\n",
      "Epoch 560/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0074\n",
      "Epoch 561/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0070\n",
      "Epoch 562/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0075\n",
      "Epoch 563/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0070\n",
      "Epoch 564/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0072\n",
      "Epoch 565/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0071\n",
      "Epoch 566/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0073\n",
      "Epoch 567/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0067\n",
      "Epoch 568/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0071\n",
      "Epoch 569/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0136 - val_loss: 0.0074\n",
      "Epoch 570/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0133 - val_loss: 0.0073\n",
      "Epoch 571/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0068\n",
      "Epoch 572/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0069\n",
      "Epoch 573/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0068\n",
      "Epoch 574/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0073\n",
      "Epoch 575/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0068\n",
      "Epoch 576/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0071\n",
      "Epoch 577/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0074\n",
      "Epoch 578/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0071\n",
      "Epoch 579/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0068\n",
      "Epoch 580/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0067\n",
      "Epoch 581/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0069\n",
      "Epoch 582/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0069\n",
      "Epoch 583/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0070\n",
      "Epoch 584/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0069\n",
      "Epoch 585/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0070\n",
      "Epoch 586/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0067\n",
      "Epoch 587/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0070\n",
      "Epoch 588/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0072\n",
      "Epoch 589/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0069\n",
      "Epoch 590/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0067\n",
      "Epoch 591/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0129 - val_loss: 0.0070\n",
      "Epoch 592/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0068\n",
      "Epoch 593/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0072\n",
      "Epoch 594/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0068\n",
      "Epoch 595/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0069\n",
      "Epoch 596/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0071\n",
      "Epoch 597/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0068\n",
      "Epoch 598/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0065\n",
      "Epoch 599/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0067\n",
      "Epoch 600/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0070\n",
      "Epoch 601/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0068\n",
      "Epoch 602/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0069\n",
      "Epoch 603/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0069\n",
      "Epoch 604/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0067\n",
      "Epoch 605/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0067\n",
      "Epoch 606/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0064\n",
      "Epoch 607/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0067\n",
      "Epoch 608/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0069\n",
      "Epoch 609/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0068\n",
      "Epoch 610/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0075\n",
      "Epoch 611/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0072\n",
      "Epoch 612/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0068\n",
      "Epoch 613/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0069\n",
      "Epoch 614/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0073\n",
      "Epoch 615/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0068\n",
      "Epoch 616/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0067\n",
      "Epoch 617/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0067\n",
      "Epoch 618/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0066\n",
      "Epoch 619/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0068\n",
      "Epoch 620/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0069\n",
      "Epoch 621/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0071\n",
      "Epoch 622/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0064\n",
      "Epoch 623/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0067\n",
      "Epoch 624/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0073\n",
      "Epoch 625/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0068\n",
      "Epoch 626/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0065\n",
      "Epoch 627/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0067\n",
      "Epoch 628/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0123 - val_loss: 0.0071\n",
      "Epoch 629/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0063\n",
      "Epoch 630/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0066\n",
      "Epoch 631/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0073\n",
      "Epoch 632/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0068\n",
      "Epoch 633/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0067\n",
      "Epoch 634/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0069\n",
      "Epoch 635/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0072\n",
      "Epoch 636/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0063\n",
      "Epoch 637/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0064\n",
      "Epoch 638/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0064\n",
      "Epoch 639/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0066\n",
      "Epoch 640/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0064\n",
      "Epoch 641/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0064\n",
      "Epoch 642/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0065\n",
      "Epoch 643/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0062\n",
      "Epoch 644/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0064\n",
      "Epoch 645/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0127 - val_loss: 0.0064\n",
      "Epoch 646/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0068\n",
      "Epoch 647/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0066\n",
      "Epoch 648/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0063\n",
      "Epoch 649/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0069\n",
      "Epoch 650/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0064\n",
      "Epoch 651/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0065\n",
      "Epoch 652/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0062\n",
      "Epoch 653/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.0063\n",
      "Epoch 654/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0066\n",
      "Epoch 655/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0071\n",
      "Epoch 656/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0069\n",
      "Epoch 657/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0062\n",
      "Epoch 658/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0065\n",
      "Epoch 659/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0070\n",
      "Epoch 660/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0065\n",
      "Epoch 661/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0064\n",
      "Epoch 662/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0064\n",
      "Epoch 663/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0063\n",
      "Epoch 664/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0068\n",
      "Epoch 665/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0065\n",
      "Epoch 666/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0063\n",
      "Epoch 667/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0061\n",
      "Epoch 668/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0070\n",
      "Epoch 669/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0063\n",
      "Epoch 670/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.0068\n",
      "Epoch 671/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0064\n",
      "Epoch 672/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0122 - val_loss: 0.0065\n",
      "Epoch 673/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0065\n",
      "Epoch 674/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0062\n",
      "Epoch 675/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0065\n",
      "Epoch 676/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0063\n",
      "Epoch 677/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.0064\n",
      "Epoch 678/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0121 - val_loss: 0.0062\n",
      "Epoch 679/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0062\n",
      "Epoch 680/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0062\n",
      "Epoch 681/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0063\n",
      "Epoch 682/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0063\n",
      "Epoch 683/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 684/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 685/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0062\n",
      "Epoch 686/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0066\n",
      "Epoch 687/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0062\n",
      "Epoch 688/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0063\n",
      "Epoch 689/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0062\n",
      "Epoch 690/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0064\n",
      "Epoch 691/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0062\n",
      "Epoch 692/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0063\n",
      "Epoch 693/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0063\n",
      "Epoch 694/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0059\n",
      "Epoch 695/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0062\n",
      "Epoch 696/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0065\n",
      "Epoch 697/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 698/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0064\n",
      "Epoch 699/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 700/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0058\n",
      "Epoch 701/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0068\n",
      "Epoch 702/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0120 - val_loss: 0.0066\n",
      "Epoch 703/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0060\n",
      "Epoch 704/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0060\n",
      "Epoch 705/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0070\n",
      "Epoch 706/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0067\n",
      "Epoch 707/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0060\n",
      "Epoch 708/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0064\n",
      "Epoch 709/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0061\n",
      "Epoch 710/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0059\n",
      "Epoch 711/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0066\n",
      "Epoch 712/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0066\n",
      "Epoch 713/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0059\n",
      "Epoch 714/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0063\n",
      "Epoch 715/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0065\n",
      "Epoch 716/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0061\n",
      "Epoch 717/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0068\n",
      "Epoch 718/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0059\n",
      "Epoch 719/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0119 - val_loss: 0.0063\n",
      "Epoch 720/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0061\n",
      "Epoch 721/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0064\n",
      "Epoch 722/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0061\n",
      "Epoch 723/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0060\n",
      "Epoch 724/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0062\n",
      "Epoch 725/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0062\n",
      "Epoch 726/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0059\n",
      "Epoch 727/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0119 - val_loss: 0.0061\n",
      "Epoch 728/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0063\n",
      "Epoch 729/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0066\n",
      "Epoch 730/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 731/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0059\n",
      "Epoch 732/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0064\n",
      "Epoch 733/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0058\n",
      "Epoch 734/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0065\n",
      "Epoch 735/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0058\n",
      "Epoch 736/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0058\n",
      "Epoch 737/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0059\n",
      "Epoch 738/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0062\n",
      "Epoch 739/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 740/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0058\n",
      "Epoch 741/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0062\n",
      "Epoch 742/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0061\n",
      "Epoch 743/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0119 - val_loss: 0.0060\n",
      "Epoch 744/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0062\n",
      "Epoch 745/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0064\n",
      "Epoch 746/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 747/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0056\n",
      "Epoch 748/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0060\n",
      "Epoch 749/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0063\n",
      "Epoch 750/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0064\n",
      "Epoch 751/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0058\n",
      "Epoch 752/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0059\n",
      "Epoch 753/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0060\n",
      "Epoch 754/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0061\n",
      "Epoch 755/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0060\n",
      "Epoch 756/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0057\n",
      "Epoch 757/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0064\n",
      "Epoch 758/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0060\n",
      "Epoch 759/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0058\n",
      "Epoch 760/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0061\n",
      "Epoch 761/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0056\n",
      "Epoch 762/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0059\n",
      "Epoch 763/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0065\n",
      "Epoch 764/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0118 - val_loss: 0.0057\n",
      "Epoch 765/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0061\n",
      "Epoch 766/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0060\n",
      "Epoch 767/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0057\n",
      "Epoch 768/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0059\n",
      "Epoch 769/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0060\n",
      "Epoch 770/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0059\n",
      "Epoch 771/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0063\n",
      "Epoch 772/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0057\n",
      "Epoch 773/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0061\n",
      "Epoch 774/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0058\n",
      "Epoch 775/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0058\n",
      "Epoch 776/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0067\n",
      "Epoch 777/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0059\n",
      "Epoch 778/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0058\n",
      "Epoch 779/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0061\n",
      "Epoch 780/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0061\n",
      "Epoch 781/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0060\n",
      "Epoch 782/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0066\n",
      "Epoch 783/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0059\n",
      "Epoch 784/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 785/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0061\n",
      "Epoch 786/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0063\n",
      "Epoch 787/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0064\n",
      "Epoch 788/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0058\n",
      "Epoch 789/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0057\n",
      "Epoch 790/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0064\n",
      "Epoch 791/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 792/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0066\n",
      "Epoch 793/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0057\n",
      "Epoch 794/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0063\n",
      "Epoch 795/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0056\n",
      "Epoch 796/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0063\n",
      "Epoch 797/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0060\n",
      "Epoch 798/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0059\n",
      "Epoch 799/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0059\n",
      "Epoch 800/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0060\n",
      "Epoch 801/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0056\n",
      "Epoch 802/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0060\n",
      "Epoch 803/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0060\n",
      "Epoch 804/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0059\n",
      "Epoch 805/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0065\n",
      "Epoch 806/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0055\n",
      "Epoch 807/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0058\n",
      "Epoch 808/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0062\n",
      "Epoch 809/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0060\n",
      "Epoch 810/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 811/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0062\n",
      "Epoch 812/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0055\n",
      "Epoch 813/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0057\n",
      "Epoch 814/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0061\n",
      "Epoch 815/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 816/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0062\n",
      "Epoch 817/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0056\n",
      "Epoch 818/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0061\n",
      "Epoch 819/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 820/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0057\n",
      "Epoch 821/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0061\n",
      "Epoch 822/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 823/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0054\n",
      "Epoch 824/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0062\n",
      "Epoch 825/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 826/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0061\n",
      "Epoch 827/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 828/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0054\n",
      "Epoch 829/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 830/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0062\n",
      "Epoch 831/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0059\n",
      "Epoch 832/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0057\n",
      "Epoch 833/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 834/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0057\n",
      "Epoch 835/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0061\n",
      "Epoch 836/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0113 - val_loss: 0.0055\n",
      "Epoch 837/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0057\n",
      "Epoch 838/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 839/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0113 - val_loss: 0.0059\n",
      "Epoch 840/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 841/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0053\n",
      "Epoch 842/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 843/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0059\n",
      "Epoch 844/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0054\n",
      "Epoch 845/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0059\n",
      "Epoch 846/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0054\n",
      "Epoch 847/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0060\n",
      "Epoch 848/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0057\n",
      "Epoch 849/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0059\n",
      "Epoch 850/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0058\n",
      "Epoch 851/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0054\n",
      "Epoch 852/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0062\n",
      "Epoch 853/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0054\n",
      "Epoch 854/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0056\n",
      "Epoch 855/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 856/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0057\n",
      "Epoch 857/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 858/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0057\n",
      "Epoch 859/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0062\n",
      "Epoch 860/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 861/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0053\n",
      "Epoch 862/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0056\n",
      "Epoch 863/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0061\n",
      "Epoch 864/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0062\n",
      "Epoch 865/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0054\n",
      "Epoch 866/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0053\n",
      "Epoch 867/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0057\n",
      "Epoch 868/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0058\n",
      "Epoch 869/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 870/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0054\n",
      "Epoch 871/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 872/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0055\n",
      "Epoch 873/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0054\n",
      "Epoch 874/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0057\n",
      "Epoch 875/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0054\n",
      "Epoch 876/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0057\n",
      "Epoch 877/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0053\n",
      "Epoch 878/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0058\n",
      "Epoch 879/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0053\n",
      "Epoch 880/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0057\n",
      "Epoch 881/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0054\n",
      "Epoch 882/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0052\n",
      "Epoch 883/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0059\n",
      "Epoch 884/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0053\n",
      "Epoch 885/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 886/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0055\n",
      "Epoch 887/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0059\n",
      "Epoch 888/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0053\n",
      "Epoch 889/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0060\n",
      "Epoch 890/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0055\n",
      "Epoch 891/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0053\n",
      "Epoch 892/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0060\n",
      "Epoch 893/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0056\n",
      "Epoch 894/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0055\n",
      "Epoch 895/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0061\n",
      "Epoch 896/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0054\n",
      "Epoch 897/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 898/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0052\n",
      "Epoch 899/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0053\n",
      "Epoch 900/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0056\n",
      "Epoch 901/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0052\n",
      "Epoch 902/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 903/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0054\n",
      "Epoch 904/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0060\n",
      "Epoch 905/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0053\n",
      "Epoch 906/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0061\n",
      "Epoch 907/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0060\n",
      "Epoch 908/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0054\n",
      "Epoch 909/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0056\n",
      "Epoch 910/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0053\n",
      "Epoch 911/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0060\n",
      "Epoch 912/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0054\n",
      "Epoch 913/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0058\n",
      "Epoch 914/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0056\n",
      "Epoch 915/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0059\n",
      "Epoch 916/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0053\n",
      "Epoch 917/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0056\n",
      "Epoch 918/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0057\n",
      "Epoch 919/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0052\n",
      "Epoch 920/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0052\n",
      "Epoch 921/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0057\n",
      "Epoch 922/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0059\n",
      "Epoch 923/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0052\n",
      "Epoch 924/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0054\n",
      "Epoch 925/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0055\n",
      "Epoch 926/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0059\n",
      "Epoch 927/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0052\n",
      "Epoch 928/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0057\n",
      "Epoch 929/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0051\n",
      "Epoch 930/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0053\n",
      "Epoch 931/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0057\n",
      "Epoch 932/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0054\n",
      "Epoch 933/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0059\n",
      "Epoch 934/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0054\n",
      "Epoch 935/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 936/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0051\n",
      "Epoch 937/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0054\n",
      "Epoch 938/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0053\n",
      "Epoch 939/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0105 - val_loss: 0.0057\n",
      "Epoch 940/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0051\n",
      "Epoch 941/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0056\n",
      "Epoch 942/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0053\n",
      "Epoch 943/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0054\n",
      "Epoch 944/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0055\n",
      "Epoch 945/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0051\n",
      "Epoch 946/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0053\n",
      "Epoch 947/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0056\n",
      "Epoch 948/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0054\n",
      "Epoch 949/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 950/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0056\n",
      "Epoch 951/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0056\n",
      "Epoch 952/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0059\n",
      "Epoch 953/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0054\n",
      "Epoch 954/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0053\n",
      "Epoch 955/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0054\n",
      "Epoch 956/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0050\n",
      "Epoch 957/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 958/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0053\n",
      "Epoch 959/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0053\n",
      "Epoch 960/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0057\n",
      "Epoch 961/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0053\n",
      "Epoch 962/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0059\n",
      "Epoch 963/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0051\n",
      "Epoch 964/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 965/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0053\n",
      "Epoch 966/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0058\n",
      "Epoch 967/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0051\n",
      "Epoch 968/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0059\n",
      "Epoch 969/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0055\n",
      "Epoch 970/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0053\n",
      "Epoch 971/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0060\n",
      "Epoch 972/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0050\n",
      "Epoch 973/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0055\n",
      "Epoch 974/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0052\n",
      "Epoch 975/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0053\n",
      "Epoch 976/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0057\n",
      "Epoch 977/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0054\n",
      "Epoch 978/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 979/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0057\n",
      "Epoch 980/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0053\n",
      "Epoch 981/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0051\n",
      "Epoch 982/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 983/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0054\n",
      "Epoch 984/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 985/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0050\n",
      "Epoch 986/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0060\n",
      "Epoch 987/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0052\n",
      "Epoch 988/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0060\n",
      "Epoch 989/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 990/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0051\n",
      "Epoch 991/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0060\n",
      "Epoch 992/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 993/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0051\n",
      "Epoch 994/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0057\n",
      "Epoch 995/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0053\n",
      "Epoch 996/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0059\n",
      "Epoch 997/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 998/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 999/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0053\n",
      "Epoch 1000/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0056\n",
      "Epoch 1001/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0054\n",
      "Epoch 1002/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0053\n",
      "Epoch 1003/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 1004/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0053\n",
      "Epoch 1005/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0054\n",
      "Epoch 1006/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0052\n",
      "Epoch 1007/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0056\n",
      "Epoch 1008/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0054\n",
      "Epoch 1009/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0056\n",
      "Epoch 1010/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0058\n",
      "Epoch 1011/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 1012/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0054\n",
      "Epoch 1013/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0057\n",
      "Epoch 1014/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0051\n",
      "Epoch 1015/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0052\n",
      "Epoch 1016/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0053\n",
      "Epoch 1017/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0061\n",
      "Epoch 1018/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0049\n",
      "Epoch 1019/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0056\n",
      "Epoch 1020/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 1021/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0052\n",
      "Epoch 1022/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 1023/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0052\n",
      "Epoch 1024/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 1025/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0051\n",
      "Epoch 1026/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 1027/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0051\n",
      "Epoch 1028/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0062\n",
      "Epoch 1029/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 1030/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0055\n",
      "Epoch 1031/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 1032/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0054\n",
      "Epoch 1033/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0056\n",
      "Epoch 1034/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0050\n",
      "Epoch 1035/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0050\n",
      "Epoch 1036/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 1037/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 1038/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 1039/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 1040/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0057\n",
      "Epoch 1041/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0053\n",
      "Epoch 1042/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0051\n",
      "Epoch 1043/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0058\n",
      "Epoch 1044/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 1045/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0050\n",
      "Epoch 1046/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0051\n",
      "Epoch 1047/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0059\n",
      "Epoch 1048/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0056\n",
      "Epoch 1049/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0051\n",
      "Epoch 1050/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0054\n",
      "Epoch 1051/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0055\n",
      "Epoch 1052/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 1053/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 1054/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 1055/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0057\n",
      "Epoch 1056/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0049\n",
      "Epoch 1057/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0053\n",
      "Epoch 1058/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0104 - val_loss: 0.0057\n",
      "Epoch 1059/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 1060/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0051\n",
      "Epoch 1061/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 1062/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0055\n",
      "Epoch 1063/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0058\n",
      "Epoch 1064/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0049\n",
      "Epoch 1065/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0057\n",
      "Epoch 1066/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0054\n",
      "Epoch 1067/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0056\n",
      "Epoch 1068/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 1069/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0050\n",
      "Epoch 1070/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0049\n",
      "Epoch 1071/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0102 - val_loss: 0.0057\n",
      "Epoch 1072/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0056\n",
      "Epoch 1073/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0050\n",
      "Epoch 1074/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0061\n",
      "Epoch 1075/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0057\n",
      "Epoch 1076/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 1077/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0049\n",
      "Epoch 1078/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0059\n",
      "Epoch 1079/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0051\n",
      "Epoch 1080/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0058\n",
      "Epoch 1081/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 1082/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0050\n",
      "Epoch 1083/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 1084/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 1085/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0053\n",
      "Epoch 1086/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 1087/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 1088/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0051\n",
      "Epoch 1089/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 1090/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0053\n",
      "Epoch 1091/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0103 - val_loss: 0.0060\n",
      "Epoch 1092/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0051\n",
      "Epoch 1093/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 1094/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 1095/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0053\n",
      "Epoch 1096/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0057\n",
      "Epoch 1097/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0057\n",
      "Epoch 1098/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0054\n",
      "Epoch 1099/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 1100/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0050\n",
      "Epoch 1101/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0050\n",
      "Epoch 1102/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 1103/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0053\n",
      "Epoch 1104/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 1105/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 1106/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 1107/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0053\n",
      "Epoch 1108/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0055\n",
      "Epoch 1109/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0052\n",
      "Epoch 1110/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0050\n",
      "Epoch 1111/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0055\n",
      "Epoch 1112/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 1113/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 1114/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 1115/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0055\n",
      "Epoch 1116/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 1117/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0053\n",
      "Epoch 1118/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0049\n",
      "Epoch 1119/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0051\n",
      "Epoch 1120/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0050\n",
      "Epoch 1121/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0061\n",
      "Epoch 1122/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 1123/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 1124/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0057\n",
      "Epoch 1125/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0050\n",
      "Epoch 1126/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0058\n",
      "Epoch 1127/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0052\n",
      "Epoch 1128/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0052\n",
      "Epoch 1129/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0051\n",
      "Epoch 1130/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0049\n",
      "Epoch 1131/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0053\n",
      "Epoch 1132/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 1133/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0052\n",
      "Epoch 1134/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 1135/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 1136/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0050\n",
      "Epoch 1137/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0055\n",
      "Epoch 1138/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 1139/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 1140/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 1141/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 1142/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 1143/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0058\n",
      "Epoch 1144/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 1145/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0049\n",
      "Epoch 1146/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 1147/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0052\n",
      "Epoch 1148/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0051\n",
      "Epoch 1149/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 1150/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0050\n",
      "Epoch 1151/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 1152/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0049\n",
      "Epoch 1153/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 1154/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 1155/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0058\n",
      "Epoch 1156/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0050\n",
      "Epoch 1157/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0058\n",
      "Epoch 1158/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0049\n",
      "Epoch 1159/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 1160/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0050\n",
      "Epoch 1161/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0057\n",
      "Epoch 1162/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0051\n",
      "Epoch 1163/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 1164/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0049\n",
      "Epoch 1165/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0051\n",
      "Epoch 1166/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0057\n",
      "Epoch 1167/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0050\n",
      "Epoch 1168/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 1169/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 1170/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 1171/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 1172/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0057\n",
      "Epoch 1173/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0048\n",
      "Epoch 1174/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0057\n",
      "Epoch 1175/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0048\n",
      "Epoch 1176/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0061\n",
      "Epoch 1177/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0053\n",
      "Epoch 1178/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0049\n",
      "Epoch 1179/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0100 - val_loss: 0.0059\n",
      "Epoch 1180/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0057\n",
      "Epoch 1181/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0050\n",
      "Epoch 1182/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0055\n",
      "Epoch 1183/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0049\n",
      "Epoch 1184/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0051\n",
      "Epoch 1185/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 1186/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0047\n",
      "Epoch 1187/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 1188/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0048\n",
      "Epoch 1189/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 1190/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0048\n",
      "Epoch 1191/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 1192/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 1193/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0055\n",
      "Epoch 1194/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0050\n",
      "Epoch 1195/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0050\n",
      "Epoch 1196/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 1197/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0052\n",
      "Epoch 1198/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 1199/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0058\n",
      "Epoch 1200/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 1201/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0058\n",
      "Epoch 1202/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0049\n",
      "Epoch 1203/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0049\n",
      "Epoch 1204/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0057\n",
      "Epoch 1205/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0049\n",
      "Epoch 1206/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0058\n",
      "Epoch 1207/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 1208/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0049\n",
      "Epoch 1209/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0051\n",
      "Epoch 1210/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0059\n",
      "Epoch 1211/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 1212/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0057\n",
      "Epoch 1213/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 1214/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0049\n",
      "Epoch 1215/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0050\n",
      "Epoch 1216/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0059\n",
      "Epoch 1217/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0050\n",
      "Epoch 1218/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0061\n",
      "Epoch 1219/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0051\n",
      "Epoch 1220/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 1221/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0049\n",
      "Epoch 1222/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0049\n",
      "Epoch 1223/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 1224/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 1225/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0057\n",
      "Epoch 1226/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 1227/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 1228/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0053\n",
      "Epoch 1229/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0052\n",
      "Epoch 1230/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 1231/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0057\n",
      "Epoch 1232/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0052\n",
      "Epoch 1233/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 1234/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0049\n",
      "Epoch 1235/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0048\n",
      "Epoch 1236/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 1237/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 1238/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 1239/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 1240/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0051\n",
      "Epoch 1241/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 1242/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 1243/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0049\n",
      "Epoch 1244/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0050\n",
      "Epoch 1245/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 1246/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0053\n",
      "Epoch 1247/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 1248/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1249/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0047\n",
      "Epoch 1250/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 1251/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0049\n",
      "Epoch 1252/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 1253/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 1254/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0057\n",
      "Epoch 1255/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0049\n",
      "Epoch 1256/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0052\n",
      "Epoch 1257/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 1258/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0052\n",
      "Epoch 1259/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0048\n",
      "Epoch 1260/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 1261/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0053\n",
      "Epoch 1262/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 1263/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0053\n",
      "Epoch 1264/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0049\n",
      "Epoch 1265/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0047\n",
      "Epoch 1266/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 1267/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0053\n",
      "Epoch 1268/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0055\n",
      "Epoch 1269/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0051\n",
      "Epoch 1270/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 1271/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0054\n",
      "Epoch 1272/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 1273/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0048\n",
      "Epoch 1274/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0048\n",
      "Epoch 1275/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0056\n",
      "Epoch 1276/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 1277/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 1278/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0047\n",
      "Epoch 1279/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0053\n",
      "Epoch 1280/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 1281/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 1282/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0056\n",
      "Epoch 1283/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 1284/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 1285/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0052\n",
      "Epoch 1286/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0047\n",
      "Epoch 1287/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 1288/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 1289/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 1290/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 1291/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0050\n",
      "Epoch 1292/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0048\n",
      "Epoch 1293/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1294/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0048\n",
      "Epoch 1295/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 1296/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 1297/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1298/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0052\n",
      "Epoch 1299/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0047\n",
      "Epoch 1300/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1301/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0097 - val_loss: 0.0054\n",
      "Epoch 1302/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0048\n",
      "Epoch 1303/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 1304/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 1305/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 1306/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 1307/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 1308/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 1309/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0098 - val_loss: 0.0046\n",
      "Epoch 1310/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0051\n",
      "Epoch 1311/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0050\n",
      "Epoch 1312/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 1313/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0050\n",
      "Epoch 1314/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 1315/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 1316/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 1317/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0047\n",
      "Epoch 1318/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 1319/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 1320/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 1321/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 1322/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0048\n",
      "Epoch 1323/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 1324/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0048\n",
      "Epoch 1325/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0056\n",
      "Epoch 1326/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 1327/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 1328/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 1329/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 1330/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0047\n",
      "Epoch 1331/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0049\n",
      "Epoch 1332/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0047\n",
      "Epoch 1333/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 1334/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 1335/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 1336/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 1337/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 1338/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 1339/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0052\n",
      "Epoch 1340/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 1341/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0053\n",
      "Epoch 1342/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0047\n",
      "Epoch 1343/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 1344/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0049\n",
      "Epoch 1345/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 1346/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 1347/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 1348/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 1349/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0052\n",
      "Epoch 1350/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 1351/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 1352/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 1353/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 1354/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 1355/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0054\n",
      "Epoch 1356/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 1357/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 1358/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 1359/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0048\n",
      "Epoch 1360/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0052\n",
      "Epoch 1361/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0048\n",
      "Epoch 1362/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 1363/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0049\n",
      "Epoch 1364/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 1365/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0052\n",
      "Epoch 1366/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0047\n",
      "Epoch 1367/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0045\n",
      "Epoch 1368/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 1369/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 1370/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 1371/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 1372/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0047\n",
      "Epoch 1373/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 1374/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0048\n",
      "Epoch 1375/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0050\n",
      "Epoch 1376/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 1377/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 1378/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0049\n",
      "Epoch 1379/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 1380/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0050\n",
      "Epoch 1381/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0055\n",
      "Epoch 1382/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 1383/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 1384/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1385/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0049\n",
      "Epoch 1386/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0052\n",
      "Epoch 1387/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 1388/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1389/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0047\n",
      "Epoch 1390/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 1391/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 1392/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 1393/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1394/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 1395/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0047\n",
      "Epoch 1396/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0047\n",
      "Epoch 1397/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 1398/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0045\n",
      "Epoch 1399/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0050\n",
      "Epoch 1400/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 1401/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 1402/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 1403/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 1404/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0047\n",
      "Epoch 1405/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 1406/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 1407/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1408/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0054\n",
      "Epoch 1409/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0095 - val_loss: 0.0049\n",
      "Epoch 1410/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 1411/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0046\n",
      "Epoch 1412/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 1413/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 1414/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 1415/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0052\n",
      "Epoch 1416/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 1417/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 1418/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 1419/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 1420/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 1421/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 1422/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 1423/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 1424/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0048\n",
      "Epoch 1425/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 1426/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 1427/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 1428/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 1429/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 1430/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 1431/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 1432/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0045\n",
      "Epoch 1433/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0047\n",
      "Epoch 1434/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 1435/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1436/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0048\n",
      "Epoch 1437/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 1438/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0048\n",
      "Epoch 1439/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 1440/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 1441/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 1442/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 1443/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0053\n",
      "Epoch 1444/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0047\n",
      "Epoch 1445/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 1446/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 1447/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 1448/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 1449/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 1450/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0052\n",
      "Epoch 1451/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 1452/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 1453/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 1454/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 1455/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 1456/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0053\n",
      "Epoch 1457/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 1458/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 1459/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 1460/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0045\n",
      "Epoch 1461/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 1462/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0050\n",
      "Epoch 1463/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 1464/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 1465/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 1466/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 1467/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0045\n",
      "Epoch 1468/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 1469/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1470/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 1471/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0049\n",
      "Epoch 1472/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 1473/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0049\n",
      "Epoch 1474/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1475/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 1476/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 1477/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 1478/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 1479/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 1480/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 1481/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 1482/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 1483/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 1484/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 1485/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0056\n",
      "Epoch 1486/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 1487/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 1488/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 1489/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 1490/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 1491/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0044\n",
      "Epoch 1492/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 1493/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 1494/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0051\n",
      "Epoch 1495/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 1496/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 1497/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 1498/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 1499/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1500/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 1501/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 1502/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0048\n",
      "Epoch 1503/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 1504/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 1505/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 1506/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0046\n",
      "Epoch 1507/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 1508/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 1509/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 1510/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 1511/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0050\n",
      "Epoch 1512/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 1513/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 1514/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 1515/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 1516/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1517/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 1518/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 1519/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 1520/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 1521/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 1522/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 1523/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 1524/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 1525/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 1526/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 1527/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1528/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1529/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 1530/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 1531/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 1532/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 1533/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 1534/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1535/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 1536/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 1537/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0048\n",
      "Epoch 1538/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1539/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 1540/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 1541/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 1542/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0047\n",
      "Epoch 1543/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0054\n",
      "Epoch 1544/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 1545/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 1546/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 1547/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1548/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 1549/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1550/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 1551/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 1552/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 1553/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 1554/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 1555/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1556/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0048\n",
      "Epoch 1557/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 1558/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 1559/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 1560/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1561/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 1562/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 1563/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 1564/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 1565/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0045\n",
      "Epoch 1566/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1567/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 1568/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 1569/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0053\n",
      "Epoch 1570/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0047\n",
      "Epoch 1571/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 1572/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 1573/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 1574/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 1575/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0047\n",
      "Epoch 1576/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 1577/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 1578/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1579/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 1580/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1581/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0048\n",
      "Epoch 1582/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 1583/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 1584/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 1585/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1586/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 1587/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 1588/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 1589/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 1590/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 1591/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 1592/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 1593/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1594/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 1595/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 1596/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 1597/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 1598/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 1599/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 1600/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 1601/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1602/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1603/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1604/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 1605/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 1606/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 1607/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1608/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1609/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0047\n",
      "Epoch 1610/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1611/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1612/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 1613/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1614/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 1615/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1616/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1617/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1618/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 1619/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 1620/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 1621/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 1622/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - val_loss: 0.0047\n",
      "Epoch 1623/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 1624/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 1625/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0052\n",
      "Epoch 1626/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 1627/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 1628/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 1629/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 1630/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1631/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 1632/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1633/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 1634/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1635/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 1636/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 1637/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 1638/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0047\n",
      "Epoch 1639/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0050\n",
      "Epoch 1640/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 1641/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 1642/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0047\n",
      "Epoch 1643/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 1644/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 1645/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 1646/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1647/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1648/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1649/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1650/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 1651/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1652/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1653/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1654/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 1655/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 1656/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1657/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 1658/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 1659/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0043\n",
      "Epoch 1660/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 1661/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1662/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 1663/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1664/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 1665/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1666/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 1667/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1668/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1669/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 1670/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 1671/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 1672/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 1673/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0043\n",
      "Epoch 1674/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 1675/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1676/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 1677/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0048\n",
      "Epoch 1678/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0048\n",
      "Epoch 1679/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 1680/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 1681/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1682/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 1683/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Epoch 1684/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 1685/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1686/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 1687/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 1688/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 1689/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1690/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0047\n",
      "Epoch 1691/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 1692/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1693/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 1694/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 1695/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 1696/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 1697/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 1698/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 1699/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1700/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1701/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0050\n",
      "Epoch 1702/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0054\n",
      "Epoch 1703/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0047\n",
      "Epoch 1704/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 1705/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 1706/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1707/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1708/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0049\n",
      "Epoch 1709/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1710/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1711/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1712/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 1713/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 1714/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 1715/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 1716/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1717/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 1718/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1719/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0047\n",
      "Epoch 1720/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 1721/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0045\n",
      "Epoch 1722/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0053\n",
      "Epoch 1723/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1724/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1725/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1726/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 1727/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1728/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 1729/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0047\n",
      "Epoch 1730/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 1731/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 1732/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1733/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1734/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1735/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 1736/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 1737/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 1738/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 1739/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0048\n",
      "Epoch 1740/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 1741/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 1742/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 1743/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 1744/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1745/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 1746/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1747/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1748/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 1749/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1750/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 1751/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 1752/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 1753/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1754/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 1755/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 1756/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0048\n",
      "Epoch 1757/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0090 - val_loss: 0.0047\n",
      "Epoch 1758/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1759/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1760/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1761/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1762/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1763/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1764/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1765/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1766/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1767/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1768/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 1769/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1770/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 1771/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0047\n",
      "Epoch 1772/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1773/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1774/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 1775/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1776/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1777/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1778/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1779/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1780/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 1781/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 1782/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1783/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1784/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1785/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1786/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1787/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1788/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1789/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1790/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1791/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 1792/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1793/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1794/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 1795/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0043\n",
      "Epoch 1796/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0052\n",
      "Epoch 1797/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1798/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1799/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 1800/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1801/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1802/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 1803/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 1804/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1805/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0044\n",
      "Epoch 1806/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 1807/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1808/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 1809/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1810/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1811/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 1812/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 1813/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 1814/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1815/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1816/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1817/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 1818/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 1819/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1820/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1821/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1822/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1823/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1824/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1825/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1826/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 1827/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1828/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 1829/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1830/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1831/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1832/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 1833/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1834/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1835/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0047\n",
      "Epoch 1836/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1837/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1838/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1839/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 1840/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 1841/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 1842/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 1843/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 1844/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1845/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1846/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1847/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 1848/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1849/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1850/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1851/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 1852/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1853/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1854/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1855/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 1856/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 1857/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0047\n",
      "Epoch 1858/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 1859/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1860/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 1861/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0050\n",
      "Epoch 1862/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 1863/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 1864/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0043\n",
      "Epoch 1865/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0046\n",
      "Epoch 1866/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 1867/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1868/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0048\n",
      "Epoch 1869/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 1870/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1871/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 1872/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1873/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1874/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 1875/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1876/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 1877/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1878/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1879/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1880/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1881/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1882/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 1883/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1884/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0047\n",
      "Epoch 1885/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1886/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 1887/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1888/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1889/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1890/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 1891/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 1892/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 1893/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 1894/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - val_loss: 0.0042\n",
      "Epoch 1895/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1896/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1897/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1898/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 1899/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 1900/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1901/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1902/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 1903/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 1904/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 1905/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1906/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1907/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1908/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1909/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1910/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1911/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1912/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 1913/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1914/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 1915/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 1916/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 1917/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 1918/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1919/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 1920/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 1921/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0045\n",
      "Epoch 1922/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0051\n",
      "Epoch 1923/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1924/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 1925/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 1926/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 1927/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 1928/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1929/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 1930/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 1931/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0043\n",
      "Epoch 1932/2000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 1933/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 1934/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 1935/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1936/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 1937/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1938/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1939/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 1940/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1941/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1942/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 1943/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 1944/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 1945/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 1946/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1947/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1948/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 1949/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 1950/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1951/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0045\n",
      "Epoch 1952/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1953/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 1954/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1955/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1956/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 1957/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 1958/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0053\n",
      "Epoch 1959/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 1960/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1961/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1962/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1963/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1964/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1965/2000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 1966/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 1967/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1968/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1969/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1970/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 1971/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0044\n",
      "Epoch 1972/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1973/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 1974/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0046\n",
      "Epoch 1975/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0048\n",
      "Epoch 1976/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 1977/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1978/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 1979/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0048\n",
      "Epoch 1980/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1981/2000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0046\n",
      "Epoch 1982/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0042\n",
      "Epoch 1983/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0048\n",
      "Epoch 1984/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1985/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 1986/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 1987/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 1988/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 1989/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 1990/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0043\n",
      "Epoch 1991/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0047\n",
      "Epoch 1992/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 1993/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0044\n",
      "Epoch 1994/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 1995/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0042\n",
      "Epoch 1996/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 1997/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 1998/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 1999/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 2000/2000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0044\n"
     ]
    }
   ],
   "source": [
    "# Set early stopping monitor so the model stops training when it won't improve anymore\n",
    "esm = EarlyStopping(monitor = 'loss', patience = 70)\n",
    "# Set the optimizer\n",
    "opt = tf.optimizers.SGD(learning_rate = 0.001)\n",
    "#design network\n",
    "batch_size = int(round(X_train.shape[0]*0.1))\n",
    "# fit network\n",
    "model.compile(loss='mae', optimizer=opt)\n",
    "history = model.fit(X_train, y_train, epochs=2000, batch_size= batch_size, verbose=1,\n",
    "    shuffle=False, validation_split=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)\n",
    "predict = [float(predict[i]) for i in range(len(predict))]\n",
    "pred = eu.scale_back_pct(predict, close_test)\n",
    "updown_pred = eu.ud_pred(pred, close_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.6247637051039697\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(updown_pred)\n",
    "df[\"Close\"] = list(close_test)\n",
    "df[\"updown_pred\"] = df.iloc[:,0]\n",
    "df[\"updown_actual\"] = eu.ud(close_test)\n",
    "df[\"Scaled_pred\"] = pred\n",
    "df[\"Pred\"] = predict\n",
    "df = df.iloc[:,1:] \n",
    "acc = (df[\"updown_pred\"] == df[\"updown_actual\"]).sum()/df.shape[0]\n",
    "print('Model Accuracy: ', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>updown_pred</th>\n",
       "      <th>updown_actual</th>\n",
       "      <th>Scaled_pred</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6823.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6823.750000</td>\n",
       "      <td>-0.000521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6813.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6805.745461</td>\n",
       "      <td>-0.002639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6845.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6806.429642</td>\n",
       "      <td>-0.000964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6931.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6834.255428</td>\n",
       "      <td>-0.001679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6965.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6911.383191</td>\n",
       "      <td>-0.002830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>14654.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22248.415971</td>\n",
       "      <td>0.548201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>14447.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17915.897613</td>\n",
       "      <td>0.222594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>14763.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19179.502692</td>\n",
       "      <td>0.327577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>14755.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18006.383735</td>\n",
       "      <td>0.219635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>14985.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14598.890559</td>\n",
       "      <td>-0.010630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Close  updown_pred  updown_actual   Scaled_pred      Pred\n",
       "0      6823.75            1              1   6823.750000 -0.000521\n",
       "1      6813.00            0              0   6805.745461 -0.002639\n",
       "2      6845.75            0              1   6806.429642 -0.000964\n",
       "3      6931.00            0              1   6834.255428 -0.001679\n",
       "4      6965.75            0              1   6911.383191 -0.002830\n",
       "...        ...          ...            ...           ...       ...\n",
       "1053  14654.00            1              1  22248.415971  0.548201\n",
       "1054  14447.00            1              0  17915.897613  0.222594\n",
       "1055  14763.75            1              1  19179.502692  0.327577\n",
       "1056  14755.75            1              0  18006.383735  0.219635\n",
       "1057  14985.25            0              1  14598.890559 -0.010630\n",
       "\n",
       "[1058 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df['Scaled_pred'], label='pred')\n",
    "plt.plot(df[\"Close\"], label='Close')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1984ee4f820>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_equity = pd.DataFrame()\n",
    "df_equity[\"long_equity\"] = eu.long_equity(df[\"updown_pred\"], df[\"Close\"])\n",
    "df_equity[\"short_equity\"] = eu.short_equity(df[\"updown_pred\"], df[\"Close\"])\n",
    "df_equity[\"total_equity\"] = eu.total_equity(df[\"updown_pred\"], df[\"Close\"])\n",
    "df_equity[\"total_equity\"].cumsum().plot()\n",
    "df[\"Close\"].plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RF_pred</th>\n",
       "      <th>RF_accuracy</th>\n",
       "      <th>RF_prob</th>\n",
       "      <th>SVC_pred</th>\n",
       "      <th>SVC_accuracy</th>\n",
       "      <th>SVC_prob</th>\n",
       "      <th>XGB_pred</th>\n",
       "      <th>XGB_accuracy</th>\n",
       "      <th>XGB_prob</th>\n",
       "      <th>ANN_pred</th>\n",
       "      <th>ANN_accuracy</th>\n",
       "      <th>ANN_prob</th>\n",
       "      <th>LGBM_pred</th>\n",
       "      <th>LGBM_accuracy</th>\n",
       "      <th>LGBM_prob</th>\n",
       "      <th>y</th>\n",
       "      <th>kNN_pred</th>\n",
       "      <th>kNN_accuracy</th>\n",
       "      <th>kNN_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.657543</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.544082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.536098</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464561</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529301</td>\n",
       "      <td>0.532322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.482987</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.324182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.544076</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.390463</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529301</td>\n",
       "      <td>0.518503</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.482987</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.496864</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.545460</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.552227</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529301</td>\n",
       "      <td>0.515129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.482987</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.574333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.545009</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.596263</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529301</td>\n",
       "      <td>0.531008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.482987</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.543872</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.483318</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529301</td>\n",
       "      <td>0.529314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.482987</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1053</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.679418</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.539406</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.598255</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529301</td>\n",
       "      <td>0.510938</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.482987</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>1054</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.555801</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.537904</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.567730</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464421</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529301</td>\n",
       "      <td>0.511045</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.482987</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>1055</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.573323</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.540966</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.561254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.463568</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529301</td>\n",
       "      <td>0.509250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.482987</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>1056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.719503</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.536726</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.590790</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.464013</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529301</td>\n",
       "      <td>0.510938</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.482987</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1057</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523629</td>\n",
       "      <td>0.531916</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558601</td>\n",
       "      <td>0.541307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533081</td>\n",
       "      <td>0.569102</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.462834</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529301</td>\n",
       "      <td>0.511825</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.482987</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1058 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  RF_pred  RF_accuracy   RF_prob  SVC_pred  SVC_accuracy  \\\n",
       "0              0        1     0.523629  0.657543         1      0.558601   \n",
       "1              1        0     0.523629  0.324182         1      0.558601   \n",
       "2              2        0     0.523629  0.496864         1      0.558601   \n",
       "3              3        1     0.523629  0.574333         1      0.558601   \n",
       "4              4        0     0.523629  0.421569         1      0.558601   \n",
       "...          ...      ...          ...       ...       ...           ...   \n",
       "1053        1053        1     0.523629  0.679418         1      0.558601   \n",
       "1054        1054        1     0.523629  0.555801         1      0.558601   \n",
       "1055        1055        1     0.523629  0.573323         1      0.558601   \n",
       "1056        1056        1     0.523629  0.719503         1      0.558601   \n",
       "1057        1057        1     0.523629  0.531916         1      0.558601   \n",
       "\n",
       "      SVC_prob  XGB_pred  XGB_accuracy  XGB_prob  ANN_pred  ANN_accuracy  \\\n",
       "0     0.544082         1      0.533081  0.536098         0      0.441399   \n",
       "1     0.544076         0      0.533081  0.390463         0      0.441399   \n",
       "2     0.545460         1      0.533081  0.552227         0      0.441399   \n",
       "3     0.545009         1      0.533081  0.596263         0      0.441399   \n",
       "4     0.543872         0      0.533081  0.483318         0      0.441399   \n",
       "...        ...       ...           ...       ...       ...           ...   \n",
       "1053  0.539406         1      0.533081  0.598255         0      0.441399   \n",
       "1054  0.537904         1      0.533081  0.567730         0      0.441399   \n",
       "1055  0.540966         1      0.533081  0.561254         0      0.441399   \n",
       "1056  0.536726         1      0.533081  0.590790         0      0.441399   \n",
       "1057  0.541307         1      0.533081  0.569102         0      0.441399   \n",
       "\n",
       "      ANN_prob  LGBM_pred  LGBM_accuracy  LGBM_prob  y  kNN_pred  \\\n",
       "0     0.464561          1       0.529301   0.532322  0         0   \n",
       "1     0.464505          1       0.529301   0.518503  1         0   \n",
       "2     0.464505          1       0.529301   0.515129  1         1   \n",
       "3     0.464505          1       0.529301   0.531008  1         0   \n",
       "4     0.464505          1       0.529301   0.529314  0         0   \n",
       "...        ...        ...            ...        ... ..       ...   \n",
       "1053  0.464011          1       0.529301   0.510938  0         1   \n",
       "1054  0.464421          1       0.529301   0.511045  1         0   \n",
       "1055  0.463568          1       0.529301   0.509250  0         0   \n",
       "1056  0.464013          1       0.529301   0.510938  1         1   \n",
       "1057  0.462834          1       0.529301   0.511825  1         1   \n",
       "\n",
       "      kNN_accuracy  kNN_prob  \n",
       "0         0.482987       0.5  \n",
       "1         0.482987       0.5  \n",
       "2         0.482987       1.0  \n",
       "3         0.482987       0.5  \n",
       "4         0.482987       0.0  \n",
       "...            ...       ...  \n",
       "1053      0.482987       1.0  \n",
       "1054      0.482987       0.5  \n",
       "1055      0.482987       0.0  \n",
       "1056      0.482987       1.0  \n",
       "1057      0.482987       1.0  \n",
       "\n",
       "[1058 rows x 20 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction = pd.read_csv(\"../data/model_accuracy_nsq.csv\", index_col = False)\n",
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction[\"LSTM_price_accuracy\"] = [acc for x in range(len(df_prediction))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv(\"../data/model_accuracy_nsq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
