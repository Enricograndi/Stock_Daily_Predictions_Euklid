{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Neural network libraries\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Visualization\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "#config = tf.compat.v1.ConfigProto(device_count = {'GPU': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary work on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_df = pd.read_csv(\"../data/IBM.csv\")\n",
    "#yahoo_df = yahoo_df.set_index(\"Date\")\n",
    "yahoo_df = yahoo_df.set_index(\"Date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = yahoo_df[['ROC_1', 'ROC_4', 'ROC_7', 'Momentum', '1 Day ROI', '3 Day ROI',\n",
    "       '5 Day ROI', '20 Day ROI', '6_day_RSI', 'MACD_12_26', 'SRSI_30',\n",
    "       'Williams_1', 'Williams_3', 'Williams_14', 'ATR_14', 'CCI']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = yahoo_df[['ROC_4', 'ROC_5', 'ROC_6', '4 Day ROI', '6 Day ROI', '30 Day ROI',\n",
    "       'RSI_3', 'RSI_4', 'CCI']]\n",
    "y = yahoo_df[\"Up down\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5151515151515151"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in 80/20 the dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    #df = data\n",
    "    for column in df:\n",
    "        df[column]=((df[column]-df[column].mean())/df[column].std())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model ANN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set early stopping monitor so the model stops training when it won't improve anymore\n",
    "esm = EarlyStopping(monitor = 'val_binary_accuracy',patience=50)\n",
    "\n",
    "# Set the optimizer\n",
    "opt = keras.optimizers.SGD(learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=[keras.metrics.Accuracy(),\n",
    "    keras.metrics.BinaryAccuracy(name=\"binary_accuracy\", dtype=None, threshold=0.49),\n",
    "    keras.metrics.MeanSquaredError(name='my_mse'),\n",
    "    keras.metrics.BinaryCrossentropy(),\n",
    "    keras.metrics.Hinge()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 3.5186 - accuracy: 0.1538 - binary_accuracy: 0.4717 - my_mse: 0.4736 - binary_crossentropy: 3.5186 - hinge: 0.9965 - val_loss: 1.0085 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.3574 - val_binary_crossentropy: 1.0085 - val_hinge: 1.0086\n",
      "Epoch 2/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.1977 - accuracy: 0.0081 - binary_accuracy: 0.4717 - my_mse: 0.3850 - binary_crossentropy: 1.1977 - hinge: 0.9910 - val_loss: 0.8681 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.3188 - val_binary_crossentropy: 0.8681 - val_hinge: 1.0127\n",
      "Epoch 3/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 1.0282 - accuracy: 0.0031 - binary_accuracy: 0.4717 - my_mse: 0.3583 - binary_crossentropy: 1.0282 - hinge: 0.9889 - val_loss: 0.8199 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.3027 - val_binary_crossentropy: 0.8199 - val_hinge: 1.0147\n",
      "Epoch 4/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.9673 - accuracy: 0.0016 - binary_accuracy: 0.4717 - my_mse: 0.3394 - binary_crossentropy: 0.9673 - hinge: 0.9877 - val_loss: 0.7862 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2902 - val_binary_crossentropy: 0.7862 - val_hinge: 1.0165\n",
      "Epoch 5/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.8945 - accuracy: 7.7963e-04 - binary_accuracy: 0.4712 - my_mse: 0.3249 - binary_crossentropy: 0.8945 - hinge: 0.9862 - val_loss: 0.7637 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2814 - val_binary_crossentropy: 0.7637 - val_hinge: 1.0178\n",
      "Epoch 6/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.8441 - accuracy: 0.0010 - binary_accuracy: 0.4709 - my_mse: 0.3121 - binary_crossentropy: 0.8441 - hinge: 0.9848 - val_loss: 0.7455 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2739 - val_binary_crossentropy: 0.7455 - val_hinge: 1.0192\n",
      "Epoch 7/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.8263 - accuracy: 5.1975e-04 - binary_accuracy: 0.4725 - my_mse: 0.3026 - binary_crossentropy: 0.8263 - hinge: 0.9831 - val_loss: 0.7331 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2685 - val_binary_crossentropy: 0.7331 - val_hinge: 1.0203\n",
      "Epoch 8/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.8015 - accuracy: 2.5988e-04 - binary_accuracy: 0.4706 - my_mse: 0.2955 - binary_crossentropy: 0.8015 - hinge: 0.9827 - val_loss: 0.7228 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2639 - val_binary_crossentropy: 0.7228 - val_hinge: 1.0214\n",
      "Epoch 9/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7920 - accuracy: 2.5988e-04 - binary_accuracy: 0.4701 - my_mse: 0.2887 - binary_crossentropy: 0.7920 - hinge: 0.9813 - val_loss: 0.7153 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2605 - val_binary_crossentropy: 0.7153 - val_hinge: 1.0222\n",
      "Epoch 10/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7660 - accuracy: 5.1975e-04 - binary_accuracy: 0.4756 - my_mse: 0.2818 - binary_crossentropy: 0.7660 - hinge: 0.9786 - val_loss: 0.7093 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2577 - val_binary_crossentropy: 0.7093 - val_hinge: 1.0230\n",
      "Epoch 11/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7564 - accuracy: 5.1975e-04 - binary_accuracy: 0.4730 - my_mse: 0.2794 - binary_crossentropy: 0.7564 - hinge: 0.9799 - val_loss: 0.7045 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2554 - val_binary_crossentropy: 0.7045 - val_hinge: 1.0237\n",
      "Epoch 12/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7480 - accuracy: 2.5988e-04 - binary_accuracy: 0.4758 - my_mse: 0.2739 - binary_crossentropy: 0.7480 - hinge: 0.9776 - val_loss: 0.7007 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2536 - val_binary_crossentropy: 0.7007 - val_hinge: 1.0244\n",
      "Epoch 13/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7424 - accuracy: 0.0000e+00 - binary_accuracy: 0.4709 - my_mse: 0.2731 - binary_crossentropy: 0.7424 - hinge: 0.9788 - val_loss: 0.6977 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2522 - val_binary_crossentropy: 0.6977 - val_hinge: 1.0250\n",
      "Epoch 14/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7393 - accuracy: 0.0010 - binary_accuracy: 0.4732 - my_mse: 0.2702 - binary_crossentropy: 0.7393 - hinge: 0.9782 - val_loss: 0.6953 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2510 - val_binary_crossentropy: 0.6953 - val_hinge: 1.0255\n",
      "Epoch 15/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7319 - accuracy: 2.5988e-04 - binary_accuracy: 0.4764 - my_mse: 0.2667 - binary_crossentropy: 0.7319 - hinge: 0.9768 - val_loss: 0.6934 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2501 - val_binary_crossentropy: 0.6934 - val_hinge: 1.0260\n",
      "Epoch 16/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7260 - accuracy: 0.0000e+00 - binary_accuracy: 0.4738 - my_mse: 0.2656 - binary_crossentropy: 0.7260 - hinge: 0.9775 - val_loss: 0.6919 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5304 - val_my_mse: 0.2494 - val_binary_crossentropy: 0.6919 - val_hinge: 1.0265\n",
      "Epoch 17/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7220 - accuracy: 0.0000e+00 - binary_accuracy: 0.4764 - my_mse: 0.2636 - binary_crossentropy: 0.7220 - hinge: 0.9766 - val_loss: 0.6908 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5304 - val_my_mse: 0.2488 - val_binary_crossentropy: 0.6908 - val_hinge: 1.0269\n",
      "Epoch 18/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7219 - accuracy: 0.0000e+00 - binary_accuracy: 0.4738 - my_mse: 0.2634 - binary_crossentropy: 0.7219 - hinge: 0.9771 - val_loss: 0.6900 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5304 - val_my_mse: 0.2484 - val_binary_crossentropy: 0.6900 - val_hinge: 1.0273\n",
      "Epoch 19/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7160 - accuracy: 0.0000e+00 - binary_accuracy: 0.4766 - my_mse: 0.2609 - binary_crossentropy: 0.7160 - hinge: 0.9758 - val_loss: 0.6894 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5350 - val_my_mse: 0.2481 - val_binary_crossentropy: 0.6894 - val_hinge: 1.0277\n",
      "Epoch 20/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7137 - accuracy: 0.0000e+00 - binary_accuracy: 0.4784 - my_mse: 0.2597 - binary_crossentropy: 0.7137 - hinge: 0.9750 - val_loss: 0.6890 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5514 - val_my_mse: 0.2479 - val_binary_crossentropy: 0.6890 - val_hinge: 1.0281\n",
      "Epoch 21/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7187 - accuracy: 0.0000e+00 - binary_accuracy: 0.4764 - my_mse: 0.2605 - binary_crossentropy: 0.7187 - hinge: 0.9763 - val_loss: 0.6887 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5537 - val_my_mse: 0.2478 - val_binary_crossentropy: 0.6887 - val_hinge: 1.0284\n",
      "Epoch 22/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7103 - accuracy: 0.0000e+00 - binary_accuracy: 0.4860 - my_mse: 0.2582 - binary_crossentropy: 0.7103 - hinge: 0.9746 - val_loss: 0.6886 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5514 - val_my_mse: 0.2477 - val_binary_crossentropy: 0.6886 - val_hinge: 1.0287\n",
      "Epoch 23/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7061 - accuracy: 0.0000e+00 - binary_accuracy: 0.4909 - my_mse: 0.2559 - binary_crossentropy: 0.7061 - hinge: 0.9729 - val_loss: 0.6885 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5444 - val_my_mse: 0.2477 - val_binary_crossentropy: 0.6885 - val_hinge: 1.0290\n",
      "Epoch 24/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7155 - accuracy: 0.0000e+00 - binary_accuracy: 0.4790 - my_mse: 0.2588 - binary_crossentropy: 0.7155 - hinge: 0.9758 - val_loss: 0.6886 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2477 - val_binary_crossentropy: 0.6886 - val_hinge: 1.0293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 2.5988e-04 - binary_accuracy: 0.4977 - my_mse: 0.2550 - binary_crossentropy: 0.7035 - hinge: 0.9725 - val_loss: 0.6887 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5421 - val_my_mse: 0.2478 - val_binary_crossentropy: 0.6887 - val_hinge: 1.0295\n",
      "Epoch 26/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7229 - accuracy: 0.0000e+00 - binary_accuracy: 0.4810 - my_mse: 0.2576 - binary_crossentropy: 0.7229 - hinge: 0.9749 - val_loss: 0.6888 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5444 - val_my_mse: 0.2478 - val_binary_crossentropy: 0.6888 - val_hinge: 1.0297\n",
      "Epoch 27/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.0000e+00 - binary_accuracy: 0.4964 - my_mse: 0.2546 - binary_crossentropy: 0.7027 - hinge: 0.9725 - val_loss: 0.6889 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5514 - val_my_mse: 0.2479 - val_binary_crossentropy: 0.6889 - val_hinge: 1.0299\n",
      "Epoch 28/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.0000e+00 - binary_accuracy: 0.4912 - my_mse: 0.2550 - binary_crossentropy: 0.7035 - hinge: 0.9731 - val_loss: 0.6891 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5397 - val_my_mse: 0.2480 - val_binary_crossentropy: 0.6891 - val_hinge: 1.0301\n",
      "Epoch 29/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.0000e+00 - binary_accuracy: 0.4893 - my_mse: 0.2548 - binary_crossentropy: 0.7099 - hinge: 0.9729 - val_loss: 0.6894 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2481 - val_binary_crossentropy: 0.6894 - val_hinge: 1.0302\n",
      "Epoch 30/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.0000e+00 - binary_accuracy: 0.5010 - my_mse: 0.2552 - binary_crossentropy: 0.7046 - hinge: 0.9732 - val_loss: 0.6896 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5327 - val_my_mse: 0.2482 - val_binary_crossentropy: 0.6896 - val_hinge: 1.0304\n",
      "Epoch 31/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.0000e+00 - binary_accuracy: 0.5026 - my_mse: 0.2557 - binary_crossentropy: 0.7068 - hinge: 0.9736 - val_loss: 0.6898 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5304 - val_my_mse: 0.2483 - val_binary_crossentropy: 0.6898 - val_hinge: 1.0306\n",
      "Epoch 32/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7068 - accuracy: 0.0000e+00 - binary_accuracy: 0.5010 - my_mse: 0.2548 - binary_crossentropy: 0.7068 - hinge: 0.9731 - val_loss: 0.6901 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5117 - val_my_mse: 0.2485 - val_binary_crossentropy: 0.6901 - val_hinge: 1.0307\n",
      "Epoch 33/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.0000e+00 - binary_accuracy: 0.4964 - my_mse: 0.2539 - binary_crossentropy: 0.7014 - hinge: 0.9724 - val_loss: 0.6903 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5164 - val_my_mse: 0.2486 - val_binary_crossentropy: 0.6903 - val_hinge: 1.0308\n",
      "Epoch 34/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7050 - accuracy: 0.0000e+00 - binary_accuracy: 0.4880 - my_mse: 0.2540 - binary_crossentropy: 0.7050 - hinge: 0.9725 - val_loss: 0.6905 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5210 - val_my_mse: 0.2487 - val_binary_crossentropy: 0.6905 - val_hinge: 1.0309\n",
      "Epoch 35/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 2.5988e-04 - binary_accuracy: 0.5088 - my_mse: 0.2524 - binary_crossentropy: 0.6981 - hinge: 0.9706 - val_loss: 0.6908 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5234 - val_my_mse: 0.2488 - val_binary_crossentropy: 0.6908 - val_hinge: 1.0310\n",
      "Epoch 36/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.0000e+00 - binary_accuracy: 0.5065 - my_mse: 0.2534 - binary_crossentropy: 0.7006 - hinge: 0.9717 - val_loss: 0.6910 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5070 - val_my_mse: 0.2489 - val_binary_crossentropy: 0.6910 - val_hinge: 1.0312\n",
      "Epoch 37/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.0000e+00 - binary_accuracy: 0.5016 - my_mse: 0.2536 - binary_crossentropy: 0.7044 - hinge: 0.9719 - val_loss: 0.6912 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5023 - val_my_mse: 0.2491 - val_binary_crossentropy: 0.6912 - val_hinge: 1.0312\n",
      "Epoch 38/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.0000e+00 - binary_accuracy: 0.5109 - my_mse: 0.2528 - binary_crossentropy: 0.6994 - hinge: 0.9713 - val_loss: 0.6915 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4907 - val_my_mse: 0.2492 - val_binary_crossentropy: 0.6915 - val_hinge: 1.0313\n",
      "Epoch 39/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.0000e+00 - binary_accuracy: 0.5010 - my_mse: 0.2537 - binary_crossentropy: 0.7013 - hinge: 0.9722 - val_loss: 0.6916 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5000 - val_my_mse: 0.2493 - val_binary_crossentropy: 0.6916 - val_hinge: 1.0314\n",
      "Epoch 40/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.0000e+00 - binary_accuracy: 0.5140 - my_mse: 0.2541 - binary_crossentropy: 0.7021 - hinge: 0.9724 - val_loss: 0.6918 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4953 - val_my_mse: 0.2494 - val_binary_crossentropy: 0.6918 - val_hinge: 1.0315\n",
      "Epoch 41/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.0000e+00 - binary_accuracy: 0.5195 - my_mse: 0.2518 - binary_crossentropy: 0.6973 - hinge: 0.9701 - val_loss: 0.6920 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4953 - val_my_mse: 0.2494 - val_binary_crossentropy: 0.6920 - val_hinge: 1.0316\n",
      "Epoch 42/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.0000e+00 - binary_accuracy: 0.5073 - my_mse: 0.2518 - binary_crossentropy: 0.7001 - hinge: 0.9702 - val_loss: 0.6922 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.5000 - val_my_mse: 0.2495 - val_binary_crossentropy: 0.6922 - val_hinge: 1.0316\n",
      "Epoch 43/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6992 - accuracy: 0.0000e+00 - binary_accuracy: 0.5125 - my_mse: 0.2528 - binary_crossentropy: 0.6992 - hinge: 0.9710 - val_loss: 0.6924 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4930 - val_my_mse: 0.2496 - val_binary_crossentropy: 0.6924 - val_hinge: 1.0317\n",
      "Epoch 44/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6995 - accuracy: 0.0000e+00 - binary_accuracy: 0.5065 - my_mse: 0.2528 - binary_crossentropy: 0.6995 - hinge: 0.9708 - val_loss: 0.6925 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4813 - val_my_mse: 0.2497 - val_binary_crossentropy: 0.6925 - val_hinge: 1.0317\n",
      "Epoch 45/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.0000e+00 - binary_accuracy: 0.5236 - my_mse: 0.2517 - binary_crossentropy: 0.6970 - hinge: 0.9696 - val_loss: 0.6927 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4673 - val_my_mse: 0.2498 - val_binary_crossentropy: 0.6927 - val_hinge: 1.0318\n",
      "Epoch 46/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.0000e+00 - binary_accuracy: 0.4979 - my_mse: 0.2544 - binary_crossentropy: 0.7038 - hinge: 0.9722 - val_loss: 0.6926 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4720 - val_my_mse: 0.2497 - val_binary_crossentropy: 0.6926 - val_hinge: 1.0318\n",
      "Epoch 47/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6998 - accuracy: 0.0000e+00 - binary_accuracy: 0.5164 - my_mse: 0.2531 - binary_crossentropy: 0.6998 - hinge: 0.9712 - val_loss: 0.6927 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4603 - val_my_mse: 0.2498 - val_binary_crossentropy: 0.6927 - val_hinge: 1.0318\n",
      "Epoch 48/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.0000e+00 - binary_accuracy: 0.5086 - my_mse: 0.2518 - binary_crossentropy: 0.7005 - hinge: 0.9702 - val_loss: 0.6929 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4579 - val_my_mse: 0.2499 - val_binary_crossentropy: 0.6929 - val_hinge: 1.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.0000e+00 - binary_accuracy: 0.5177 - my_mse: 0.2519 - binary_crossentropy: 0.7011 - hinge: 0.9701 - val_loss: 0.6930 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4579 - val_my_mse: 0.2500 - val_binary_crossentropy: 0.6930 - val_hinge: 1.0319\n",
      "Epoch 50/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.0000e+00 - binary_accuracy: 0.5052 - my_mse: 0.2528 - binary_crossentropy: 0.6993 - hinge: 0.9709 - val_loss: 0.6931 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4556 - val_my_mse: 0.2500 - val_binary_crossentropy: 0.6931 - val_hinge: 1.0320\n",
      "Epoch 51/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7044 - accuracy: 0.0000e+00 - binary_accuracy: 0.5047 - my_mse: 0.2534 - binary_crossentropy: 0.7044 - hinge: 0.9715 - val_loss: 0.6932 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4579 - val_my_mse: 0.2501 - val_binary_crossentropy: 0.6932 - val_hinge: 1.0320\n",
      "Epoch 52/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.0000e+00 - binary_accuracy: 0.5234 - my_mse: 0.2521 - binary_crossentropy: 0.7013 - hinge: 0.9700 - val_loss: 0.6933 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4533 - val_my_mse: 0.2501 - val_binary_crossentropy: 0.6933 - val_hinge: 1.0320\n",
      "Epoch 53/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.0000e+00 - binary_accuracy: 0.5130 - my_mse: 0.2510 - binary_crossentropy: 0.6988 - hinge: 0.9692 - val_loss: 0.6935 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4603 - val_my_mse: 0.2502 - val_binary_crossentropy: 0.6935 - val_hinge: 1.0321\n",
      "Epoch 54/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6974 - accuracy: 0.0000e+00 - binary_accuracy: 0.5236 - my_mse: 0.2519 - binary_crossentropy: 0.6974 - hinge: 0.9699 - val_loss: 0.6936 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4603 - val_my_mse: 0.2502 - val_binary_crossentropy: 0.6936 - val_hinge: 1.0321\n",
      "Epoch 55/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.0000e+00 - binary_accuracy: 0.5135 - my_mse: 0.2528 - binary_crossentropy: 0.6990 - hinge: 0.9712 - val_loss: 0.6937 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4579 - val_my_mse: 0.2503 - val_binary_crossentropy: 0.6937 - val_hinge: 1.0321\n",
      "Epoch 56/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6972 - accuracy: 0.0000e+00 - binary_accuracy: 0.5120 - my_mse: 0.2519 - binary_crossentropy: 0.6972 - hinge: 0.9700 - val_loss: 0.6938 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4579 - val_my_mse: 0.2504 - val_binary_crossentropy: 0.6938 - val_hinge: 1.0322\n",
      "Epoch 57/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.0000e+00 - binary_accuracy: 0.5096 - my_mse: 0.2516 - binary_crossentropy: 0.6967 - hinge: 0.9700 - val_loss: 0.6939 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4650 - val_my_mse: 0.2504 - val_binary_crossentropy: 0.6939 - val_hinge: 1.0322\n",
      "Epoch 58/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 2.5988e-04 - binary_accuracy: 0.5138 - my_mse: 0.2537 - binary_crossentropy: 0.7011 - hinge: 0.9718 - val_loss: 0.6940 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4673 - val_my_mse: 0.2504 - val_binary_crossentropy: 0.6940 - val_hinge: 1.0322\n",
      "Epoch 59/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.0000e+00 - binary_accuracy: 0.5198 - my_mse: 0.2513 - binary_crossentropy: 0.6962 - hinge: 0.9693 - val_loss: 0.6941 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4696 - val_my_mse: 0.2505 - val_binary_crossentropy: 0.6941 - val_hinge: 1.0323\n",
      "Epoch 60/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.0000e+00 - binary_accuracy: 0.5133 - my_mse: 0.2535 - binary_crossentropy: 0.7006 - hinge: 0.9716 - val_loss: 0.6942 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4720 - val_my_mse: 0.2505 - val_binary_crossentropy: 0.6942 - val_hinge: 1.0323\n",
      "Epoch 61/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 2.5988e-04 - binary_accuracy: 0.5223 - my_mse: 0.2524 - binary_crossentropy: 0.7017 - hinge: 0.9702 - val_loss: 0.6942 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4720 - val_my_mse: 0.2506 - val_binary_crossentropy: 0.6942 - val_hinge: 1.0323\n",
      "Epoch 62/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7046 - accuracy: 0.0000e+00 - binary_accuracy: 0.5112 - my_mse: 0.2537 - binary_crossentropy: 0.7046 - hinge: 0.9715 - val_loss: 0.6943 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4720 - val_my_mse: 0.2506 - val_binary_crossentropy: 0.6943 - val_hinge: 1.0323\n",
      "Epoch 63/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.0000e+00 - binary_accuracy: 0.5073 - my_mse: 0.2537 - binary_crossentropy: 0.7013 - hinge: 0.9718 - val_loss: 0.6943 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4720 - val_my_mse: 0.2506 - val_binary_crossentropy: 0.6943 - val_hinge: 1.0323\n",
      "Epoch 64/1000\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7000 - accuracy: 0.0000e+00 - binary_accuracy: 0.5068 - my_mse: 0.2529 - binary_crossentropy: 0.7000 - hinge: 0.9707 - val_loss: 0.6943 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4720 - val_my_mse: 0.2506 - val_binary_crossentropy: 0.6943 - val_hinge: 1.0323\n",
      "Epoch 65/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 2.5988e-04 - binary_accuracy: 0.5127 - my_mse: 0.2526 - binary_crossentropy: 0.7022 - hinge: 0.9707 - val_loss: 0.6943 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4696 - val_my_mse: 0.2506 - val_binary_crossentropy: 0.6943 - val_hinge: 1.0323\n",
      "Epoch 66/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.0000e+00 - binary_accuracy: 0.5161 - my_mse: 0.2524 - binary_crossentropy: 0.6985 - hinge: 0.9704 - val_loss: 0.6944 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4696 - val_my_mse: 0.2506 - val_binary_crossentropy: 0.6944 - val_hinge: 1.0324\n",
      "Epoch 67/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.0000e+00 - binary_accuracy: 0.5257 - my_mse: 0.2513 - binary_crossentropy: 0.6962 - hinge: 0.9694 - val_loss: 0.6944 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4696 - val_my_mse: 0.2507 - val_binary_crossentropy: 0.6944 - val_hinge: 1.0324\n",
      "Epoch 68/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6988 - accuracy: 0.0000e+00 - binary_accuracy: 0.5159 - my_mse: 0.2525 - binary_crossentropy: 0.6988 - hinge: 0.9707 - val_loss: 0.6945 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4696 - val_my_mse: 0.2507 - val_binary_crossentropy: 0.6945 - val_hinge: 1.0324\n",
      "Epoch 69/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7056 - accuracy: 2.5988e-04 - binary_accuracy: 0.5086 - my_mse: 0.2543 - binary_crossentropy: 0.7056 - hinge: 0.9721 - val_loss: 0.6945 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4720 - val_my_mse: 0.2507 - val_binary_crossentropy: 0.6945 - val_hinge: 1.0324\n",
      "Epoch 70/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.0000e+00 - binary_accuracy: 0.5166 - my_mse: 0.2534 - binary_crossentropy: 0.7039 - hinge: 0.9713 - val_loss: 0.6945 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4720 - val_my_mse: 0.2507 - val_binary_crossentropy: 0.6945 - val_hinge: 1.0324\n",
      "Epoch 71/1000\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 2.5988e-04 - binary_accuracy: 0.5120 - my_mse: 0.2524 - binary_crossentropy: 0.6982 - hinge: 0.9706 - val_loss: 0.6946 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.4720 - val_my_mse: 0.2507 - val_binary_crossentropy: 0.6946 - val_hinge: 1.0324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2920b53b5b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(256,  activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(Dense(128,  activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(Dense(64,  activation = 'relu'))\n",
    "classifier.add(Dense(32,  activation = 'relu'))\n",
    "classifier.add(Dense(16,  activation = 'relu'))\n",
    "classifier.add(Dense(8,  activation = 'relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(1,  activation = 'relu'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = metrics)\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 50, epochs = 1000, validation_split = 0.10, callbacks = [esm],shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training and validation loss\n",
    "plt.plot(classifier.history.history[\"loss\"], label='train')\n",
    "plt.plot(classifier.history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "#x1,y1 =plt.axis()\n",
    "#plt.axis([0,0])\n",
    "#plt.ylim([0.5, 0.7])\n",
    "plt.title('Training/Validation Loss');\n",
    "# Evaluate the model >> model.metrics_names\n",
    "#print(f'{model.metrics_names}: {model.evaluate(Bitcoin_train, y_train , verbose=1)}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = classifier.predict(X_test)\n",
    "y_pred = list(map(lambda x: 0 if x<0.5 else 1, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48317757009345796\n"
     ]
    }
   ],
   "source": [
    "# Computing Accuracy, Precision and Recall\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = pd.read_csv(\"../data/model_accuracy_IBM.csv\", index_col = False)\n",
    "df_prediction =  df_prediction.drop(columns=[\"Unnamed: 0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction[\"ANN_pred\"] = y_pred\n",
    "df_prediction[\"ANN_accuracy\"] = [accuracy for x in range(len(y_pred))]\n",
    "df_prediction[\"ANN_prob\"] = y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogReg_pred</th>\n",
       "      <th>LogReg_accuracy</th>\n",
       "      <th>LogReg_prob</th>\n",
       "      <th>LGBM_pred</th>\n",
       "      <th>LGBM_accuracy</th>\n",
       "      <th>LGBM_prob</th>\n",
       "      <th>y</th>\n",
       "      <th>kNN_pred</th>\n",
       "      <th>kNN_accuracy</th>\n",
       "      <th>kNN_prob</th>\n",
       "      <th>ANN_pred</th>\n",
       "      <th>ANN_accuracy</th>\n",
       "      <th>ANN_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.48785</td>\n",
       "      <td>0.499232</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48972</td>\n",
       "      <td>0.482038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483178</td>\n",
       "      <td>0.490417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.48785</td>\n",
       "      <td>0.504807</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48972</td>\n",
       "      <td>0.516175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483178</td>\n",
       "      <td>0.506478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.48785</td>\n",
       "      <td>0.591117</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48972</td>\n",
       "      <td>0.526401</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483178</td>\n",
       "      <td>0.594908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.48785</td>\n",
       "      <td>0.595272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48972</td>\n",
       "      <td>0.515859</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483178</td>\n",
       "      <td>0.625306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.48785</td>\n",
       "      <td>0.590655</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48972</td>\n",
       "      <td>0.515859</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483178</td>\n",
       "      <td>0.620808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1</td>\n",
       "      <td>0.48785</td>\n",
       "      <td>0.543262</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48972</td>\n",
       "      <td>0.536454</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483178</td>\n",
       "      <td>0.507600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1</td>\n",
       "      <td>0.48785</td>\n",
       "      <td>0.570132</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48972</td>\n",
       "      <td>0.521491</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483178</td>\n",
       "      <td>0.546710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>1</td>\n",
       "      <td>0.48785</td>\n",
       "      <td>0.542180</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48972</td>\n",
       "      <td>0.537546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483178</td>\n",
       "      <td>0.533604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1</td>\n",
       "      <td>0.48785</td>\n",
       "      <td>0.569741</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48972</td>\n",
       "      <td>0.521313</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483178</td>\n",
       "      <td>0.560094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1</td>\n",
       "      <td>0.48785</td>\n",
       "      <td>0.543188</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48972</td>\n",
       "      <td>0.521491</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483178</td>\n",
       "      <td>0.541299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LogReg_pred  LogReg_accuracy  LogReg_prob  LGBM_pred  LGBM_accuracy  \\\n",
       "0               0          0.48785     0.499232          0        0.48972   \n",
       "1               1          0.48785     0.504807          1        0.48972   \n",
       "2               1          0.48785     0.591117          1        0.48972   \n",
       "3               1          0.48785     0.595272          1        0.48972   \n",
       "4               1          0.48785     0.590655          1        0.48972   \n",
       "...           ...              ...          ...        ...            ...   \n",
       "1065            1          0.48785     0.543262          1        0.48972   \n",
       "1066            1          0.48785     0.570132          1        0.48972   \n",
       "1067            1          0.48785     0.542180          1        0.48972   \n",
       "1068            1          0.48785     0.569741          1        0.48972   \n",
       "1069            1          0.48785     0.543188          1        0.48972   \n",
       "\n",
       "      LGBM_prob  y  kNN_pred  kNN_accuracy  kNN_prob  ANN_pred  ANN_accuracy  \\\n",
       "0      0.482038  0         0      0.508411       0.5         0      0.483178   \n",
       "1      0.516175  1         0      0.508411       0.5         1      0.483178   \n",
       "2      0.526401  1         0      0.508411       0.5         1      0.483178   \n",
       "3      0.515859  1         1      0.508411       1.0         1      0.483178   \n",
       "4      0.515859  1         1      0.508411       1.0         1      0.483178   \n",
       "...         ... ..       ...           ...       ...       ...           ...   \n",
       "1065   0.536454  1         0      0.508411       0.5         1      0.483178   \n",
       "1066   0.521491  1         1      0.508411       1.0         1      0.483178   \n",
       "1067   0.537546  0         1      0.508411       1.0         1      0.483178   \n",
       "1068   0.521313  1         0      0.508411       0.5         1      0.483178   \n",
       "1069   0.521491  0         1      0.508411       1.0         1      0.483178   \n",
       "\n",
       "      ANN_prob  \n",
       "0     0.490417  \n",
       "1     0.506478  \n",
       "2     0.594908  \n",
       "3     0.625306  \n",
       "4     0.620808  \n",
       "...        ...  \n",
       "1065  0.507600  \n",
       "1066  0.546710  \n",
       "1067  0.533604  \n",
       "1068  0.560094  \n",
       "1069  0.541299  \n",
       "\n",
       "[1070 rows x 13 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv(\"../data/model_accuracy_IBM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
